{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse_args function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "def parse_args(args):\n",
    "\n",
    "    while(len(args) > 0):\n",
    "        # input gwas file name (full path)\n",
    "        if(args[0] == '--in_file'):\n",
    "            in_name = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        # (string) name of header column for chromosome\n",
    "        elif(args[0] == '--chr_name'):\n",
    "            chr_name = args[1]\n",
    "            args = args[2:]\n",
    "            \n",
    "        # name of study (e.g. s4s, ftc, gain, adaa, etc)\n",
    "        elif(args[0] == '--study_name'):\n",
    "            study = args[1]\n",
    "            args = args[2:]\n",
    "            \n",
    "        # (string) name of header column for allele1\n",
    "        elif(args[0] == '--a1_name'):\n",
    "            a1_name = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        # (string) name of header column for allele2\n",
    "        # if \n",
    "        elif(args[0] == '--a2_name'):\n",
    "            a2_name = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        # (string) name of header column for position (BP)\n",
    "        elif(args[0] == '--position_name'):\n",
    "            pos_name = args[1]\n",
    "            args = args[2:]\n",
    "            \n",
    "        elif(args[0] == '--ancestry'):\n",
    "            ancestry = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        # (string) path to processing directory\n",
    "        elif(args[0] == '--processing_dir'):\n",
    "            proc_dir = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        # other arguments unused\n",
    "        else:\n",
    "            sys.exit('Unused arguments: ' + ' '.join(args))\n",
    "\n",
    "    # check if missing required arguments\n",
    "    if('in_name' not in locals() or 'chr_name' not in locals() \\\n",
    "       or 'a1_name' not in locals() or 'pos_name' not in locals() \\\n",
    "       or 'proc_dir' not in locals(), or 'ancestry' not in locals()):\n",
    "        sys.exit('Missing at least one required argument. Please specify \\\n",
    "                --in_file, --chr_name, --a1_name, --position_name, --ancestry, --proc_dir')\n",
    "    if('a2_name' not in locals()):\n",
    "        sys.exit('Missing the argument <--a2_name>. If input data has no\\\n",
    "                 a2 column then specify <--a2_name none>')\n",
    "\n",
    "    return (in_name, study, chr_name, a1_name, a2_name, pos_name, proc_dir, ancestry)\n",
    "\n",
    "#in_name, study, chr_name, a1_name, a2_name, pos_name, processing_dir, ancestry = parse_args(sys.argv[1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_dir=/home/ec2-user/sand\n",
    "python ${methods_dir}/meth1.py \\\n",
    "    --in_file ~/sand/SAS_final_ftnd.summary.gz \\\n",
    "    --study_name s4s \\\n",
    "    --ancestry sas \\\n",
    "    --chr_name CHR \\\n",
    "    --a1_name A1 \\\n",
    "    --a2_name none \\\n",
    "    --position_name BP \\\n",
    "    --processing_dir ~/sand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chr(in_name, study, chr_name, a1_name, a2_name, pos_name, processing_dir, ancestry):\n",
    "    with open(in_name, 'r') as inF:\n",
    "        \n",
    "        # create a 'Marker' column that will be CHR:POSITION\n",
    "        study = 's4s'\n",
    "        header = inF.readline().split()\n",
    "        header.insert(0, 'Marker')\n",
    "\n",
    "        chr_index = header.index(chr_name)\n",
    "        pos_index = header.index(pos_name)\n",
    "        a1_index = header.index(a1_name)\n",
    "        \n",
    "        # if there is no A2 column then insert one\n",
    "        if a2_name == 'none':\n",
    "            a2_index = a1_index + 1\n",
    "            header.insert(a2_index, 'A2') # insert after a1\n",
    "            had_a2 = False \n",
    "        else:\n",
    "            had_a2 = True\n",
    "\n",
    "        last_chr = ''\n",
    "        processed_list = [] # keep track of which chr have been processed\n",
    "\n",
    "        line = inF.readline()\n",
    "        while(line): # while we are not at the end of the file\n",
    "            split_line = line.split()\n",
    "            current_chr = split_line[chr_index]\n",
    "\n",
    "            if not had_a2:\n",
    "                split_line.insert(a2_index, '.') # insert place holder\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if(current_chr != last_chr): # create a new file \n",
    "                proc_message = 'Processing chr{}'.format(current_chr)\n",
    "                print(proc_message)\n",
    "\n",
    "                # keep track of which chromosomes have been processed\n",
    "                processed_list.append(current_chr)\n",
    "                times_processed = processed_list.count(current_chr)\n",
    "                last_chr = current_chr # new last chromosome now\n",
    "                \n",
    "                \n",
    "                # construct outfile name\n",
    "                fname = '{}.{}.1000G.chr{}.CAT_FTND~1df_add.out.txt'.format(study,\n",
    "                                                                            ancestry,\n",
    "                                                                            split_line[chr_index])\n",
    "                out_dir = \"{}/processing/chr{}/\".format(ancestry, split_line[chrIndex])\n",
    "                outF = open(processing_dir + out_dir + fname, 'a')\n",
    "\n",
    "                # if this is first time this chr has been encountered make a header\n",
    "                if times_processed == 1:\n",
    "                    # write to a new file based on the new chr we are processing\n",
    "                    # also add the column Marker to the column header\n",
    "                    outF.write(\"\\t\".join(header) + \"\\n\")\n",
    "                    \n",
    "                    \n",
    "                # creating the Markername = CHR:POSITION in first field\n",
    "            out_line = \"{}:{}\\t{}\\n\".format(split_line[chr_index],\n",
    "                                            split_line[pos_index],\n",
    "                                            \"\\t\".join(split_line))\n",
    "            outF.write(out_line)\n",
    "\n",
    "            line = inF.readline() # read next row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_snp(base_dir, ancestry, study, chrom):\n",
    "    \"\"\"Convert snps to 1000G phase 3 format\"\"\"\n",
    "    import gzip\n",
    "    thou_dict = kp3_dict(chrom) # reference panel dictionary of SNPs\n",
    "\n",
    "    in_name = \"{}.{}.1000G.chr{}.CAT_FTND~1df_add.out.txt\".format(study, ancestry, chrom)\n",
    "    file_dir = \"{}/{}/processing/chr{}/\".format(base_dir, ancestry, chrom)\n",
    "    with open(file_dir + in_name, \"r\") as inF:\n",
    "        #leg_file = \"/shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr{}.legend.gz\".format(chrom)\n",
    "        out_name = \"{}.{}.1000G.chr{}.CAT_FTND~1df.phase3ID_add.out.txt\".format(study, ancestry, chrom)\n",
    "        with open(file_dir + out_name, \"w\") as outF:\n",
    "            header = inF.readline()\n",
    "            outF.write(header)\n",
    "\n",
    "            snp_index = header.split().index(\"SNP\")\n",
    "            a1_index = header.split().index(\"A1\")\n",
    "            a2_index = header.split().index(\"A2\")\n",
    "            phase3_index = header.split().index(\"Marker\") # updated SNP id\n",
    "\n",
    "            line = inF.readline()\n",
    "\n",
    "            while line:\n",
    "                snp = line.split()[snp_index]\n",
    "                snp_split = snp.split(\":\")\n",
    "                a1 = line.split()[a1_index]\n",
    "                snp_id = snp_split[0]\n",
    "\n",
    "                split_line = line.split()\n",
    "                if len(snp_split) >= 4: # indicates already in 1000G_p3 format\n",
    "                    split_line[phase3_index] = snp\n",
    "                    split_line[a2_index] = snp_split[3] # fill in A2 data\n",
    "                    new_line = \"\\t\".join(split_line)\n",
    "                    outF.write(new_line + \"\\n\")\n",
    "\n",
    "                # if not already in 1000G_p3 format, search for it in ref panel\n",
    "                # which is in dictionary we created\n",
    "                elif (len(snp_split) == 1) and (snp_id[:2] == \"rs\"):\n",
    "                    try:\n",
    "                        marker_name = \":\".join(thou_dict[snp_id])\n",
    "                        potential_a1 = thou_dict[snp_id][2]\n",
    "                        potential_a2 = thou_dict[snp_id][3]\n",
    "\n",
    "                        if a1 == potential_a1:\n",
    "                            a2 = potential_a2\n",
    "                            split_line[a2_index] = a2\n",
    "                            split_line[phase3_index] = marker_name\n",
    "                            new_line = \"\\t\".join(split_line)\n",
    "                            outF.write(new_line + \"\\n\")\n",
    "                        elif a1 == potential_a2:\n",
    "                            a2 = potential_a1\n",
    "                            split_line[a2_index] = a2\n",
    "                            split_line[phase3_index] = marker_name\n",
    "                            new_line = \"\\t\".join(split_line)\n",
    "                            outF.write(new_line + \"\\n\")\n",
    "                        else:\n",
    "                            pass\n",
    "                    except KeyError: # rsID not in ref panel dictionary\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "                line = inF.readline()\n",
    "    message = \"Done with {} chr{}.\".format(ancestry, chrom)\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args):\n",
    "    import sys, os\n",
    "\n",
    "    while(len(args) > 0):\n",
    "        # input gwas file name (full path)\n",
    "        if(args[0] == '--base_dir'):\n",
    "            base_dir = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        elif(args[0] == '--ancestry'):\n",
    "            ancestry = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        elif(args[0] == '--study'):\n",
    "            study = args[1]\n",
    "            args = args[2:]\n",
    "            \n",
    "        elif(args[0] == '--chrom'):\n",
    "            chrom = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        # other arguments unused\n",
    "        else:\n",
    "            sys.exit('Unused arguments: ' + ' '.join(args))\n",
    "\n",
    "    # check if missing required arguments\n",
    "    if('base_dir' not in locals() or 'ancestry' not in locals() \\\n",
    "       or 'study' not in locals(), or 'chrom' not in locals()):\n",
    "        sys.exit('Missing at least one required argument. Please specify \\\n",
    "                --base_dir, --ancestry, --study, --chrom')\n",
    "    return (base_dir, ancestry, study, chrom)\n",
    "\n",
    "#base_dir, ancestry, study, chrom = parse_args(sys.argv[1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestry_list=\"afr amr eur eas sas\"\n",
    "study=s4s\n",
    "\n",
    "base=/home/ec2-user/jmarks/nicotine/spit_science/processed_results/003\n",
    "for chr in {1..22}; do\n",
    "    for ancestry in $ancestry_list;do\n",
    "        outF=$base/$ancestry/processing/chr$chr\n",
    "        /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "            --job_name S4S_${ancestry}_chr${chr} \\\n",
    "            --script_prefix $outF/convert_to_1000g_p3 \\\n",
    "            --mem 15 \\\n",
    "            --nslots 3 \\\n",
    "            --priority 0 \\\n",
    "            --program python convert_gwas_results_1000g_p3.py \\\n",
    "                --base_dir \\\n",
    "                --ancestry $ancestry \\\n",
    "                --study $study \\\n",
    "                --chrom $chr $study $chr\n",
    "    done\n",
    "done\n",
    "\n",
    "\n",
    "for ancestry in ${ancestry_list}; do\n",
    "    if [ $ancestry == \"afr\" ]; then\n",
    "        group=afr\n",
    "    elif [ $ancestry == \"amr\" ]; then\n",
    "        group=amr\n",
    "    elif [ $ancestry == \"eas\" ]; then\n",
    "        group=eas\n",
    "    elif [ $ancestry == \"sas\" ]; then\n",
    "        group=sas\n",
    "    else\n",
    "        group=eur\n",
    "    fi    \n",
    "    for (( chr=1; chr<23; chr++ )); do\n",
    "        /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "            --job_name _$ancestry_${chr} \\\n",
    "            --script_prefix $base/$ancestry/processing/chr$chr/s4s.$ancestry.1000G.chr$chr.CAT_FTND~1df.phase3ID_add.out.txt \\\n",
    "            --mem 15 \\\n",
    "            --nslots 3 \\\n",
    "            --priority 0 \\\n",
    "            --program perl /shared/bioinformatics/software/perl/id_conversion/convert_to_1000g_p3_ids.pl \\\n",
    "            --file_in $base/$ancestry/processing/chr$chr/s4s.$ancestry.1000G.chr$chr.CAT_FTND~1df_add.out.txt \\\n",
    "            --file_out $base/$ancestry/processing/chr$chr/s4s.$ancestry.1000G.chr$chr.CAT_FTND~1df.phase3ID_add.out.txt \\\n",
    "            --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr$chr.legend.gz \\\n",
    "            --file_in_header 1 \\\n",
    "            --file_in_id_col 0 \\\n",
    "            --file_in_chr_col 1 \\\n",
    "            --file_in_pos_col 3 \\\n",
    "            --file_in_a1_col 4 \\\n",
    "            --file_in_a2_col 8 \\\n",
    "            --chr $chr\n",
    "    done\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

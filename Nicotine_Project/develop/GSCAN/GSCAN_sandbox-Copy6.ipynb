{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data and visualize\n",
    "Grab the beta value and the standard error (beta) for each SNP accross each cohort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 044 meta-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from decimal import Decimal\n",
    "from scipy.stats import chi2\n",
    "import csv\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "This function takes as input (1) a list of cohorts specific to a meta-analysis,\n",
    "(2) and an excel file containing the data on each variant that was the results \n",
    "of a SNP look-up. You need to specify the name of the sheet as well. This file should contain a header. For each column, the heading should be\n",
    "the cohort name & ancestry followed by a period followed by the data description. Specifically,\n",
    "the data that are of interest for this script are: the beta value, standard error, and the variant\n",
    "specific p-value. An example of how these entries should be in the excel sheet is\n",
    "\n",
    "Example:\n",
    "AAND_COGEND2_AA.beta_SNP_add,  AAND_COGEND2_AA.sebeta_SNP_add, AAND_COGEND2_AA.p\n",
    "\n",
    "For (1) an example of the input list is: \n",
    "AAND_COGEND2_AA, DECODE_EA, NONGAIN_EA \n",
    "\n",
    "The output will be an excel file with the meta-analysis calculations for each variant of interest.\n",
    "\"\"\"\n",
    "# I will create a new data frame for each variant. This data frame will have the column names:\n",
    "# (1) cohort, (2) Ancestry group, (3) Beta, (4) Std. Error, (5) Seweighted, and (6) Pr(>|t|) which is the p-val\n",
    "# addictionally  I will add the rows for calculating the meta in the Seweighted column and below all of the cohorts\n",
    "# getting the first cohort, note that this will eventually be in a loop of the cohorts\n",
    "\n",
    "#os.chdir(\"C:\\\\Users\\\\jmarks\\\\Desktop\\\\Projects\\\\Nicotine\\\\GSCAN_extended_results_nicotine\\\\results\\\\results_from_missing_snp_lookup\\\\\")\n",
    "#mypath = r\"C:\\Users\\jmarks\\Desktop\\Projects\\Nicotine\\GSCAN_extended_results_nicotine\\develop\\missing_snps_from_first_set_of_results\\results\\SNP-lookup-results\"\n",
    "#os.chdir(mypath)\n",
    "#mydata = pd.ExcelFile(\"missing_SNPs_results_prefiltered_meta_analyses_044_045_046_V02.xlsx\")\n",
    "#mydata = mydata.parse(\"044_combined_data\")\n",
    "\n",
    "mypath = r\"C:\\Users\\jmarks\\Desktop\\20180201\"\n",
    "os.chdir(mypath)\n",
    "mydata = pd.ExcelFile(\"rs910_example.xlsx\")\n",
    "mydata = mydata.parse(\"Sheet1\")\n",
    "\n",
    "\n",
    "cohorts_list44 = [\"AAND_COGEND2_AA\",\n",
    "\"COGEND_AA\",\n",
    "\"COGEND_EA\",\n",
    "\"COGEND2_AA\",\n",
    "\"COGEND2_EA\",\n",
    "\"COPDGene_AA\",\n",
    "\"COPDGene_EA\",\n",
    "\"deCODE_EA\",\n",
    "\"Dental_Caries_EA\",\n",
    "\"EAGLE_EA\",\n",
    "\"FINN_TWIN_EA\",\n",
    "\"GAIN_AA\",\n",
    "\"GAIN_EA\",\n",
    "\"JHS_AA\",\n",
    "\"nonGAIN_EA\",\n",
    "\"NTR_EA\",\n",
    "\"SAGE_AA\",\n",
    "\"SAGE_EA\",\n",
    "\"UW_TTURC_AA\",\n",
    "\"UW_TTURC_EA\",\n",
    "\"YALE_PENN_AA\",\n",
    "\"YALE_PENN_EA\"]\n",
    "\n",
    "totalRows = len(cohorts_list44)\n",
    "\n",
    "# This dictionary will have an rsID for the key and the key value will be a dataframe\n",
    "dataDict = {}\n",
    "\n",
    "# initialize a dataframe\n",
    "emptyArray = np.empty((totalRows,13,))\n",
    "emptyArray[:] = np.nan\n",
    "columns = [\"SNP\", \"Cohort\", \"Ancestry group\", \"Beta\", \"Std. Error\", \"Seweighted\", \"Pr(>|t|)\", \n",
    "           \"AllMeta.SumSEweight\", \"AllMeta.weightedSE\", \"AllMeta.SEweighted_beta\", \n",
    "           \"AllMeta.SEweighted_Z\", \"AllMeta.SEweighted_Chi\", \"AllMeta.SEweighted_P\"]\n",
    "num_of_rsIDs = len(mydata)\n",
    "print(num_of_rsIDs)\n",
    "# Above this write a script which removes the variants who were not present in any of the cohorts\n",
    "\n",
    "\n",
    "\n",
    "# list of SNPs which were all NA across all cohorts\n",
    "noDataSNPs = []\n",
    "\n",
    "# loop to fill in information for the meta-anlaysis calculation\n",
    "for rsID in range(num_of_rsIDs):\n",
    "    \n",
    "    # check SNP missing across all cohorts\n",
    "    if pd.isnull(mydata.iloc[rsID,3:]).all():\n",
    "        noDataSNPs.append(mydata.iloc[rsID,0])\n",
    "        break\n",
    "    \n",
    "    markerName = mydata.iloc[rsID,0]\n",
    "    dataDict[markerName] = pd.DataFrame(columns=columns, data=emptyArray)\n",
    "    dataDict[markerName].iloc[0,0] = markerName # add SNP\n",
    "    metaSEweighted_beta = 0\n",
    "    \n",
    "    \n",
    "    for cohort in range(len(cohorts_list44)):\n",
    "        \n",
    "        # get all of the cohort specific data\n",
    "        cohortData = mydata.filter(like=cohorts_list44[cohort]).iloc[rsID,:]\n",
    "        \n",
    "        # add cohort to dataframe\n",
    "        cohortName = cohorts_list44[cohort]\n",
    "        dataDict[markerName].iloc[cohort,1] = cohorts_list44[cohort][0:-3]\n",
    "            \n",
    "        # add Ancestry group\n",
    "        ancestry = cohorts_list44[cohort][-2:]\n",
    "        dataDict[markerName].iloc[cohort, 2] = ancestry\n",
    "        # add Beta\n",
    "        betaVal = cohortData.filter(like=\".beta\")[0]\n",
    "        \n",
    "        # flip the sign for deCODE and NTR\n",
    "        if cohorts_list44[cohort] == \"FINN_TWIN_EA\":\n",
    "            betaVal = -betaVal\n",
    "        dataDict[markerName].iloc[cohort, 3] = betaVal\n",
    "        \n",
    "        # add Std. Error\n",
    "        standardErr = cohortData.filter(like=\"sebeta\")[0]\n",
    "        dataDict[markerName].iloc[cohort, 4] = standardErr\n",
    "        \n",
    "        # add Seweighted\n",
    "        seWeighted = 1 / (standardErr ** 2)\n",
    "        dataDict[markerName].iloc[cohort,5]  = seWeighted\n",
    "        \n",
    "        # add p-val\n",
    "        pVal = cohortData.filter(regex=\".p$\")[0]\n",
    "        dataDict[markerName].iloc[cohort, 6] = pVal\n",
    "        \n",
    "        #  metaSEweighted_beta calculation \n",
    "        if not np.isnan(betaVal):\n",
    "            metaSEweighted_beta += (betaVal*seWeighted)\n",
    "      \n",
    "    # Meta calculations\n",
    "    SumSEweight = dataDict[markerName]['Seweighted'].sum()\n",
    "    dataDict[markerName].iloc[0, 7] = SumSEweight\n",
    "\n",
    "    metaWeightedSE = math.sqrt(1/SumSEweight)\n",
    "    dataDict[markerName].iloc[0, 8] = metaWeightedSE\n",
    "    \n",
    "    metaSEweighted_beta = metaSEweighted_beta / SumSEweight \n",
    "    dataDict[markerName].iloc[0, 9] = metaSEweighted_beta\n",
    "\n",
    "    metaSEweighted_Z = (metaSEweighted_beta / metaWeightedSE)\n",
    "    dataDict[markerName].iloc[0, 10] = metaSEweighted_Z\n",
    "\n",
    "    metaSEweighted_chi = metaSEweighted_Z ** 2\n",
    "    dataDict[markerName].iloc[0, 11] = metaSEweighted_chi\n",
    "\n",
    "    metaSEweighted_P = '%.2E' % Decimal(chi2.sf(metaSEweighted_chi, 1))\n",
    "    dataDict[markerName].iloc[0, 12] = metaSEweighted_P\n",
    "\n",
    "    \n",
    "\n",
    "# write meta-calculations for all variants to a file,\n",
    "with open('C:\\\\Users\\\\jmarks\\\\Desktop\\\\meta_results_for_missing_snps.tsv', 'a') as outfile:\n",
    "    for item in dataDict:\n",
    "        dataDict[item].to_csv(outfile, sep='\\t', index=False)\n",
    "        outfile.write('\\n\\n\\n')\n",
    "    \n",
    "# write the missing the missing SNPs to a file\n",
    "with open('C:\\\\Users\\\\jmarks\\\\Desktop\\\\missingSNPs.tsv', 'w') as outfile:\n",
    "    for item in noDataSNPs:\n",
    "        outfile.write(\"%s\\n\" % item)\n",
    "\n",
    "#dataDict[markerName].to_csv(\"C:\\\\Users\\\\jmarks\\\\Desktop\\\\meta_results_for_missing_snps.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jmarks\\\\Desktop\\\\Projects\\\\Nicotine\\\\GSCAN_extended_results_nicotine\\\\develop\\\\missing_snps_from_first_set_of_results\\\\results\\\\SNP-lookup-results\\\\044_missing_snp_lookup_results\\\\044_combine_data.tsv'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "strs = r\"C:\\Users\\jmarks\\Desktop\\Projects\\Nicotine\\GSCAN_extended_results_nicotine\\develop\\missing_snps_from_first_set_of_results\\results\\SNP-lookup-results\\044_missing_snp_lookup_results\\044_combine_data.tsv\"   \n",
    "strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-31457ffe1a7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mzero44\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mzero44\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero44\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mzero45\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mzero45\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero45\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mzero46\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\jmarks\\\\Desktop\\\\Projects\\\\Nicotine\\\\GSCAN_extended_results_nicotine\\\\results\\\\results_from_missing_snp_lookup\\\\\")\n",
    "\n",
    "\n",
    "#os.listdir()\n",
    "#xl = pd.ExcelFile(\"missing_SNPs_results_prefiltered_meta_analyses_044_045_046_V02.xlsx\")\n",
    "xl.sheet_names\n",
    "zero44 = xl.sheet_names[0]\n",
    "zero44 = xl.parse(zero44)\n",
    "zero45 = xl.sheet_names[1]\n",
    "zero45 = xl.parse(zero45)\n",
    "zero46 = xl.sheet_names[2]\n",
    "zero46 = xl.parse(zero46)\n",
    "zero44.iloc[0:1,:]\n",
    "\n",
    "# beta is in each, but also sebeta is too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 045 meta-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 046 meta-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function parses input arguments\n",
    "# required arguments: --metal\n",
    "#                     --probabel\n",
    "#                     --probabel_labels\n",
    "#                     --out\n",
    "def parseArguments(args):\n",
    "        while(len(args) > 0):\n",
    "                # input metal file name (full path)\n",
    "                if(args[0] == '--metal'):\n",
    "                        metalFName = args[1]\n",
    "                        args = args[2:]\n",
    "\n",
    "                # a list of input probabel file names (full path)\n",
    "                elif(args[0] == '--probabel'):\n",
    "                        args = args[1:]\n",
    "                        probabelFList = []\n",
    "                        while(len(args)>0 and args[0][:2] != '--'):\n",
    "                                probabelFList.append(args[0])\n",
    "                                args = args[1:]\n",
    "\n",
    "                # a list of probabel labels\n",
    "                elif(args[0] == '--probabel_labels'):\n",
    "                        args = args[1:]\n",
    "                        labelsList = []\n",
    "                        while(len(args)>0 and args[0][:2] != '--'):\n",
    "                                labelsList.append(args[0])\n",
    "                                args = args[1:]\n",
    "\n",
    "                # output merged file name (full path)\n",
    "                elif(args[0] == '--out'):\n",
    "                        outFName = args[1]\n",
    "                        args = args[2:]\n",
    "\n",
    "                # other arguments unused\n",
    "                else:\n",
    "                        sys.exit('Unused arguments: ' + ' '.join(args))\n",
    "\n",
    "        # check if missing required arguments\n",
    "        if('metalFName' not in locals() or 'probabelFList' not in locals() or 'labelsList' not in locals() or 'outFName' not in locals()):\n",
    "                sys.exit('Missing at least one required argument. Please specify --metal, --probabel, --probabel_labels, --out')\n",
    "\n",
    "        # check if length of probabel files equals length of probabel labels\n",
    "        if(len(probabelFList) != len(labelsList)):\n",
    "                sys.exit('Length of probabel files does not match length of probabel labels.')\n",
    "\n",
    "        return (metalFName, outFName, probabelFList, labelsList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse_args function\n",
    "Note to have an argument \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "def parse_args(args):\n",
    "\n",
    "    while(len(args) > 0):\n",
    "        # input gwas file name (full path)\n",
    "        if(args[0] == '--in_file'):\n",
    "            in_name = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        # (string) name of header column for chromosome\n",
    "        elif(args[0] == '--chr_name'):\n",
    "            chr_name = args[1]\n",
    "            args = args[2:]\n",
    "            \n",
    "        # name of study (e.g. s4s, ftc, gain, adaa, etc)\n",
    "        elif(args[0] == '--study_name'):\n",
    "            study = args[1]\n",
    "            args = args[2:]\n",
    "            \n",
    "        # (string) name of header column for allele1\n",
    "        elif(args[0] == '--a1_name'):\n",
    "            a1_name = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        # (string) name of header column for allele2\n",
    "        # if \n",
    "        elif(args[0] == '--a2_name'):\n",
    "            a2_name = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        # (string) name of header column for position (BP)\n",
    "        elif(args[0] == '--position_name'):\n",
    "            pos_name = args[1]\n",
    "            args = args[2:]\n",
    "            \n",
    "        elif(args[0] == '--ancestry'):\n",
    "            ancestry = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        # (string) path to processing directory\n",
    "        elif(args[0] == '--processing_dir'):\n",
    "            proc_dir = args[1]\n",
    "            args = args[2:]\n",
    "\n",
    "        # other arguments unused\n",
    "        else:\n",
    "            sys.exit('Unused arguments: ' + ' '.join(args))\n",
    "\n",
    "    # check if missing required arguments\n",
    "    if('in_name' not in locals() or 'chr_name' not in locals() \\\n",
    "       or 'a1_name' not in locals() or 'pos_name' not in locals() \\\n",
    "       or 'proc_dir' not in locals(), or 'ancestry' not in locals()):\n",
    "        sys.exit('Missing at least one required argument. Please specify \\\n",
    "                --in_file, --chr_name, --a1_name, --position_name, --ancestry, --proc_dir')\n",
    "    if('a2_name' not in locals()):\n",
    "        sys.exit('Missing the argument <--a2_name>. If input data has no\\\n",
    "                 a2 column then specify <--a2_name none>')\n",
    "\n",
    "    return (in_name, study, chr_name, a1_name, a2_name, pos_name, proc_dir, ancestry)\n",
    "\n",
    "#in_name, study, chr_name, a1_name, a2_name, pos_name, processing_dir, ancestry = parse_args(sys.argv[1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python meth1.py \\\n",
    "    --in_file ~/sand/SAS_final_ftnd.summary.gz \\\n",
    "    --study_name s4s \\\n",
    "    --ancestry sas \\\n",
    "    --chr_name CHR \\\n",
    "    --a1_name A1 \\\n",
    "    --a2_name none \\\n",
    "    --position_name BP \\\n",
    "    --processing_dir ~/sand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chr(in_name, study, chr_name, a1_name, a2_name, pos_name, processing_dir, ancestry):\n",
    "    with open(in_name, 'r') as inF:\n",
    "        \n",
    "        # create a 'Marker' column that will be CHR:POSITION\n",
    "        study = 's4s'\n",
    "        header = inF.readline().split()\n",
    "        header.insert(0, 'Marker')\n",
    "\n",
    "        chr_index = header.index(chr_name)\n",
    "        pos_index = header.index(pos_name)\n",
    "        a1_index = header.index(a1_name)\n",
    "        \n",
    "        # if there is no A2 column then insert one\n",
    "        if a2_name == 'none':\n",
    "            a2_index = a1_index + 1\n",
    "            header.insert(a2_index, 'A2') # insert after a1\n",
    "            had_a2 = False \n",
    "        else:\n",
    "            had_a2 = True\n",
    "\n",
    "        last_chr = ''\n",
    "        processed_list = [] # keep track of which chr have been processed\n",
    "\n",
    "        line = inF.readline()\n",
    "        while(line): # while we are not at the end of the file\n",
    "            split_line = line.split()\n",
    "            current_chr = split_line[chr_index]\n",
    "\n",
    "            if not had_a2:\n",
    "                split_line.insert(a2_index, '.') # insert place holder\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            if(current_chr != last_chr): # create a new file \n",
    "                proc_message = 'Processing chr{}'.format(current_chr)\n",
    "                print(proc_message)\n",
    "\n",
    "                # keep track of which chromosomes have been processed\n",
    "                processed_list.append(current_chr)\n",
    "                times_processed = processed_list.count(current_chr)\n",
    "                last_chr = current_chr # new last chromosome now\n",
    "                \n",
    "                \n",
    "                # construct outfile name\n",
    "                fname = '{}.{}.1000G.chr{}.CAT_FTND~1df_add.out.txt'.format(study,\n",
    "                                                                            ancestry,\n",
    "                                                                            split_line[chr_index])\n",
    "                out_dir = \"{}/processing/chr{}/\".format(ancestry, split_line[chrIndex])\n",
    "                outF = open(processing_dir + out_dir + fname, 'a')\n",
    "\n",
    "                # if this is first time this chr has been encountered make a header\n",
    "                if times_processed == 1:\n",
    "                    # write to a new file based on the new chr we are processing\n",
    "                    # also add the column Marker to the column header\n",
    "                    outF.write(\"\\t\".join(header) + \"\\n\")\n",
    "                    \n",
    "                    \n",
    "                # creating the Markername = CHR:POSITION in first field\n",
    "            out_line = \"{}:{}\\t{}\\n\".format(split_line[chr_index],\n",
    "                                            split_line[pos_index],\n",
    "                                            \"\\t\".join(split_line))\n",
    "            outF.write(out_line)\n",
    "\n",
    "            line = inF.readline() # read next row "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kp3_dict(chrom):\n",
    "    \"\"\"\n",
    "    Create a dictionary for the 1000G_p3 snps.\n",
    "    The key is the rsID and the value is a list of [A1,A2]\n",
    "    \"\"\"\n",
    "    import gzip\n",
    "################################################################################ \n",
    "    base_dir = \"/shared/data/ref_panels/1000G/2014.10\"\n",
    "    in_file = \"{}/1000GP_Phase3_chr{}.legend.gz\".format(base_dir, chrom)\n",
    "    thousand_dict = {}\n",
    "    with gzip.open(in_file, \"r\") as inF:\n",
    "        next(inF)\n",
    "        line = inF.readline()\n",
    "        while line:\n",
    "            uniq_id = line.split()[0]\n",
    "            uniq_id = uniq_id.split(\":\") \n",
    "            rs_id = uniq_id[0]\n",
    "            position = uniq_id[1]\n",
    "            a1 = uniq_id[2]\n",
    "            a2 = uniq_id[3]\n",
    "            thousand_dict[rs_id] = [rs_id, position, a1, a2]\n",
    "            line = inF.readline()\n",
    "    message = \"Done creating dictionary for chr{} 1000G_p3 reference panel.\".format(chrom)\n",
    "    print(message)\n",
    "    return thousand_dict\n",
    "\n",
    "thou_dict = kp3_dict(15)\n",
    "\n",
    "import sys\n",
    "\n",
    "base_dir = \"/home/ec2-user/jmarks/nicotine/spit_science/processed_results/002\"\n",
    "#ancestry_list = [\"aa\", \"amr\", \"ea\", \"eas\", \"sas\"]\n",
    "ancestry_list = [\"sas\"]\n",
    "study = \"sfs\"\n",
    "\n",
    "import sys\n",
    "print \"This is the name of the script: \", sys.argv[0]\n",
    "\n",
    "def convert_snp(base_dir, ancestry, study, chrom):\n",
    "    \"\"\"Convert snps to 1000G phase 3 format\"\"\"\n",
    "    import gzip\n",
    "    thou_dict = kp3_dict(chrom) # reference panel dictionary of SNPs\n",
    "    \n",
    "    in_name = \"{}.{}.1000G.chr{}.CAT_FTND~1df_add.out.txt\".format(study, ancestry, chrom)\n",
    "    file_dir = \"{}/{}/processing/chr{}/\".format(base_dir, ancestry, chrom)\n",
    "    with open(file_dir + in_name, \"r\") as inF:\n",
    "        #leg_file = \"/shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr{}.legend.gz\".format(chrom)\n",
    "        out_name = \"{}.{}.1000G.chr{}.CAT_FTND~1df.phase3ID_add.out.txt\".format(study, ancestry, chrom)\n",
    "        with open(file_dir + out_name, \"w\") as outF:\n",
    "            header = inF.readline()\n",
    "            outF.write(header)\n",
    "            \n",
    "            snp_index = header.split().index(\"SNP\")\n",
    "            a1_index = header.split().index(\"A1\")\n",
    "            a2_index = header.split().index(\"A2\")\n",
    "            phase3_index = header.split().index(\"Marker\") # updated SNP id\n",
    "            \n",
    "            line = inF.readline()\n",
    "            \n",
    "            while line:\n",
    "                snp = line.split()[snp_index]\n",
    "                snp_split = snp.split(\":\")\n",
    "                a1 = line.split()[a1_index]\n",
    "                snp_id = snp_split[0]\n",
    "                \n",
    "                split_line = line.split()\n",
    "                if len(snp_split) >= 4: # indicates already in 1000G_p3 format\n",
    "                    split_line[phase3_index] = snp\n",
    "                    split_line[a2_index] = snp_split[3] # fill in A2 data\n",
    "                    new_line = \"\\t\".join(split_line)\n",
    "                    outF.write(new_line + \"\\n\")\n",
    "                    \n",
    "                # if not already in 1000G_p3 format, search for it in ref panel \n",
    "                # which is in dictionary we created\n",
    "                elif (len(snp_split) == 1) and (snp_id[:2] == \"rs\"): \n",
    "                    try:\n",
    "                        marker_name = \":\".join(thou_dict[snp_id])\n",
    "                        potential_a1 = thou_dict[snp_id][2]\n",
    "                        potential_a2 = thou_dict[snp_id][3]\n",
    "                        \n",
    "                        if a1 == potential_a1:\n",
    "                            a2 = potential_a2\n",
    "                            split_line[a2_index] = a2\n",
    "                            split_line[phase3_index] = marker_name\n",
    "                            new_line = \"\\t\".join(split_line)\n",
    "                            outF.write(new_line + \"\\n\")\n",
    "                        elif a1 == potential_a2:\n",
    "                            a2 = potential_a1\n",
    "                            split_line[a2_index] = a2\n",
    "                            split_line[phase3_index] = marker_name\n",
    "                            new_line = \"\\t\".join(split_line)\n",
    "                            outF.write(new_line + \"\\n\")\n",
    "                        else:\n",
    "                            continue \n",
    "                    except KeyError: # rsID not in ref panel dictionary\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "                line = inF.readline()\n",
    "    print(\"Done\")\n",
    "    \n",
    "base_dir = \"/home/ec2-user/jmarks/nicotine/spit_science/processed_results/002\"\n",
    "ancestry = \"sas\"\n",
    "study = \"sfs\"\n",
    "chrom = 15\n",
    "\n",
    "print(sys.argv[0])\n",
    "print(sys.argv[1])\n",
    "print(sys.argv[2])\n",
    "print(sys.argv[3])\n",
    "convert_snp(base_dir, ancestry, study, chrom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

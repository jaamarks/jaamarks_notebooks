{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UHS4 imputation\n",
    "__Author__: Jesse Marks <br>\n",
    "\n",
    "**GitHub Issue:** [Issue #117](https://github.com/RTIInternational/bioinformatics/issues/117)\n",
    "\n",
    "This document logs the steps taken to perform pre-imputation procedures on the UHS4 dataset, both EA and AA. The starting point for this analysis is after quality control of observed genotypes. The quality controlled genotypes are oriented on the GRCh37 plus strand. \n",
    "\n",
    "## Software and tools\n",
    "The software and tools used for porcessing these data are\n",
    "* [Michigan Imputation Server](https://imputationserver.sph.umich.edu/index.html) (MIS)\n",
    "* [Amazon Web Services (AWS) - Cloud Computing Services](https://aws.amazon.com/)\n",
    "    * Linux AMI\n",
    "* [PLINK v1.90 beta 4.10](https://www.cog-genomics.org/plink/)\n",
    "* [bgzip](http://www.htslib.org/doc/tabix.html)\n",
    "* [BCF Tools](http://www.htslib.org/doc/bcftools.html)\n",
    "* Windows 10 with [Cygwin](https://cygwin.com/) installed\n",
    "* GNU bash version 4.2.46\n",
    "\n",
    "## Data retrieval and organization\n",
    "PLINK binary filesets will be obtained from AWS S3 storage.\n",
    "\n",
    "Jesse Marks performed the QC and stored the observed genotype data at:\n",
    "\n",
    "```\n",
    "s3/rti-heroin/uhs4/data/genotype/observed/final/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Statistics Breakdown \n",
    "This table includes the initial number of variants in each study as well as the final number of variants in the intersection set. The `Variants Post-Filtering` is in referral to the filtering steps (1) remove discordant alleles & (2) removal of monomorphic variants.\n",
    "\n",
    "#### HA \n",
    "| Data Set      | Initial Variants | Variants Post-Filtering  | Intersection     |\n",
    "|---------------|------------------|--------------------------|------------------|\n",
    "| UHS4          |                  |                          | NA               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Directory Structure & Download Data\n",
    "The following section needs to be modified each time to reflect where the data is stored!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EC2 command line (bash) ###\n",
    "\n",
    "# Modify variables below\n",
    "######################################################################\n",
    "base_dir=/shared/jmarks/heroin/uhs4/genotype/imputed/003\n",
    "genD=/shared/data/studies/heroin/uhs4/genotype/observed/final/003\n",
    "\n",
    "base_name=\"chr_all\" # chr23 or chr_all\n",
    "chr_list={1..23} # or {1..22} \n",
    "ancestry_list=\"ha\" # space delimited Ex. \"ea aa ha\"\n",
    "study_list=\"uhs4\" # space delimited, lowercase\n",
    "######################################################################\n",
    "\n",
    "mkdir ${base_dir}/processing/{intersect,1000g,impute_prep}\n",
    "for study in ${study_list};do\n",
    "    for ancestry in ${ancestry_list};do\n",
    "        mkdir -p ${base_dir}/processing/${study}\n",
    "        mkdir -p ${base_dir}/data/${study}/genotype/observed/${ancestry}\n",
    "    done\n",
    "done\n",
    "\n",
    "## download genotype (with AWS CLI tools) to respective directories ##\n",
    "#aws s3 sync s3://rti-heroin/kreek/data/genotype/original/20181128/ \\\n",
    "#    ${base_dir}/data/${study}/genotype/observed/\n",
    "#mv ${base_dir}/data/${study}/genotype/observed/ea* ${base_dir}/data/${study}/genotype/observed/ea\n",
    "#mv ${base_dir}/data/${study}/genotype/observed/aa* ${base_dir}/data/${study}/genotype/observed/aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "## GRCh37 strand and allele discordance check\n",
    "### MAF for study data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### EC1 command line (Bash) ###\n",
    "\n",
    "# write out the MAF report\n",
    "for study in ${study_list}; do\n",
    "    study_dir=${base_dir}/processing/${study}/strand_check\n",
    "    mkdir ${study_dir}\n",
    "    for ancestry in ${ancestry_list};do\n",
    "        data_dir=${base_dir}/data/${study}/genotype/observed/${ancestry}\n",
    "        /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --memory 2048 \\\n",
    "            --bed ${data_dir}/*bed\\\n",
    "            --bim ${data_dir}/*bim\\\n",
    "            --fam ${data_dir}/*fam\\\n",
    "            --freq \\\n",
    "            --out ${study_dir}/${ancestry}_${base_name}\n",
    "    done\n",
    "done\n",
    "\n",
    "# Get list of variants from all studies\n",
    "for ancestry in ${ancestry_list}; do\n",
    "    for study in ${study_list};do\n",
    "        cat ${base_dir}/data/${study}/genotype/observed/${ancestry}/*bim | \\\n",
    "                perl -lane 'if (($F[0]+0) <= 23) { print $F[1]; }' | \\\n",
    "                sort -u > ${base_dir}/processing/${ancestry}_${base_name}_sorted_variants.txt\n",
    "    done\n",
    "     wc -l ${base_dir}/processing/$ancestry*\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " 1986657 /shared/jmarks/heroin/uhs4/genotype/imputed/003/processing/ha_chr_all_sorted_variants.txt\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAF for 1000G\n",
    "This pipeline is currently set up to handle EUR and AFR populations.\n",
    "#### Autosomes\n",
    "Get 1000G MAF for chromosomes 1–22 (autosomes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EC2 command line (Bash)\n",
    "\n",
    "# Calculate autosome MAFs for 1000G populations\n",
    "for ancestry in ${ancestry_list}; do\n",
    "\n",
    "    if [ $ancestry == \"ea\" ]; then\n",
    "        pop=\"EUR\"\n",
    "    elif [ $ancestry == \"ha\" ]; then\n",
    "        pop=\"AMR\";\n",
    "    else\n",
    "        pop=\"AFR\"\n",
    "    fi\n",
    "    \n",
    "    for chr in {1..22}; do\n",
    "        /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "            --job_name ${pop}_${chr}_MAF \\\n",
    "            --script_prefix ${base_dir}/processing/1000g/${pop}_chr${chr}.maf \\\n",
    "            --mem 6.8 \\\n",
    "            --nslots 1 \\\n",
    "            --priority 0 \\\n",
    "            --program /shared/bioinformatics/software/perl/stats/calculate_maf_from_impute2_hap_file.pl \\\n",
    "                --hap /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr${chr}.hap.gz\\\n",
    "                --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr${chr}.legend.gz \\\n",
    "                --sample /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3.sample \\\n",
    "                --chr ${chr} \\\n",
    "                --out ${base_dir}/processing/1000g/${pop}_chr${chr}.maf \\\n",
    "                --extract ${base_dir}/processing/${ancestry}_${base_name}_sorted_variants.txt \\\n",
    "                --keep_groups ${pop}\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chrX\n",
    "Get 1000G MAF for chromosome 23 (chrX)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bash ###\n",
    "\n",
    "chr=23\n",
    "for ancestry in ${ancestry_list};do\n",
    "\n",
    "    if [ $ancestry == \"ea\" ]\n",
    "    then\n",
    "        pop=\"EUR\"\n",
    "    elif [ $ancestry == \"ha\" ]; then\n",
    "        pop=\"AMR\"\n",
    "    else\n",
    "        pop=\"AFR\"\n",
    "    fi\n",
    "\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name ${pop}_23_MAF \\\n",
    "        --script_prefix ${base_dir}/processing/1000g/${pop}_chr${chr}.maf \\\n",
    "        --mem 6.8 \\\n",
    "        --nslots 1 \\\n",
    "        --priority 0 \\\n",
    "        --program /shared/bioinformatics/software/perl/stats/calculate_maf_from_impute2_hap_file.pl \\\n",
    "            --hap /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chrX_NONPAR.hap.gz\\\n",
    "            --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chrX_NONPAR.legend.gz \\\n",
    "            --sample /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3.sample \\\n",
    "            --chr $chr \\\n",
    "            --out ${base_dir}/processing/1000g/${pop}_chr${chr}.maf \\\n",
    "            --extract ${base_dir}/processing/${ancestry}_${base_name}_sorted_variants.txt \\\n",
    "            --keep_groups ${pop}\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge 1000G chromosomes\n",
    "Only need to perform this if there were multiple chromosomes for which the MAF was calculated—e.g. more than just chrX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bash ###\n",
    "\n",
    "# Merge per chr MAFs for each 1000G population\n",
    "for ancestry in ${ancestry_list};do\n",
    "    if [ $ancestry == \"ea\" ]\n",
    "    then\n",
    "        pop=\"EUR\"\n",
    "    elif [ $ancestry == \"ha\" ]; then\n",
    "        pop=\"AMR\"\n",
    "    else\n",
    "        pop=\"AFR\"\n",
    "    fi\n",
    "    \n",
    "    head -n 1 ${base_dir}/processing/1000g/${pop}_chr1.maf > ${base_dir}/processing/1000g/${pop}_chr_all.maf\n",
    "    tail -q -n +2 ${base_dir}/processing/1000g/${pop}_chr??maf  >> ${base_dir}/processing/1000g/${pop}_chr_all.maf\n",
    "    \n",
    "    wc -l $base_dir/processing/1000g/${pop}_chr_all.maf\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1060871 /shared/jmarks/heroin/uhs4/genotype/imputed/003/processing/1000g/AMR_chr_all.maf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Allele Discordances Check\n",
    "The allele discordances will be resolved by\n",
    "* Flipping allele discordances that are fixed by flipping\n",
    "* Removing SNPs with discordant names\n",
    "* Removing SNPs with discordant positions\n",
    "* Removing allele discordances that are not resolved by flipping\n",
    "* Removing alleles with large deviations from the reference population allele frequencies\n",
    "\n",
    "Given that the allele discordance check was done using a union set of SNPs across all studies within an ancestry group, some of the SNPs logged as discordant for a given study may not actually be in the study. Fortunately, if they are not in a given study they will not interfere with the filtering procedures. Note that the intersection set is used for the final studies merger.\n",
    "\n",
    "#### Autosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bash ###\n",
    "\n",
    "# Run discordance checks for each ancestry group\n",
    "for study in ${study_list}; do\n",
    "    for ancestry in ${ancestry_list};do\n",
    "        if [ $ancestry = \"ea\" ]; then\n",
    "            pop=EUR\n",
    "        elif [ $ancestry = \"ha\" ]; then\n",
    "            pop=AMR\n",
    "        else\n",
    "            pop=AFR\n",
    "        fi\n",
    "\n",
    "       /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "           --job_name ${ancestry}_${study}_crosscheck \\\n",
    "           --script_prefix ${base_dir}/processing/$study/strand_check/${ancestry}_allele_discordance_check \\\n",
    "           --mem 6 \\\n",
    "           --nslots 4 \\\n",
    "           --priority 0 \\\n",
    "           --program \"Rscript /shared/bioinformatics/software/R/check_study_data_against_1000G.R\n",
    "               --study_bim_file ${base_dir}/data/${study}/genotype/observed/${ancestry}/*bim\n",
    "               --study_frq_file ${base_dir}/processing/${study}/strand_check/${ancestry}_chr_all.frq\n",
    "               --ref_maf_file ${base_dir}/processing/1000g/${pop}_chr_all.maf\n",
    "               --out_prefix ${base_dir}/processing/${study}/strand_check/${ancestry}_allele_discordance\"\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chrX \n",
    "Not necessary to run unless you are only processing chrX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for study in ${study_list}; do\n",
    "#    for ancestry in ${ancestry_list};do\n",
    "#        if [ $ancestry = \"ea\" ]; then\n",
    "#            pop=EUR\n",
    "#        elif [ $ancestry == \"ha\" ]; then\n",
    "#            pop=AMR\n",
    "#        else\n",
    "#            pop=AFR\n",
    "#        fi\n",
    "#\n",
    "#        # chr23 discordance check\n",
    "#        /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#            --job_name ${ancestry}_${study}_crosscheck_chr$chr \\\n",
    "#            --script_prefix ${base_dir}/processing/${study}/strand_check/${ancestry}_allele_discordance_check \\\n",
    "#            --mem 6.8 \\\n",
    "#            --nslots 1 \\\n",
    "#            --priority 0 \\\n",
    "#            --program \"Rscript /shared/bioinformatics/software/R/check_study_data_against_1000G.R\n",
    "#                --study_bim_file ${base_dir}/data/${study}/genotype/observed/${ancestry}/*bim\n",
    "#                --study_frq_file ${base_dir}/processing/${study}/strand_check/${ancestry}_chr23.frq\n",
    "#                --ref_maf_file ${base_dir}/processing/1000g/${pop}_chr23.maf\n",
    "#                --out_prefix ${base_dir}/processing/${study}/strand_check/${ancestry}_allele_discordance\"\n",
    "#    done\n",
    "#done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolving Allele Discordances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply filters\n",
    "for study in ${study_list}; do\n",
    "    for ancestry in ${ancestry_list};do\n",
    "        echo -e \"\\n===============\\nProcessing ${study}_${ancestry}\\n\"\n",
    "        echo \"Making remove list\"\n",
    "        cat <(cut -f2,2 ${base_dir}/processing/${study}/strand_check/${ancestry}_allele_discordance.discordant_alleles_not_fixed_by_strand_flip | tail -n +2) \\\n",
    "            <(cut -f2,2 ${base_dir}/processing/${study}/strand_check/${ancestry}_allele_discordance.at_cg_snps_freq_diff_gt_0.2 | tail -n +2) \\\n",
    "            <(cut -f2,2 ${base_dir}/processing/${study}/strand_check/${ancestry}_allele_discordance.discordant_names | tail -n +2) \\\n",
    "            <(cut -f2,2 ${base_dir}/processing/${study}/strand_check/${ancestry}_allele_discordance.discordant_positions | tail -n +2) \\\n",
    "            <(cut -f2,2 ${base_dir}/processing/${study}/strand_check/${ancestry}_allele_discordance.discordant_alleles_polymorphic_in_study_not_fixed_by_strand_flip | tail -n +2) | \\\n",
    "              sort -u > ${base_dir}/processing/${study}/strand_check/${ancestry}_snps.remove\n",
    "\n",
    "        # Create flip list\n",
    "        echo \"Making flip list\"\n",
    "        comm -23 <(cut -f2,2 ${base_dir}/processing/${study}/strand_check/${ancestry}_allele_discordance.discordant_alleles | tail -n +2 | sort -u) \\\n",
    "                 <(cut -f2,2 ${base_dir}/processing/${study}/strand_check/${ancestry}_allele_discordance.discordant_alleles_not_fixed_by_strand_flip | tail -n +2 | sort -u) \\\n",
    "                 > ${base_dir}/processing/${study}/strand_check/${ancestry}_snps.flip\n",
    "\n",
    "        # Apply filters\n",
    "        /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --memory 2048 \\\n",
    "            --bed     ${base_dir}/data/${study}/genotype/observed/${ancestry}/*bed \\\n",
    "            --bim     ${base_dir}/data/${study}/genotype/observed/${ancestry}/*bim \\\n",
    "            --fam     ${base_dir}/data/${study}/genotype/observed/${ancestry}/*fam \\\n",
    "            --exclude ${base_dir}/processing/${study}/strand_check/${ancestry}_snps.remove \\\n",
    "            --flip    ${base_dir}/processing/${study}/strand_check/${ancestry}_snps.flip \\\n",
    "            --make-bed \\\n",
    "            --out     ${base_dir}/processing/${study}/${ancestry}_filtered\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```\n",
    " wc -l $base_dir/processing/*/*bim\n",
    "1986620 /shared/jmarks/heroin/uhs4/genotype/imputed/003/processing/uhs4/ha_filtered.bim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove monomorphic variants\n",
    "Monomorphic variants prevent MIS from accepting the genotype data. In this case, an arbitrarily small MAF is set that is smaller than the lower bound for these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Bash ###\n",
    "\n",
    "# Apply filters\n",
    "for study in ${study_list}; do\n",
    "    for ancestry in ${ancestry_list};do\n",
    "        geno_dir=${base_dir}/processing/${study}\n",
    "\n",
    "        /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --memory 2048 \\\n",
    "            --bfile ${geno_dir}/${ancestry}_filtered \\\n",
    "            --maf 0.000001 \\\n",
    "            --make-bed \\\n",
    "            --out ${geno_dir}/${ancestry}_filtered_mono\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "wc -l $base_dir/processing/*/*mono.bim\n",
    "    1767028 /shared/jmarks/heroin/uhs4/genotype/imputed/003/processing/uhs4/ha_filtered_mono.bim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNP intersection\n",
    "Only run if merging multiple data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#studies=($study_list)  #studies=(UHS1 UHS2 UHS3_v1-2 UHS3_v1-3) # array of study names\n",
    "#num=${#studies[@]}\n",
    "#\n",
    "## Get intersection set\n",
    "#for ancestry in ${ancestry_list};do\n",
    "#    bim_files=()\n",
    "#    for (( i=0; i<${num}; i++ ));do\n",
    "#        bim_files+=(${base_dir}/processing/${studies[$i]}/${ancestry}_filtered_mono.bim)\n",
    "#    done\n",
    "#    \n",
    "#    echo -e \"\\nCalculating intersection between $ancestry ${study_list}...\\n\"\n",
    "#    sort ${bim_files[@]} | uniq -dc | awk -v num=$num '$1 == num {print $3}' \\\n",
    "#        > ${base_dir}/processing/intersect/${ancestry}_variant_intersection.txt\n",
    "#\n",
    "#    # Make new PLINK binary file sets\n",
    "#    for study in ${studies[@]}; do\n",
    "#        /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "#            --noweb \\\n",
    "#            --bfile ${base_dir}/processing/${study}/${ancestry}_filtered_mono \\\n",
    "#            --extract ${base_dir}/processing/intersect/${ancestry}_variant_intersection.txt \\\n",
    "#            --make-bed \\\n",
    "#            --out ${base_dir}/processing/intersect/${study}_${ancestry}_filtered_snp_intersection\n",
    "#    done\n",
    "#done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```wc -l *txt\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge test\n",
    "If merging multiple datasets together:\n",
    "\n",
    "As a final check to confirm that our data sets are all compatible, a PLINK file set merge is conducted. If any issues persist then an error will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for ancestry in $ancestry_list;do\n",
    "#\n",
    "#    echo \"Creating $ancestry merge-list\"\n",
    "#    touch ${base_dir}/processing/intersect/${ancestry}_merge_list.txt\n",
    "#    for study in $study_list;do\n",
    "#        echo ${base_dir}/processing/intersect/${study}_${ancestry}_filtered_snp_intersection >>\\\n",
    "#             ${base_dir}/processing/intersect/${ancestry}_merge_list.txt\n",
    "#    done\n",
    "#\n",
    "## Merge file sets\n",
    "#    echo -e \"\\n\\n======== ${ancestry} ========\\n\\n\"\n",
    "#    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "#        --noweb \\\n",
    "#        --memory 4000 \\\n",
    "#        --merge-list ${base_dir}/processing/intersect/${ancestry}_merge_list.txt \\\n",
    "#        --make-bed \\\n",
    "#        --out ${base_dir}/processing/intersect/${ancestry}_studies_merged\n",
    "#done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " wc -l *merged.bim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation preparation for Michigan Imputation Server\n",
    "Visit the [MIS Getting Started Webpage](https://imputationserver.sph.umich.edu/start.html#!pages/help) for more information about the preparing the data for upload to MIS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCF File Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split by chr and remove any individuals with missing data for whole chr\n",
    "\n",
    "## if merged data sets together\n",
    "#for ancestry in $ancestry_list;do\n",
    "#    # Remove SNPs\n",
    "#    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "#        --noweb \\\n",
    "#        --memory 4000 \\\n",
    "#        --bfile ${base_dir}/processing/intersect/${ancestry}_studies_merged \\\n",
    "#        --chr ${chr} \\\n",
    "#        --mind 0.99 \\\n",
    "#        --make-bed \\\n",
    "#        --out ${base_dir}/processing/impute_prep/${ancestry}_chr${chr}_for_phasing \n",
    "#done > ${base_dir}/processing/impute_prep/chr_splitting.log \n",
    "\n",
    "## if NO merging was done\n",
    "for ancestry in $ancestry_list;do\n",
    "    for chr in {1..23};do\n",
    "        # Remove SNPs\n",
    "        /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --memory 4000 \\\n",
    "            --bfile ${base_dir}/processing/$study/${ancestry}_filtered_mono \\\n",
    "            --chr ${chr} \\\n",
    "            --mind 0.99 \\\n",
    "            --make-bed \\\n",
    "            --out ${base_dir}/processing/impute_prep/${ancestry}_chr${chr}_for_phasing \n",
    "    done\n",
    "done > ${base_dir}/processing/impute_prep/chr_splitting.log \n",
    "\n",
    "for ancestry in $ancestry_list; do\n",
    "    grep removed $base_dir/processing/impute_prep/$ancestry*log |\n",
    "        perl -lne '/(\\d+)(\\speople)/;\n",
    "             $mycount += $1; \n",
    "             print $mycount if eof'  > $base_dir/processing/impute_prep/$ancestry.removed\n",
    "    any_removed=$(cat $base_dir/processing/impute_prep/$ancestry.removed)\n",
    "    if [ \"$any_removed\" == 0 ]; then\n",
    "        echo \"No subjects removed\"\n",
    "    else\n",
    "        echo \"Some subjects removed\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: No subjects were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EC2 command line #\n",
    "\n",
    "for chr in {1..23};do\n",
    "    for ancestry in ${ancestry_list};do\n",
    "        final_dir=${base_dir}/processing/impute_prep/${ancestry}\n",
    "        mkdir $final_dir\n",
    "        /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --memory 5000 \\\n",
    "            --bfile ${final_dir}/../${ancestry}_chr${chr}_for_phasing \\\n",
    "            --output-chr M \\\n",
    "            --set-hh-missing \\\n",
    "            --recode vcf bgz \\\n",
    "            --out ${final_dir}/${ancestry}_chr${chr}_final\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer the *.vcf.gz files to local machine (per chromosome) and then upload to MIS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Michigan Imputation Server (MIS)\n",
    "\n",
    "### Uploading parameters\n",
    "These are the parameters that were selected on MIS.\n",
    "\n",
    "__Name__: UHS4_HA\n",
    "\n",
    "__Reference Panel__ 1000G Phase 3 v5\n",
    "\n",
    "__Input Files__ File Upload <br>\n",
    "\n",
    "* Select Files - select VCF (.gz) files that were downloaded to local machine from cloud. <br>\n",
    "\n",
    "__Phasing__: ShapeIT v2.r790 (unphased) \n",
    "\n",
    "__Population__: AMR\n",
    "\n",
    "__Mode__: Quality Control & Imputation\n",
    "\n",
    "* I will not attempt to re-identify or contact research participants.\n",
    "* I will report any inadvertent data release, security breach or other data management incident of which I become aware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Imputed Results from MIS\n",
    "First, download the data form the Michigan Imputation Server (MIS) by clicking on the link provided in the email they send out to alert you that your data has finished. Here you will find commands for downloading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HA\n",
    "The zip files from Michigan Imputation Server (MIS) need to be inflated before you can begin working with them. They require a passcode that is sent by MIS to email.\n",
    "* password: HWNevtQW9o2s)f\n",
    "\n",
    "Then, inflate imputation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestry=ha\n",
    "passW=\"'HWNevtQW9o2s)f'\"\n",
    "cd /shared/data/studies/heroin/uhs4/genotype/imputed/003/final\n",
    "\n",
    "# QC-results\n",
    "wget https://imputationserver.sph.umich.edu/share/results/4bcb8d82891abd87b155c91c7b8abd85/qcreport.html\n",
    "\n",
    "# SNP Statistics\n",
    "wget https://imputationserver.sph.umich.edu/share/results/8ab8b51b7903f786b03c9c1e4bcc8853/statistics.txt\n",
    "\n",
    "# Logs\n",
    "wget https://imputationserver.sph.umich.edu/share/results/d0b314980139987d36e238fbc6c8949f/chr_1.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/61e53f13f34089b16085c9172dd93c2e/chr_10.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/ec77a7f2b8806729a3e74ccf10a269c5/chr_11.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/1be6ee52364cb9a4f00d493d31f1ffc8/chr_12.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/bdc465b70cdf617366f53dfada699104/chr_13.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/b12002ee2d1baeb398d349c601baf5e8/chr_14.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/a93913dbda0d905b6f964bd1bc9051cf/chr_15.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/b18d47a848f6074a9ef39736585af57c/chr_16.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/24f743ce71f71a9364025a7826d94421/chr_17.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/8f8da2f566b2ab4e6fefdf91aeb9d3ab/chr_18.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/1df86a2c718e9ed550a61768bcbe4c72/chr_19.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/5e1d5c88617c0a75e8b4c0490e8d231d/chr_2.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/95fd11159636a17cf5260d2056ec772d/chr_20.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/de22fe482882ef6a59ebe62bc900a564/chr_21.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/a93a690483161107229b6ca80b62f2d0/chr_22.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/2b1792ee6d0f91999e9715411bb2e39d/chr_3.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/638351fc2e27fdcfd3eb90b6370f5d0e/chr_4.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/5b74f03ed1b9a568ec0894f5f45d5de0/chr_5.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/9bf8d4405a08feb15f70e9aca31aabd5/chr_6.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/fd4618a636df7b52a5837fb281d56887/chr_7.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/46244002c4e5129c15eadaf028ecfe96/chr_8.log\n",
    "wget https://imputationserver.sph.umich.edu/share/results/d3910353666401dd4c799dfa159a9a1c/chr_9.log\n",
    "\n",
    "\n",
    "# Imputation Results\n",
    "wget https://imputationserver.sph.umich.edu/share/results/f275e8bd516eb186e4e858aeafe2adc1/chr_1.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/6228d72316f4dfe80ba28f49063f4747/chr_10.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/ec7de76d2c489481981981ea3f813a9f/chr_11.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/c7ba9b2dfaf64456dcf0330e9421c765/chr_12.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/4e2f3300e5c657ec39db68fad83dc357/chr_13.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/1cd67e3ed12de7a920088df656d7cd1d/chr_14.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/52011057dfb5711648cbe028c8297d1a/chr_15.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/4d46bac2ac6cb6f0074e4d13f215e775/chr_16.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/e3cfb64b884cf63fd40ab538c87073ba/chr_17.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/2ffa9e3633a8f001903e31e4d82f071e/chr_18.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/cd525701612d2912c54a5a705ccdd3c3/chr_19.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/aa87a9a331a35f3770eeca62256dfee8/chr_2.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/1e21909d38610cd7080f80f2aa25ee9a/chr_20.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/b602439757554250f6b2c57b3d9d5b9c/chr_21.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/9e8db03239d587e1115873a0a17736cf/chr_22.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/c193d13a8209191b50c8560efd347c05/chr_3.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/a9c2edba3d39d7d8cb7fe47b859be9bc/chr_4.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/96be3d359917bf5f8e4518afb2d5a831/chr_5.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/e0033490d0c7b68898d8b53aaa684928/chr_6.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/221e31dfeb58b9910b4c2f45f6194175/chr_7.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/c41a289bb681e763b601ee4c57932889/chr_8.zip\n",
    "wget https://imputationserver.sph.umich.edu/share/results/da92e64ab2288ed492a0ad71cd04bbd/chr_9.zip\n",
    "\n",
    "# paste code above into bash script called download_data\n",
    "/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name ${ancestry}_impute_down \\\n",
    "    --script_prefix ${ancestry}_impute_download \\\n",
    "    --mem 6.8 \\\n",
    "    --nslots 7 \\\n",
    "    --priority 0 \\\n",
    "    --program bash download_data_${ancestry}\n",
    "\n",
    "\n",
    "# inflate chr results\n",
    "for file in *zip;do\n",
    "    let mylen=${#file}-4\n",
    "    chr=${file:0:$mylen}\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name ${ancestry}_unzip_$chr \\\n",
    "        --script_prefix ${ancestry}_unzip \\\n",
    "        --mem 6.8 \\\n",
    "        --nslots 2 \\\n",
    "        --priority 0 \\\n",
    "        --program unzip -P $passW $file\n",
    "done\n",
    "\n",
    "## inflate chr results\n",
    "#/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#    --job_name ${ancestry}_unzip \\\n",
    "#    --script_prefix ${ancestry}_unzip \\\n",
    "#    --mem 6.8 \\\n",
    "#    --nslots 1 \\\n",
    "#    --priority 0 \\\n",
    "#    --program unzip -P $passW *zip \n",
    "# we can remove the original imputed data from MIS after we inflate the zip files\n",
    "rm -rf *zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/rti-heroin/uhs4/data/genotype/imputed/ha\n",
    "#for ancestry in {aa,ea};do\n",
    "for ancestry in {ha};do\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name ${ancestry}_upload \\\n",
    "        --script_prefix ${ancestry}_upload \\\n",
    "        --mem 6.8 \\\n",
    "        --nslots 1 \\\n",
    "        --priority 0 \\\n",
    "        --program aws s3 sync ${ancestry} s3://rti-heroin/uhs4/data/genotype/imputed/${ancestry}/\n",
    "done\n",
    "\n",
    "ancestry=ha\n",
    "aws s3 sync . s3://rti-heroin/uhs4/data/genotype/imputed/${ancestry}/\n",
    "#for chr in {1..22}; do\n",
    "#    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#        --job_name chr$chr.s3.upload.info \\\n",
    "#        --script_prefix chr$chr.s3.upload.info \\\n",
    "#        --mem 6.8 \\\n",
    "#        --nslots 2 \\\n",
    "#        --priority 0 \\\n",
    "#        --program aws s3 cp chr$chr.info.gz s3://rti-heroin/uhs4/data/genotype/imputed/${ancestry}/chr$chr.info.gz\n",
    "#\n",
    "#    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#        --job_name chr$chr.s3.upload.tbi \\\n",
    "#        --script_prefix chr$chr.s3.upload.tbi \\\n",
    "#        --mem 6.8 \\\n",
    "#        --nslots 2 \\\n",
    "#        --priority 0 \\\n",
    "#        --program aws s3 cp chr$chr.dose.vcf.gz.tbi s3://rti-heroin/uhs4/data/genotype/imputed/${ancestry}/chr$chr.dose.vcf.gz.tbi\n",
    "#\n",
    "#    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#        --job_name chr$chr.s3.upload.dose \\\n",
    "#        --script_prefix chr$chr.s3.upload.dose \\\n",
    "#        --mem 6.8 \\\n",
    "#        --nslots 2 \\\n",
    "#        --priority 0 \\\n",
    "#        --program aws s3 cp chr$chr.dose.vcf.gz s3://rti-heroin/uhs4/data/genotype/imputed/${ancestry}/chr$chr.dose.vcf.gz\n",
    "#done\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

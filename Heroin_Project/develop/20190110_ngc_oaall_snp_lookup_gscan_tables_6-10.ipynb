{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension of NGC Heroin OAall Results \n",
    "**Author:** Jesse Marks\n",
    "\n",
    "We have preliminary results from a very large-scale GWAS for cigarette smoking and alcohol consumption phenotypes. We will search for those SNPs in our NGC meta-analysis results. Supplemental tables S6-S10 are here:\n",
    "`\\rcdcollaboration01.rti.ns\\GxG\\Analysis\\GSCAN\\shared MS version 1\\`\n",
    "\n",
    "The phenotypes of interest to us include:\n",
    "\n",
    "1) **Age of smoking initiation (AI)** - supplemental table 6\n",
    "\n",
    "2) **Cigarettes per day (CPD)**- supplemental table 7\n",
    "\n",
    "3) **Smoking cessation (SC)** - supplemental table 8\n",
    "\n",
    "4) **smoking initiation (SI)** - supplemental table 9\n",
    "\n",
    "5) **Drinks Per Week (DPW)** - supplemental table 10\n",
    "\n",
    "We are interested in seeing whether these associations extend over to opioid addiction. The NGC OAall meta-analysis results are located on the share drive at:\n",
    "`//rcdcollaboration01.rti.ns/Heroin_Public_Data/NGC GWAS/meta/oaall/061.adaa+cats+coga+decode+kreek+uhs+vidus+yale-penn.aa+ea`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data + Create SNP list\n",
    "The data are located on the share drive, so there is no need to download them from S3. Create a list of SNPs for the lookup from the GSCAN Excell sheet. Copy the SNPs from each of the five Excell sheets (supplemental tables) into separate files and then combine them while removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## local ##\n",
    "\n",
    "# Create directory structure locally\n",
    "cd ~/Desktop/Projects/heroin/ngc/gscan_lookup\n",
    "\n",
    "# populate these files with the SNPs from respective Excel sheets\n",
    "touch age_of_initiation.tsv  cig_per_day.tsv  smoking_cessation.tsv  smoking_initiation.tsv drink_week.tsv\n",
    "wc -l *tsv\n",
    "\"\"\"\n",
    "   11 age_of_initiation.tsv\n",
    "   56 cig_per_day.tsv\n",
    "  101 drink_week.tsv\n",
    "   25 smoking_cessation.tsv\n",
    "  377 smoking_initiation.tsv\n",
    "  570 total\n",
    "\"\"\"\n",
    "\n",
    "# combine SNPs into one file, make sure SNPs are not listed twice\n",
    "head -1 age_of_initiation.tsv > combined_snp_list.tsv\n",
    "for file in age* cig* smoking* drink*;do\n",
    "    tail -n +2 $file >> combined_snp_list.tsv\n",
    "done\n",
    "\n",
    "# filter so that there are no duplicated SNPs (no header either)\n",
    "tail -n +2 combined_snp_list.tsv | sort -u > combined_snp_list_filtered.tsv\n",
    "\n",
    "# convert to 1000g_p3 format\n",
    "awk '{print $3\":\"$2\":\"$4\":\"$5\"\\t\"$1}' combined_snp_list_filtered.tsv > combined-snp_list-filtered-1000g_p3-chr.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "wc -l combined-snp_list-filtered-1000g_p3-chr.tsv\n",
    "557 combined-snp_list-filtered-1000g_p3-chr.tsv\n",
    "\n",
    "head combined-snp_list-filtered-1000g_p3-chr.tsv\n",
    "rs12027999:154206358:T:C        1\n",
    "rs2072659:154548521:C:G 1\n",
    "rs45444697:155034632:C:G        1\n",
    "rs10753661:165119792:G:A        1\n",
    "rs28680958:173848808:G:A        1\n",
    "rs2901785:174104743:G:A 1\n",
    "rs34973462:175993820:C:T        1\n",
    "rs147052174:179783167:G:T       1\n",
    "rs3820277:18436657:G:T  1\n",
    "rs35656245:190957480:G:A        1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNP lookup\n",
    "I need to create a dictionary of the GSCAN SNPs and then see if each SNP in the meta-analysis is in the dictionary. I think this makes more sense than vice-versa; in particular, creating a dictionary for each SNP in the meta-analysis and then searching to see if the GSCAN SNPs are in the dictionary. This latter strategy would require a large amount of memory to create the Python dictionary. I think the former strategy makes more computational sense.\n",
    "\n",
    "Also note that there are some SNPs in the meta-analysis which have the format of chr:position:a1:a2 instead of rsid:position:a1:a2. I think the reason is that these SNPs of the former format did not have an associated rsID available. If a GSCAN SNP is not found in the lookup, then we need to output the SNPs that were not found and deal with those later. It might be the case that they we have to convert them from rsid:position:a1:a2 format to chr:position:a1:a2 and then perform the search again with just these SNPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs12027999:154206358:T:C\t1\n",
      "\n",
      "MarkerName\tCHR\tPOS\tAllele1\tAllele2\tEffect\tStdErr\tP-value\n",
      " 1:178757976:-:CTTTCT\t1\t178757976\t-\tctttct\t0.0639\t0.0574\t0.2653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Python3 ###\n",
    "\"\"\"\n",
    "*SNP lookup*\n",
    "\n",
    "    Make sure the IDs are of the same format for the snp-list\n",
    "    and the IDs in the meta-analysis results. e.g. 1000g_p3 or rsID only\n",
    "\"\"\"\n",
    "import gzip\n",
    "\n",
    "################################################################################\n",
    "date = \"20190110\"  # enter today's date\n",
    "#ancestry = \"ea\"\n",
    "\n",
    "#if ancestry==\"aa\":\n",
    "#    pop = \"afr\"\n",
    "#elif ancestry==\"ea\":\n",
    "#    pop = \"eur\"\n",
    "#else:\n",
    "#    pop = \"afr+eur\"\n",
    "\n",
    "## dict to hold gscan snps and the number of times they were found.\n",
    "## we can tell which SNPs did not show up in any of the meta files\n",
    "gscan_dict =  {}\n",
    "base_dir = \"C:\\\\Users\\\\jmarks\\\\Desktop\\\\gscan_lookup\"\n",
    "snp_list = \"{}\\\\combined-snp_list-filtered-1000g_p3-chr.tsv\".format(base_dir)\n",
    "\n",
    "#for chrom in range(1,23):\n",
    "out_file = \"{}\\\\results\\\\{}-ngc-meta-analysis-aa+ea.maf_gt_0.03.rsq_gt_0.3-gscan-lookup.txt\".format(base_dir, date)\n",
    "results = \"{}\\\\adaa+cats+coga+decode+kreek+uhs+vidus+yale-penn.aa+ea.maf_gt_0.03.rsq_gt_0.3.fuma.gz\".format(base_dir)\n",
    "not_found = \"{}\\\\results\\\\{}-ngc-meta-analysis-gscan-snps-not-found\".format(base_dir, date)\n",
    "################################################################################\n",
    "\n",
    "with gzip.open(results, 'rt') as metF, open(snp_list) as gscanF, open(out_file, \"wt\") as outF:\n",
    "    gscan_line = gscanF.readline()\n",
    "    met_head = metF.readline()\n",
    "    met_line = metF.readline()\n",
    "    print(gscan_line)\n",
    "    print(met_head, met_line)\n",
    "\n",
    "    outF.write(met_head)\n",
    "\n",
    "    ## create a dictionary containing the gscan snps\n",
    "    if len(gscan_dict) == 0:\n",
    "        while gscan_line:\n",
    "            key = gscan_line.split()[0]\n",
    "            gscan_dict[key] = 0\n",
    "            gscan_line = gscanF.readline()\n",
    "\n",
    "\n",
    "    while met_line:\n",
    "        met_id = met_line.split()[0] # the 1000g_p3 ID in the meta-analysis\n",
    "\n",
    "        if met_id in gscan_dict:\n",
    "            gscan_dict[met_id] += 1\n",
    "            outF.write(met_line)\n",
    "        met_line = metF.readline()\n",
    "        \n",
    "# report SNPs not found\n",
    "with open(not_found, \"wt\") as notF:\n",
    "    for key, value in gscan_dict.items():\n",
    "        if value==0:\n",
    "            notF.write(key + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    " ~/Desktop/gscan_lookup/results\n",
    "$ head *\n",
    "==> 20190110-ngc-meta-analysis-aa+ea.maf_gt_0.03.rsq_gt_0.3-gscan-lookup.txt <==\n",
    "MarkerName      CHR     POS     Allele1 Allele2 Effect  StdErr  P-value\n",
    "rs4912332:58815243:C:T  1       58815243        t       c       0.0095  0.0172  0.5828\n",
    "rs10914684:33795572:G:A 1       33795572        a       g       0.0007  0.0232  0.9759\n",
    "rs34973462:175993820:C:T        1       175993820       t       c       -0.0579 0.0187  0.001976\n",
    "rs951740:44011737:G:A   1       44011737        a       g       -0.0110 0.0183  0.5491\n",
    "rs11264100:35591626:A:G 1       35591626        a       g       -0.0178 0.0272  0.513\n",
    "rs3820277:18436657:G:T  1       18436657        t       g       0.0250  0.0180  0.1645\n",
    "rs12088813:66407700:A:C 1       66407700        a       c       -0.0502 0.0218  0.02126\n",
    "rs35656245:190957480:G:A        1       190957480       a       g       -0.0154 0.0199  0.4406\n",
    "rs12563365:236872829:G:A        1       236872829       a       g       -0.0089 0.0193  0.6425\n",
    "\n",
    "==> 20190110-ngc-meta-analysis-gscan-snps-not-found <==\n",
    "rs147052174:179783167:G:T\n",
    "rs184083806:96981736:T:C\n",
    "rs2145451:29316842:T:C\n",
    "rs28929474:94844947:C:T\n",
    "rs4886550:78243579:A:G\n",
    "rs12442563:83893243:G:T\n",
    "rs72836318:44121579:T:C\n",
    "rs143200968:41338847:G:C\n",
    "rs145580088:41342842:A:G\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

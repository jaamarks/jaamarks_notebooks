{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing for dbGaP phs000634.v1.p1.c1 (Lung Cancer in Never Smokers)\n",
    "\n",
    "\n",
    "**Author:** Jesse Marks\n",
    "\n",
    "This document logs several components of data processing for [A genome wide study of lung cancer in never smokersÂ (phs000634.v1.p1)](https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs000634.v1.p1) including \n",
    "\n",
    "* Data retrieval\n",
    "* Genotype data quality control.\n",
    "\n",
    "The purpose of processing these data are to prepare them for further processing and analysis steps such as haplotype phasing, imputation, and genome-wide association analysis.\n",
    "\n",
    "**Note**: the `Illumina  HumanOmniExpress-12v1_H.` chip was used to genotype the subjects in this study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software and tools\n",
    "The software and tools used for processing these data are\n",
    "* Windows 10 with [Cygwin](https://cygwin.com/) installed \n",
    "* [Aspera Connect](http://downloads.asperasoft.com/downloads)\n",
    "* [KING](http://people.virginia.edu/~wc9c/KING/)\n",
    "* [PLINK v1.9 beta 3.45](https://www.cog-genomics.org/plink/) \n",
    "* [SRA toolkit](https://www.ncbi.nlm.nih.gov/sra/docs/toolkitsoft/)\n",
    "* [STRUCTURE](https://web.stanford.edu/group/pritchardlab/structure.html)\n",
    "* [R v3.2.3](https://www.r-project.org/)\n",
    "* [iGraph (R package)](http://igraph.org/r/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retieval\n",
    "### Genotypes and phenotypes\n",
    "The genotype and phenotype data were downloaded from dbGaP to a local machine, decrypted (most), and then transfered to [Amazon Simple Storage Service (S3)](https://aws.amazon.com/s3/?sc_channel=PS&sc_campaign=acquisition_US&sc_publisher=google&sc_medium=s3_b&sc_content=s3_e&sc_detail=amazon%20s3&sc_category=s3&sc_segment=192085379926&sc_matchtype=e&sc_country=US&s_kwcid=AL!4422!3!192085379926!e!!g!!amazon%20s3&ef_id=Wd4L7QAAAFUPlk0C:20180115144528:s). \n",
    "Some of the data were not decrypted locally and will thus need to be decrypted on [Amazon Elastic Compute Cloud (EC2)](https://aws.amazon.com/ec2/?sc_channel=PS&sc_campaign=acquisition_US&sc_publisher=google&sc_medium=ec2_b_rlsa_hv&sc_content=ec2_e&sc_detail=amazon%20ec2&sc_category=ec2&sc_segment=213206985258&sc_matchtype=e&sc_country=US&s_kwcid=AL!4422!3!213206985258!e!!g!!amazon%20ec2&ef_id=Wd4L7QAAAFUPlk0C:20180115144653:s).\n",
    "The data were downloaded using the Aspera Connect Browser plug-in. Note that these data require authorized access, so the [authorized access portal](https://dbgap.ncbi.nlm.nih.gov/dbgap/aa/wga.cgi?page=login) must be used (request login information from Eric Johnson). \n",
    "\n",
    "The data files downloaded from dbGaP are encrypted and thus will need to be decrypted using `vdb-decrypt` from the SRA toolkit [(instructions here)](https://www.ncbi.nlm.nih.gov/books/NBK63512/#_Download_Points_often_Ignored_When_Decry_).\n",
    "\n",
    "**Note**: As a way to conserve space, certain genotype data for a given study are excluded from download. General criteria are:\n",
    "* Exclude imputed data\n",
    "* Exclude individual format genotype calls (if the matrix and/or PLINK binary fileset format is available)\n",
    "* Exclude index files that lay out the directory structure for the individual format genotype calls\n",
    "* Exclude raw array data if genotype calls are available\n",
    "\n",
    "To assess which files may be unnecessary for download, the study report available through the [public FTP download site]() (accessible via the dbGaP landing page for a given study accession) should be examined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General directory structure setup\n",
    "\n",
    "After locally downloading, all of the dbGaP data should be organized within a directory called `ncbi`. For each cohort, its data needs to be placed within a subdirectory of the format dbGaP-x where x signifies the project number of the download (not to be confused with the download request number). The project number can be found on the \"Downloads\" tab of the dbGaP authorized access portal. Also in that tab is the link to download the repository key file. This file should be placed in the top level of the project folder then imported using [vdb-config](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=toolkit_doc&f=std). Although each download request provides a link to download the repository key, only one key file is needed per project.\n",
    "\n",
    "**Note:** File names longer than the allowed Windows file name character limit will not decrypt and must be renamed before decrypting. It is highly recommended to check the file names after decryption to ensure that they successfully decrypted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Local machine cygwin terminal ##\n",
    "\n",
    "# Create NCBI and project specific directory\n",
    "mkdir -p /cygdrive/c/Users/jmarks/ncbi/dbGaP-2556\n",
    "\n",
    "# Download data and repo key to the appropriate project directory \n",
    "cd /cygdrive/c/Users/jmarks/ncbi/dbGaP-2556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Web Services\n",
    "#### S3 Directory Structure  \n",
    "For each dbGaP study, we will use the directory structure setup outlined on [GitHub for AWS S3](https://github.com/RTIInternational/bioinformatics/blob/master/documentation/aws_s3_data_organization.md).\n",
    "\n",
    "#### Configure AWS \n",
    "The settings for using the AWS CLI need to be configured before interacting with AWS. These configurations include security credentials and the default region. For more information on this process, see [here](http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html).\n",
    "\n",
    "**Note:** these only need to be configured once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Local machine (Cygwin)\n",
    "aws configure\n",
    "\n",
    "AWS Access Key ID [None]: AKIAJONBCJHOJSW2PFJA\n",
    "AWS Secret Access Key [None]:  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\n",
    "Default region name [None]: us-east-1\n",
    "Default output format [None]: text  # could be json, text, or table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify an EBS Volume from the Command Line\n",
    "The following example demonstrates how an EBS volume can be modified from the command line using hte AWS CLI. An example is detailed [here](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/cli-modify.html).To make use of the new storage capacity after modifying the ebs volume you need to [extend a linux file system after resizing](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/recognize-expanded-volume-linux.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "\n",
    "# first configure AWS. you will be prompted to enter the following information\n",
    "# the keys and default region can be found in the config file on the cluster launcher\n",
    "# note, these keys are not accurate, they are just examples of what one would see\n",
    "aws configure\n",
    "'''\n",
    "AWS Access Key ID [None]: AKIAI44QH8DHBEXAMPLE\n",
    "AWS Secret Access Key [None]: je7MtGbClwBF/2Zp9Utk/h3yCo8nvbEXAMPLEKEY\n",
    "Default region name [None]: us-east-1\n",
    "Default output format [None]: text\n",
    "'''\n",
    "\n",
    "# this command would modify the volume to 1800 (remove dry-run to actually apply)\n",
    "aws ec2 modify-volume --dry-run --volume-id vol-038921893392154fa --size 1800  \n",
    "\n",
    "# extend file system to the new volume capacity.\n",
    "sudo resize2fs /dev/xvdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genotype processing\n",
    "## Quality Control Sample Tracking\n",
    "The table below provides statistics on variants and subjects filtered during each step of the QC process.\n",
    "\n",
    "## Initial QC\n",
    "\n",
    "| QC procedure                         | Variants removed | Variants retained | Subjects removed | Subjects retained |\n",
    "|--------------------------------------|------------------|-------------------|------------------|-------------------|\n",
    "| Initial dbGaP dataset                |0                 |656,891            |0                 |1998               |\n",
    "| Genome build 37 and dbGaP 138 update |1,649             |655,242            |0                 |1998               |\n",
    "| Duplicate rsID filtering             |0                 |655,242            |0                 |1998               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## European Ancestry\n",
    "### Autosome statistics\n",
    "This table includes filtering statistics prior to merging with chrX.\n",
    "\n",
    "\n",
    "| QC procedure                                    | Variants removed | Variants retained | Subjects removed | Subjects added | Subjects retained |\n",
    "|-------------------------------------------------|------------------|-------------------|------------------|--------------|-------------------|\n",
    "| Pre-partitioning w/initial procedures (all chr) |0                 |655,242            |0                 |0             |1,998              |\n",
    "| Partitioning to only autosomes                  |1,402             |653,840            |0                 |0             |1,998              |\n",
    "| Remove subjects missing whole autosome data     |0                 |653,840            |0                 |0              |1,998              |\n",
    "| Remove ancestral outliers                       |0                 |653,840            |0                 |0             |1,998              |\n",
    "| Remove sujects with re-assigned ancestry        |0                 |653,840            |0                 |0              |1,998              |\n",
    "| Add subjects re-assigned by STRUCTURE           |0                 |653,840            |0                 |0              |1,998              |\n",
    "| Remove variants with missing call rate > 3%     |1,433             |652,407            |0                 |0              |1,998              |\n",
    "| Remove variants with HWE p < 0.0001             |0                 |652,407            |0                 |0              |1,998              | \n",
    "\n",
    "\n",
    "[call rate](#call-rate) <br/>\n",
    "[HWE](#hardy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChrX statistics\n",
    "**Note:** No chrX statistics to report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged autosome and chrX statistics\n",
    "__Note__: These statistics do not include chrX\n",
    "\n",
    "| QC procedure                                            | Variants removed | Variants retained | Subjects removed | Subjects added | Subjects retained |\n",
    "|---------------------------------------------------------|------------------|-------------------|------------------|----------------------|-------------------|\n",
    "| Merge autosomes and chrX                                |0                 |652,407            |0                 |0                     |1,998              |\n",
    "| Remove subjects with IBD > 0.4, IBS > 0.9               |0                 |652,407            |0                 |0                     |1,998              |\n",
    "| Remove subjects with missing call rate > 3%             |0                 |652,407            |2                 |0                     |1,996              |\n",
    "| Sex discordance filter                                  |0                 |652,407            |0                 |0                     |1,996              |\n",
    "| Excessive homozygosity filter                           |0                 |652,407            |0                 |0                     |1,996              |\n",
    "| Duplicate variant ID filter after 1000G renaming        |0                 |652,407            |0                 |0                     |1,996              |\n",
    "\n",
    "[Duplicates](#variant_dups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EC2 login\n",
    "Login to EC2 master instance. In this case, we use a spot instance called `QCspot`. The compute instance types are `m4.xlarge`. This can be updated with `cfncluster` in the cluster launcher with the command:\n",
    "\n",
    "`cfncluster update QCspot -t default_spot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# local command line\n",
    "ssh -i ~/.ssh/gwas_rsa ec2-user@35.171.207.199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving data from S3 and decompress\n",
    "To avoid writing over the current directory structure, I create a new directory within the directory structure of the other studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "# Retrieve data from S3 and store in EC2\n",
    "cd /shared/data/studies\n",
    "aws s3 cp s3://rti-common/dbGaP/phs000634_lung_cancer/ phs000634_lung_cancer --recursive\n",
    "\n",
    "# create directory structure\n",
    "cd /shared/data/studies/phs000634_lung_cancer/\n",
    "mkdir -p phenotype/{final,processing} \n",
    "mkdir -p genotype/original/{final,processing}\n",
    "\n",
    "# decompress phenotype data and gunzip\n",
    "cp phenotype/unprocessed/* phenotype/processing\n",
    "for f in phenotype/processing/*.gz; do\n",
    "gunzip \n",
    "done &\n",
    "\n",
    "guzip -r phenotype/processing* &\n",
    "\n",
    "\n",
    "# decompress genotype data and gunzip\n",
    "cp genotype/original/unprocessed/* genotype/original/processing &   # job 18962\n",
    "cd /genotype/original/processing\n",
    "for f in *.gz; do\n",
    "tar -xzf $f -C .\n",
    "done &\n",
    "\n",
    "\n",
    "rm *.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming the data** can be done, mainly for convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/phenotype/processing\n",
    "\n",
    "for f in *; do  mv $f $(echo $f | perl -pi -e s/phs.+Smokers_//g); done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exlusion of subjects without phenotype data\n",
    "The `.fam` file may contain more subject IDs than the phenotype file. The subjects without phenotype data are excluded as they provide no benefit for GWA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing\n",
    "\n",
    "mkdir ea\n",
    "\n",
    "# Get EA subject IDs\n",
    "tail -n +12 ../../../Subject_Phenotypes.GRU-MDS.txt | awk '{print $2}' > ../../../ea_subject_ids.txt\n",
    "\n",
    "# Add family IDs\n",
    "grep -f ../../../phenotype/processing/ea_subject_ids.txt \\\n",
    "    matrix/c1/nslc_c1.fam | \\\n",
    "    cut -d ' ' -f 1,2    \\\n",
    "    > ../../../phenotype/processing/ea_subject_ids.keep\n",
    "\n",
    "# Create filtered PLINK filesets\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile  matrix/c1/nslc_c1 \\\n",
    "        --keep ../../../phenotype/processing/ea_subject_ids.keep \\\n",
    "        --make-bed \\\n",
    "        --out ea/genotypes\n",
    "\n",
    "'656891 variants and 1998 people pass filters and QC.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strand orientation conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/ea\n",
    "\n",
    "# Download zip file for Human1M-Duo chip (HumanOmniExpress-12v1_H.zip) from http://www.well.ox.ac.uk/~wrayner/strand/ - includes the following:\n",
    "# Human1M-Duov3_B-b37-v2.strand\n",
    "# Strand-Human1M-Duov3_B-b37.miss\n",
    "# Strand-Human1M-Duov3_B-b37.multiple\n",
    "\n",
    "# Create flip list for use with PLINK\n",
    "perl -lane 'if ($F[4] eq \"-\") { print $F[0]; }' ~/HumanOmniExpress-12v1_H-b37.strand > \\\n",
    " HumanOmniExpress-12v1_H-b37.top_to_plus.flip\n",
    "\n",
    "# Extract chr1 unflipped variants\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --memory 800 \\\n",
    "    --bfile genotypes \\\n",
    "    --chr 1 \\\n",
    "    --make-bed \\\n",
    "    --out chr1_unflipped\n",
    "\n",
    "# Attempt merge with 1000G chr1 data\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --memory 800 \\\n",
    "    --bfile chr1_unflipped \\\n",
    "    --bmerge /shared/data/ref_panels/1000G/2013.05/plink/ALL.chr1 \\\n",
    "    --make-bed \\\n",
    "    --out chr1_unflipped_test\n",
    "'Error: 21966 variants with 3+ alleles present.'\n",
    "\n",
    "# Flip chr1 variants\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --memory 800 \\\n",
    "    --bfile genotypes \\\n",
    "    --chr 1 \\\n",
    "    --flip ~/HumanOmniExpress-12v1_H-b37.top_to_plus.flip \\\n",
    "    --make-bed \\\n",
    "    --out chr1_flipped\n",
    "\n",
    "# Attempt merge with 1000G chr1 data using flipped data\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --memory 800 \\\n",
    "    --bfile chr1_flipped \\\n",
    "    --bmerge /shared/data/ref_panels/1000G/2013.05/plink/ALL.chr1 \\\n",
    "    --make-bed \\\n",
    "    --out chr1_flipped_test\n",
    "\n",
    "'Error: 275 variants with 3+ alleles present.'\n",
    "\n",
    "# Clean up\n",
    "rm chr1_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between the flipped and unflipped merge, the flipped merge produced drastically less errors. As a consequence, I will apply the flip to all chromosomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/ea\n",
    "\n",
    "# Perform final flip\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --memory 800 \\\n",
    "        --noweb \\\n",
    "        --bfile genotypes \\\n",
    "        --flip ~/HumanOmniExpress-12v1_H-b37.top_to_plus.flip \\\n",
    "        --make-bed \\\n",
    "        --out genotypes_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update dbSNP and genome build\n",
    "\n",
    "To ensure that all of the population controls have variant and genomic data in dbSNP 138 and genome build 37 format, I use ID and position mappers to make the updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/ea\n",
    "\n",
    "# Update variant chr \n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile genotypes_plus_flipped \\\n",
    "        --update-chr /shared/common/build_conversion/b37/dbsnp_b138/uniquely_mapped_snps.chromosomes \\\n",
    "        --make-bed \\\n",
    "        --out genotypes_plus_flipped_chr_b37\n",
    "# Note: 655242 values updated.\n",
    "\n",
    "# Update variant chr coordinate\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile genotypes_plus_flipped_chr_b37 \\\n",
    "        --update-map /shared/common/build_conversion/b37/dbsnp_b138/uniquely_mapped_snps.positions \\\n",
    "        --make-bed \\\n",
    "        --out genotypes_plus_flipped_chr_position_b37\n",
    "\n",
    "# Filter to only build 37 uniquely mapped variants\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile genotypes_plus_chr_position_b37 \\\n",
    "        --extract /shared/common/build_conversion/b37/dbsnp_b138/uniquely_mapped_snps.ids \\\n",
    "        --make-bed \\\n",
    "        --out genotypes_b37_dbsnp138_flipped\n",
    "\n",
    "'655242 variants and 1998 people pass filters and QC.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition into autosome and chrX groups\n",
    "I apply QC to autosomes and chrX separately, so separate subdirectories are created for the processing of each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/ea\n",
    "\n",
    "mkdir autosomes chrX\n",
    "\n",
    "# Autosomes\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --bfile genotypes_b37_dbsnp138_flipped \\\n",
    "    --autosome \\\n",
    "    --make-bed \\\n",
    "    --out autosomes/genotypes_b37_dbsnp138_flipped\n",
    "'653840 variants pass'\n",
    "\n",
    "# ChrX (include split PARs)\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --bfile genotypes_b37_dbsnp138_flipped \\\n",
    "    --chr 23,25 \\\n",
    "    --make-bed \\\n",
    "    --out chrX/genotypes_b37_dbsnp138_flipped_unmerged\n",
    "\n",
    "# Combine split chrX and PARs\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --bfile chrX/genotypes_b37_dbsnp138_flipped_unmerged \\\n",
    "    --merge-x \\\n",
    "    --make-bed \\\n",
    "    --out chrX/genotypes_b37_dbsnp138_flipped\n",
    "'243'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Missing autosome data subject filtering\n",
    "We calculate the proportion of missing genotype calls per chromosome using PLINK to assess whether any subjects have data missing for whole autosomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd /shared/data/studies/phs000428_retirement/genotype/original/processing/ea\n",
    "\n",
    "for chr in {1..22}; do\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name ea_${chr} \\\n",
    "        --script_prefix autosomes/chr${chr}_missing_call_rate \\\n",
    "        --mem 3.8 \\\n",
    "        --priority 0 \\\n",
    "        --program  /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --bfile autosomes/genotypes_b37_dbsnp138_flipped \\\n",
    "            --missing \\\n",
    "            --chr $chr \\\n",
    "            --out autosomes/chr${chr}_missing_call_rate\n",
    "done\n",
    "\n",
    "# if the missing call rate is 1 (i.e. all data was missing for that chromosome)\n",
    "for chr in {1..22}; do\n",
    "    tail -n +2 autosomes/chr${chr}_missing_call_rate.imiss | \\\n",
    "        awk '{ OFS=\"\\t\" } { if($6==1){ print $1,$2 } }' >> autosomes/missing_whole_autosome.remove\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case none of the EA subjects had missing autosome data. If subjects ever show up as having missing autosome data then further discussions need to be had on whether these subjects should be removed completely or whether they should only be excluded for the missing chromosomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up \n",
    "    rm autosomes/chr*missing_call_rate*\n",
    "    rm autosomes/missing_whole_autosome.remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate SNPs\n",
    "If multiple rsIDs are present then the one with the better genotype call rate across subjects should be retained. Obtaining the genotype call rates across subjects would need to be calculated using PLINK --missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/ea\n",
    "\n",
    "# Find duplicate rsIDs - cut the rsID field then print out duplicated lines (both/all time)\n",
    "cut -f2,2 autosomes/genotypes_b37_dbsnp138_flipped.bim | sort | uniq -D > autosomes/variant_duplicates.txt\n",
    "\n",
    "wc -l autosomes/variant_duplicates.txt\n",
    "'0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000428_retirement/genotype/original/processing\n",
    "aws s3 cp aa s3://rti-common/dbGaP/phs000428_retirement/genotype/original/processing/aa --recursive --quiet &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Detecting ancestral outliers with STRUCTURE\n",
    "[STRUCTURE](https://web.stanford.edu/group/pritchardlab/structure.html) is a software tool that can be used to identify admixed individuals, among other uses. By comparing the study subjects with the 1000 Genomes Phase 3 reference panel, I can estimate the composition of an individual's ancestry to determine any discrepancies between self-reporting and genetic information. For the study data, I will be comparing the individuals to 3 different superpopulations from 1000 Genomes Phase 3 reference panel\n",
    "\n",
    "* AFR (African)\n",
    "* EAS (East Asian)\n",
    "* EUR (European)\n",
    "\n",
    "### SNP subset selection\n",
    "For compuational efficiency 10,000 SNPs are randomly chosen from the intersection of SNPs in the study data with the three 1000 Genomes superpopulations of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "mkdir structure\n",
    "\n",
    "# Get lists of non-A/T and non-C/G SNPs\n",
    "ancestry=\"ea\"\n",
    "perl -lane 'if (($F[4] eq \"A\" && $F[5] ne \"T\") || ($F[4] eq \"T\" && $F[5] ne \"A\") ||\n",
    "($F[4] eq \"C\" && $F[5] ne \"G\") || ($F[4] eq \"G\" && $F[5] ne \"C\")) { print $F[1]; }' \\\n",
    "${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped.bim | \\\n",
    "    sort -u | \\\n",
    "    grep \"rs\" \\\n",
    "    > structure/no_at_cg_snps.txt\n",
    "\n",
    "\n",
    "# Get list of variants from 1000G\n",
    "mkdir structure/1000g_data\n",
    "/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name merge_1000g_snps \\\n",
    "    --script_prefix structure/1000g_data/merge_1000g_snps \\\n",
    "    --mem 3 \\\n",
    "    --priority 0 \\\n",
    "    --program \"cat /shared/data/ref_panels/1000G/2013.05/plink/ALL.chr{1..22}.bim | \\\n",
    "        cut -f2,2 | \\\n",
    "        sort -u | \\\n",
    "        grep \\\"rs\\\" > structure/1000g_data/1000g_phase3_snps.txt\"\n",
    "\n",
    "\n",
    "\n",
    "study=\"lung_cancer\"\n",
    "\n",
    "# Get SNP overlap between study data and 1000G\n",
    "comm -12 structure/no_at_cg_snps.txt structure/1000g_data/1000g_phase3_snps.txt > structure/${study}_1000g_shared_snps.txt\n",
    "\n",
    "# Select 10,000 random SNPs from study and 1000G overlap\n",
    "perl -ne 'print rand().\"\\t\".$_' structure/${study}_1000g_shared_snps.txt | \\\n",
    "    sort -k1,1 | \\\n",
    "    head -10000 | \\\n",
    "    cut -f2,2 \\\n",
    "    > structure/10k_snp_random_sample.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extract SNP subset PLINK binary filesets for study data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Command line #\n",
    "cd /shared/data/studies/phs000428_retirement/genotype/original/processing\n",
    "\n",
    "# Create ped and map files for study genotype data for SNP subset\n",
    "for ancestry in {ea,aa}; do\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name merge_1000g_snps \\\n",
    "        --script_prefix structure/1000g_data/merge_1000g_snps \\\n",
    "        --mem 4 \\\n",
    "        --priority 0 \\\n",
    "        --program /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --bfile ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped \\\n",
    "            --extract structure/10k_snp_random_sample.txt \\\n",
    "            --snps-only just-acgt \\\n",
    "            --recode \\\n",
    "            --out structure/${ancestry}_10k_snp_random_sample\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extract SNP subset PLINK binary files sets for 1000G data\n",
    "The 05/2013 release of the 1000 Genomes data have been previously processed and converted to PLINK binary fileset format, but the files include all the 1000G individuals. We are interested in only three superpopulations, so we create filesets specifically for each of these groups. It was brought to my attention that 1000G Phase 3 rsIDs may be duplicated across chromosomes potentially causing chromosome merging issues. For that reason, it is typically recommended to process the chromosomes separately initially, then combine post SNP subsetting. Subject IDs with superpopulation classifications are available at\n",
    "\n",
    "`/shared/data/ref_panels/1000G/igsr_samples.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd /shared/data/studies/phs000428_retirement/genotype/original/processing\n",
    "\n",
    "# Ancestry specific directories\n",
    "for pop in {AFR,EAS,EUR}; do\n",
    "    mkdir structure/1000g_data/${pop}\n",
    "done\n",
    "\n",
    "# Get subject IDs by ancestry\n",
    "awk 'BEGIN { FS=\"\\t\"; OFS=\"\\t\" } { if($7==\"African\"){print $1,$1} }'  /shared/data/ref_panels/1000G/igsr_samples.tsv \\\n",
    "    > structure/1000g_data/AFR/AFR_subject_ids.txt\n",
    "awk 'BEGIN { FS=\"\\t\"; OFS=\"\\t\" } { if($7==\"East Asian\"){print $1,$1} }'  /shared/data/ref_panels/1000G/igsr_samples.tsv \\\n",
    "    > structure/1000g_data/EAS/EAS_subject_ids.txt\n",
    "awk 'BEGIN { FS=\"\\t\"; OFS=\"\\t\" } { if($7==\"European\"){print $1,$1} }' /shared/data/ref_panels/1000G/igsr_samples.tsv \\\n",
    "    > structure/1000g_data/EUR/EUR_subject_ids.txt\n",
    "\n",
    "\n",
    "\n",
    "# Make new binary filesets for each 1000G group\n",
    "# only keeping the data from individuals which are from 1 of the three super populations\n",
    "for pop in {AFR,EAS,EUR}; do\n",
    "    for chr in {1..22}; do\n",
    "        /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "            --job_name ${pop}_${chr}_filter \\\n",
    "            --script_prefix structure/1000g_data/${pop}/ancestry_partition_chr${chr} \\\n",
    "            --mem 8 \\\n",
    "            --priority 0 \\\n",
    "            --program /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink  \\\n",
    "                --noweb \\\n",
    "                --memory 10000 \\\n",
    "                --bfile /shared/data/ref_panels/1000G/2013.05/plink/ALL.chr${chr} \\\n",
    "                --keep structure/1000g_data/${pop}/${pop}_subject_ids.txt \\\n",
    "                --make-bed \\\n",
    "                --out structure/1000g_data/${pop}/${pop}.chr${chr}\n",
    "    done\n",
    "done\n",
    "\n",
    "\n",
    "# Apply SNP subset extraction by chr\n",
    "for pop in {AFR,EAS,EUR}; do\n",
    "    for chr in {1..22}; do\n",
    "        /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "            --job_name ${pop}_${chr}_subsample \\\n",
    "            --script_prefix structure/1000g_data/${pop}/ancestry_partition_chr${chr} \\\n",
    "            --mem 7.6 \\\n",
    "            --priority 0 \\\n",
    "            --program /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "                --noweb \\\n",
    "                --memory 7500 \\\n",
    "                --bfile structure/1000g_data/${pop}/${pop}.chr${chr} \\\n",
    "                --extract structure/10k_snp_random_sample.txt \\\n",
    "                --make-bed \\\n",
    "                --out structure/1000g_data/${pop}/${pop}_chr${chr}_10k_snp_random_sample\n",
    "    done\n",
    "done\n",
    "\n",
    "# Create merge lists and merge autosomes for each 1000G population\n",
    "data_dir=structure/1000g_data\n",
    "for pop in {AFR,EAS,EUR}; do\n",
    "    echo \"${data_dir}/${pop}/${pop}_chr1_10k_snp_random_sample\" > ${data_dir}/${pop}/${pop}_autosome_merge_list.txt\n",
    "    for chr in {2..22}; do\n",
    "        echo \"${data_dir}/${pop}/${pop}_chr${chr}_10k_snp_random_sample\" \\\n",
    "        >> ${data_dir}/${pop}/${pop}_autosome_merge_list.txt\n",
    "    done\n",
    "done\n",
    "\n",
    "for pop in {AFR,EAS,EUR}; do\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name ${pop}_merge_plink_filesets \\\n",
    "        --script_prefix structure/1000g_data/${pop}/merge_plink_filesets \\\n",
    "        --mem 4 \\\n",
    "        --priority 0 \\\n",
    "        --program /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --memory 4000 \\\n",
    "            --merge-list structure/1000g_data/${pop}/${pop}_autosome_merge_list.txt \\\n",
    "            --snps-only just-acgt \\\n",
    "            --make-bed \\\n",
    "            --out structure/1000g_data/${pop}/${pop}_all_autosomes_10k_snp_random_sample\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Discrepancy assessment between 1000G and study data\n",
    "\n",
    "As a quality check that the SNP data subsampled from the 1000 Genomes and study data are the same, I will attempt to merge an arbitrarily selected group from each data set using PLINK. If any errors are found, PLINK will generate an error file. Likely causes of errors would be:\n",
    "\n",
    "* SNP genomic coordinates not matching\n",
    "* SNP duplicates found\n",
    "* SNP strand orientation flipped\n",
    "\n",
    "If errors are found the two options for moving forward are\n",
    "\n",
    "1. Re-run the 10,000 SNP subsampling and hope the SNPs chosen do not raise issues\n",
    "2. Remove the problematic SNPs\n",
    "\n",
    "Option #2 is the prefered approach and the one I will be taking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "ancestry=\"ea\"\n",
    "study=\"lung_cancer\"\n",
    "pop=\"EUR\"\n",
    "# Merge EA and EUR genotype files\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --file structure/${ancestry}_10k_snp_random_sample \\\n",
    "    --bmerge structure/1000g_data/${pop}/${pop}_all_autosomes_10k_snp_random_sample \\\n",
    "    --recode \\\n",
    "    --out structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample\n",
    "\n",
    "'''\n",
    "Error: 2 variants with 3+ alleles present.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The attempted merge generated 2 for the EAs. In the case of an unsuccessful merge, the following are common:\n",
    "\n",
    "* Multiple positions found for a variant\n",
    "* Non-biallelic variants found\n",
    "\n",
    "When these occur, a common approach is to exclude variants with multiple positions and see if flipping the non-biallelic variants resolves the second issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "study=\"lung_cancer\"\n",
    "ancestry=\"ea\"\n",
    "pop=\"EUR\"\n",
    "# Get list of multiple position variants\n",
    "grep \"Multiple positions seen for variant\" structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample.log | \\\n",
    "    cut -d\"'\" -f2,2 > structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample.bad_snps.remove\n",
    "\n",
    "# Flip study EA non-biallelic SNPs and remove multi-position variants\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --file structure/${ancestry}_10k_snp_random_sample \\\n",
    "    --exclude structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample.bad_snps.remove \\\n",
    "    --flip structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample.missnp \\\n",
    "    --recode \\\n",
    "    --out structure/${ancestry}_10k_snp_random_sample_retry\n",
    "\n",
    "'''\n",
    "--flip: 2 SNPs flipped.\n",
    "--exclude: 10000 variants remaining.\n",
    "'''\n",
    "\n",
    "# Remove multi-position variants from 1000G ${pop} (there are none so this step is actually uneccessary)\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --bfile structure/1000g_data/${pop}/${pop}_all_autosomes_10k_snp_random_sample \\\n",
    "    --exclude structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample.bad_snps.remove \\\n",
    "    --make-bed \\\n",
    "    --out structure/${pop}_all_autosomes_10k_snp_random_sample_retry\n",
    "\n",
    "\n",
    "# Retry merge\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --file structure/${ancestry}_10k_snp_random_sample_retry \\\n",
    "    --bmerge structure/${pop}_all_autosomes_10k_snp_random_sample_retry \\\n",
    "    --make-bed \\\n",
    "    --out structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample_retry\n",
    "\n",
    "'''\n",
    "Error: 2 variants with 3+ alleles present.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If the merge retry fails then the subset of failed flipped SNPs will get combined with the multi-position SNPs into a blacklist to use for creating the final PED files. Otherwise a separate blacklist and flip list will be used with PLINK --exclude and --flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "# Create final exclusion list\n",
    "study=\"lung_cancer\"\n",
    "pop=\"EUR\"\n",
    "ancestry=\"ea\"\n",
    "\n",
    "sort structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample.missnp | uniq > \\\n",
    "     structure/10k_snp_random_sample_blacklist.txt\n",
    "\n",
    "cat structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample_retry-merge.missnp\\\n",
    "    structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample.bad_snps.remove > structure/10k_snp_random_sample_blacklist.txt\n",
    "\n",
    "# Create final flip list if retry merge was successful\n",
    "cat structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample_retry-merge.missnp structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample.missnp | \\\n",
    "sort | uniq -u > structure/10k_snp_random_sample_flip_list.txt\n",
    "\n",
    "# File cleanup\n",
    "rm structure/1000g_${pop}_${study}_${ancestry}_10k_snp_random_sample.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### STUCTURE input file construction\n",
    "Because our initial merge and flip test was unsuccessful, I proceed with appying a blacklist filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Command line #\n",
    "cd /shared/data/studies/phs000428_retirement/genotype/original/processing\n",
    "\n",
    "pop=\"EUR\"\n",
    "ancestry=\"ea\"\n",
    "\n",
    "# Create final ped and map files for study genotype data for SNP subset\n",
    "#for ancestry in {ea,aa}; do\n",
    "\n",
    "echo \"=======================${ancestry}========================\"\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 3000 \\\n",
    "        --bfile ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped \\\n",
    "        --extract structure/10k_snp_random_sample.txt \\\n",
    "        --exclude structure/10k_snp_random_sample_blacklist.txt \\\n",
    "        --snps-only just-acgt \\\n",
    "        --recode \\\n",
    "        --out structure/${ancestry}_10k_snp_random_sample.final\n",
    "#done\n",
    "'9998 variants and 1998 people pass filters and QC.'\n",
    "\n",
    "# Create ped and map files for each 1000G population\n",
    "for pop in {AFR,EAS,EUR}; do\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 1024 \\\n",
    "        --bfile structure/1000g_data/${pop}/${pop}_all_autosomes_10k_snp_random_sample \\\n",
    "        --exclude structure/10k_snp_random_sample_blacklist.txt \\\n",
    "        --recode \\\n",
    "        --out structure/1000g_data/${pop}_10k_snp_random_sample.final\n",
    "done\n",
    "\n",
    "\n",
    "\n",
    "# Final check for SNP discrepancies EA\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --file structure/ea_10k_snp_random_sample.final \\\n",
    "    --merge structure/1000g_data/${pop}_10k_snp_random_sample.final \\\n",
    "    --recode \\\n",
    "    --out structure_input_test\n",
    "\n",
    "\n",
    "# File cleanup\n",
    "rm structure_input_test*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No merging issues were identified in the final check, so I will use the script ped2structure.pl to convert the PED file into a STRUCTURE input file format. This script takes two inputs. The first is an integer that serves as an ID to distinguish between a reference panel population or a study data set group. The second input is an integer that is unique to each group/population regardless of whether it's from the study or 1000G data.\n",
    "\n",
    "The goal of the conversion script is to generate a single STRUCTURE input file containing genotype information for the ~10,000 (post-filtered) subsampled SNPs and the individuals from the study and 1000G data sets. Documentation on the format can be found [here](https://web.stanford.edu/group/pritchardlab/structure_software/release_versions/v2.3.4/structure_doc.pdf). The first three columns contatin the following information respectively\n",
    "\n",
    "1. Subject identifier\n",
    "2. Group/population identifier. Distinct for each ancestry group or superpopulation\n",
    "3. Boolean indicator (1=True, 0=False) specifying reference panel populations. This is used by STRUCTURE to define the ancestry groups\n",
    "\n",
    "We will be running structure assuming that the study subjects descended from three populations. The traditional approach would be to use AFR, EAS, and EUR. I will run STRUCTURE using these 1000G superpopulations.\n",
    "\n",
    "**Note:** for $K$ reference panel populations used for ancestry comparisons, the reference panel populations must be given group IDs between 1 and $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "mkdir structure/input_files\n",
    "\n",
    "#### Create STRUCTURE file with AFR, EAS, and EUR ####\n",
    "\n",
    "groupID=1 #distinguish between all groups\n",
    "\n",
    "# Append 1000G populations to STRUCTURE file\n",
    "truncate -s 0 structure/input_files/input_afr_eas_eur\n",
    "for pop in {AFR,EAS,EUR}; do\n",
    "    cat structure/1000g_data/${pop}_10k_snp_random_sample.final.ped | \\\n",
    "    /shared/bioinformatics/software/perl/file_conversion/ped2structure.pl 1 ${groupID} \\\n",
    "    >> structure/input_files/input_afr_eas_eur\n",
    "    groupID=`echo ${groupID} + 1 | bc`\n",
    "done\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Append remaining acestry group (ea) to STRUCTURE file\n",
    "ancestry=\"ea\"\n",
    "cat structure/${ancestry}_10k_snp_random_sample.final.ped | \\\n",
    "/shared/bioinformatics/software/perl/file_conversion/ped2structure.pl 0 ${groupID} \\\n",
    "    >> structure/input_files/input_afr_eas_eur\n",
    "    groupID=`echo ${groupID} + 1 | bc` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run STRUCTURE\n",
    "For running STRUCTURE, the following command line paramters are explicitly specified\n",
    "\n",
    "* m - Main parameter file\n",
    "* e - Additional parameter file\n",
    "* i - Input data file\n",
    "* o - Output file\n",
    "* L - Number of loci in data file\n",
    "* N - Number of subjects\n",
    "* K - Maximum number of populations\n",
    "\n",
    "The remaining parameters are specified in the `mainparams` and `extraparams` files. Any values specified on the command-line overrided the values in the configuration files. Documentation on the parameter options can be found [here](https://web.stanford.edu/group/pritchardlab/structure_software/release_versions/v2.3.4/structure_doc.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "mkdir structure/output_files\n",
    "\n",
    "ancestry='ea'\n",
    "# Run Structure using AFR, EAS, and EUR\n",
    "L=$(wc -l structure/${ancestry}_10k_snp_random_sample.final.map | perl -lane 'print $F[0];')\n",
    "N=$(wc -l structure/input_files/input_afr_eas_eur | perl -lane 'print $F[0]/2;')\n",
    "/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name structure_afr_eas_eur \\\n",
    "    --script_prefix structure/output_files/structure_afr_eas_eur \\\n",
    "    --mem 7.5 \\\n",
    "    --priority 0 \\\n",
    "    --nslots 1 \\\n",
    "    --program /shared/bioinformatics/software/third_party/structure_v2.3.4/console/structure \\\n",
    "         -m /shared/bioinformatics/software/third_party/structure_v2.3.4/console/mainparams \\\n",
    "         -e /shared/bioinformatics/software/third_party/structure_v2.3.4/console/extraparams \\\n",
    "         -i structure/input_files/input_afr_eas_eur \\\n",
    "         -o structure/output_files/output_afr_eas_eur \\\n",
    "         -L $L \\\n",
    "         -N $N \\\n",
    "         -K 3\n",
    "'278 0.55500 structure_ ec2-user     r     02/14/2018 17:39:29 all.q@ip-172-31-29-1.ec2.inter     1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing triangle plots\n",
    "\n",
    "[Triangle or ternary plots](https://en.wikipedia.org/wiki/Ternary_plot) provide a means to visualize membership strength. For the purposes of the study data, the triangle plots are used to determine how similar self-reports of individuals from a Retirement ancestry group are to three disparate reference populations. The visualizations allow for the identification of potential outliers that would be removed from downstream processing and analysis.\n",
    "\n",
    "**Note:** The command line Perl script below assumes a specific order of the STRUCTURE output data in regards to the group IDs. Modifications should be made as necessary to ensure that the labels match with the ID. Additionaly, `triagle_plot.R` does not check that the cluster specifications match the given 1000G superpopulations labels. Be sure to assign the right label to the right group ID from previous processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "mkdir structure/triangle_plots\n",
    "\n",
    "#### AFR, EAS, and EUR ####\n",
    "\n",
    "# Prepare results for triangle plot\n",
    "perl -ne 'if (/%Miss/) {\n",
    "              $in=1;\n",
    "              print \"num\\tID\\tpop\\tcluster1\\tcluster2\\tcluster3\\n\";\n",
    "          }\n",
    "          if ($in==1 && !/Label/ && !/^\\s+$/) {\n",
    "              @datasets=(\"AFR\",\"EAS\",\"EUR\", Study_EA);\n",
    "              s/^\\s+//g;\n",
    "              @F=split /\\s+/;\n",
    "              # Grab only study data set groups by ID\n",
    "              if ($F[3] > 3) {\n",
    "                  print $F[0].\"\\t\".$F[1].\"\\t\".$datasets[$F[3]-1].\"\\t\".$F[5].\"\\t\".$F[6].\"\\t\".$F[7].\"\\n\";\n",
    "              }\n",
    "          } \n",
    "          s/\\s+//g;\n",
    "          if ($_ eq \"\") { $in=0; }' structure/output_files/output_afr_eas_eur_f > \\\n",
    "    structure/triangle_plots/afr_eas_eur.triangle_input\n",
    "\n",
    "\n",
    "# Prepare id xref file, EA\n",
    "perl -ne 'if ($count==0) { print \"num\\tID\\n\"; }\n",
    "          if (!defined $even) { print STDERR \"LALALA\\n\";} \n",
    "          if ($even==0) {/^(\\S+)/; print $count+1; print \"\\t\".$1.\"\\n\"; $count++; $even=1}\n",
    "          else {$even=0}' structure/input_files/input_afr_eas_eur > \\\n",
    "    structure/triangle_plots/afr_eas_eur_id_xref\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# Generate triangle plot\n",
    "Rscript /shared/bioinformatics/software/R/triangle_plot.R \\\n",
    "    --data structure/triangle_plots/afr_eas_eur.triangle_input \\\n",
    "    --prefix structure/triangle_plots/afr_eas_eur \\\n",
    "    --cluster1 African \\\n",
    "    --cluster2 Asian \\\n",
    "    --cluster3 European \\\n",
    "    --xref structure/triangle_plots/afr_eas_eur_id_xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## local machine ##\n",
    "\n",
    "# copy output triangle plot to local desktop\n",
    "scp -i ~/.ssh/gwas_rsa ec2-user@35.171.207.199:/shared/data/studies/phs000634_lung_cancer/genotype/original/processing/structure/triangle_plots/afr_eas_eur_Study_EA.jpg \\\n",
    "    GitHub/jaamarks_notebooks/Heroin_Project/figures/634_lung_cancer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"IRdisplay\")\n",
    "display_png(file=\"C:/Users/jmarks/Desktop/GitHub/jaamarks_notebooks/Heroin_Project/figures/634_lung_cancer/afr_eas_eur_Study_EA.jpg\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers\n",
    "\n",
    "The triangle plots show an ancestral continuum derived from the genetic data. Since PCA principal components will be utilized as covariates in the GWA model, we can afford to be less conservative with our thresholds here for calling outliers. Based on the figure, I will apply the following inclusion criteria to avoid the loss of usable samples:\n",
    "***\n",
    "\n",
    "| Action Description        | Thresholding Criteria              |\n",
    "|---------------------------|------------------------------------|\n",
    "| For EA retainment         | (AFR < 0.25) $\\wedge$ (EAS < 0.25) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "# Create triangle plot input with potential outliers filtered\n",
    "head -1 structure/triangle_plots/afr_eas_eur.triangle_input >\\\n",
    "    structure/triangle_plots/afr_eas_eur_filtered.triangle_input\n",
    "# EA retained\n",
    "tail -n +2 structure/triangle_plots/afr_eas_eur.triangle_input | \\\n",
    "    perl -lane 'if ($F[2] eq \"Study_EA\" && ($F[3] < 0.25 && $F[4] < 0.25)) { print $_; }' \\\n",
    "    >> structure/triangle_plots/afr_eas_eur_filtered.triangle_input\n",
    "\n",
    "wc -l structure/triangle_plots/afr_eas_eur.triangle_input\n",
    "'1999'\n",
    "wc -l structure/triangle_plots/afr_eas_eur_filtered.triangle_input\n",
    "'1999'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: no subjects were removed after applying filter, therefore all of the reassignment and removal procedures do not need to be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/ea/autosomes\n",
    "\n",
    "for ext in {.bed,.bim,.fam,.log}; do\n",
    "    cp genotypes_b37_dbsnp138_flipped${ext} genotypes_b37_dbsnp138_flipped_structure${ext}\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genotype call rate variant filter\n",
    "I calculate the genotype missing call rate and remove any variants with a rate $> 3\\%$.\n",
    "<a id='call-rate'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "# Get missing call rate\n",
    "ancestry=\"ea\"\n",
    "#for ancestry in{\"ea\",\"aa\"}\n",
    "    echo -e \"\\n\\n================ ${ancestry} ================\\n\\n\"\n",
    "        /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --bfile ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure \\\n",
    "            --missing \\\n",
    "            --out ${ancestry}/autosomes/autosome_missing_call_rate\n",
    "\n",
    "    # Get list of variants with missing call rate > 3% \n",
    "    tail -n +2 ${ancestry}/autosomes/autosome_missing_call_rate.lmiss | \\\n",
    "        perl -lane 'if ($F[4] > 0.03) { print $F[1]; }' | \\\n",
    "        sort -u > ${ancestry}/autosomes/variant_missing_rate_gt_3_pct.remove\n",
    "\n",
    "    # Remove variants\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure \\\n",
    "        --exclude ${ancestry}/autosomes/variant_missing_rate_gt_3_pct.remove \\\n",
    "        --make-bed \\\n",
    "        --out ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_filter\n",
    "#done\n",
    "\n",
    "wc -l ea/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_filter.bim\n",
    " '652407'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardy-Weinberg equilibrium filtering\n",
    "Extensive deviation from Hardy-Weinberg equilibrium (HWE) can be indicative of a genotyping or genotype calling error. Using PLINK  --hardy, I calculate goodness of fit test p-values for allele frequencies compared to HWE. Any variant with p < 0.0001 is removed.\n",
    "\n",
    "<a id='hardy'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "# Calculate HW p-values for each ancestry group\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    echo -e \"\\n\\n================ ${ancestry} ================\\n\\n\"\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --bfile ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_filter \\\n",
    "        --hardy \\\n",
    "        --out ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_filter\n",
    "\n",
    "   # Get list of variants with HWE p-value < 0.0001 for each ancestry group\n",
    "    tail -n +2 ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_filter.hwe | \\\n",
    "        perl -lane 'if ($F[2] eq \"ALL(NP)\" && $F[8] < 0.0001) { print $F[1]; }' | \\\n",
    "        sort -u > ${ancestry}/autosomes/hwe_p_lt_0.0001.remove\n",
    "\n",
    "\n",
    "    # Remove variants with HWE p-value < 0.0001\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --bfile ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_filter \\\n",
    "        --exclude ${ancestry}/autosomes/hwe_p_lt_0.0001.remove \\\n",
    "        --make-bed \\\n",
    "        --out ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_filter\n",
    "#done\n",
    "wc -l ea/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_filter.bim\n",
    "'652407' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Genotype call rate subject filter\n",
    "**Note**: The genotype call rate subject filtereing and the subsequent LD pruning are specifically for relatedness filtering calculations. Autosomes and chrX merging will be done using the PLINK file sets generated in the preceding step (HWE filtering).\n",
    "\n",
    "I calculate the genotype missing call rate and remove any subjects with a rate > $3\\%.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "# Remove variants\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    echo -e \"\\n\\n================ ${ancestry} ================\\n\\n\"\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --bfile ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_filter \\\n",
    "        --mind 0.03 \\\n",
    "        --make-bed \\\n",
    "        --out ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_lte_0.03_filter\n",
    "#done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linkage disequilibrium pruning\n",
    "\n",
    "Linkage disequilibrium (LD) pruning eliminates a large degree of redundancy in the data and reduces the influence of chromosomal artifacts. The objective of LD pruning is to select a subset of variants based off of LD such that the variants in the subset are indepdendent. This filtering will not carry forward to the final processed results, but this step improves the quality of identity-by-state (IBS) and identity-by-descent (IBD) calculations. Consequently, the LD pruned data will be used as input into IBS and IBD calculations.\n",
    "\n",
    "LD pruning is implemented using [PLINK --indep-pairwise](https://www.cog-genomics.org/plink/1.9/ld#indep)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "# Run per chromosome LD pruning \n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    echo -e \"\\n\\n================ ${ancestry} ================\\n\\n\"\n",
    "    for chr in {1..22}; do\n",
    "        /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "            --job_name ${ancestry}_${chr}_ld_prune \\\n",
    "            --script_prefix ${ancestry}/autosomes/${ancestry}_${chr}_ld_prune \\\n",
    "            --mem 7.5 \\\n",
    "            --priority 0 \\\n",
    "            --nslots 1 \\\n",
    "            --program /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "                --noweb \\\n",
    "                --bfile ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_lte_0.03_filter \\\n",
    "                --indep-pairwise 50 5 0.5 \\\n",
    "                --chr ${chr} \\\n",
    "                --out ${ancestry}/autosomes/genotypes_for_relatedness_filtering.ld_prune_chr${chr}\n",
    "    done\n",
    "#done\n",
    "\n",
    "\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    echo -e \"\\n\\n================ ${ancestry} ================\\n\\n\"\n",
    "    # Merge *prune.in files\n",
    "    cat ${ancestry}/autosomes/genotypes_for_relatedness_filtering.ld_prune_chr*.prune.in \\\n",
    "        > ${ancestry}/autosomes/genotypes_for_relatedness_filtering.ld_prune_autosomes.prune.in\n",
    "\n",
    "    # Create new PLINK filesets with only lD pruned variants\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile ${ancestry}/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_lte_0.03_filter \\\n",
    "        --extract ${ancestry}/autosomes/genotypes_for_relatedness_filtering.ld_prune_autosomes.prune.in \\\n",
    "        --make-bed \\\n",
    "        --out ${ancestry}/autosomes/genotypes_for_relatedness_ld_prune_filter\n",
    "#done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Identical-by-state and identical-by-descent filtering\n",
    "\n",
    "Identical-by-state or identity-by-state (IBS) filtering provides a means to identify duplicate subjects or monozygotic twins. Identical-by-descent or identity-by-descent allows for detection of high relatedness. For computational efficiency and memory usage limitations, `ibd_pipeline.sh` is used to perform IBS/IBD calculations on data chunks that are used as input for IBS and IBD filtering. If the study contains AA subjects, then for AA subjects only, [KING](http://people.virginia.edu/~wc9c/KING/manual.html) is used as an additional relationship inference tool for filtering.\n",
    "\n",
    "For these filtering steps, a list of individuals is identified separately for each filtering type then combined into a final list for exclusion. Following IBS filtering, if any individuals are identified for removal, a graph analysis needs to be done to account for an individual being related/identical to multiple individuals. Removal criteria is based on genotype calling rate. These individuals would need to be removed before running IBD filtering and KING. Graph analysis would need to be run after IBD calculations/KING if individuals were selected for removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "# Calculate allele frequencies in data chunks\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    echo -e \"\\n\\n================ ${ancestry} ================\\n\\n\"\n",
    "    /shared/bioinformatics/software/scripts/ibd_pipeline.sh \\\n",
    "        --in_prefix ${ancestry}/autosomes/genotypes_for_relatedness_ld_prune_filter \\\n",
    "        --out_dir ${ancestry}/autosomes/\n",
    "    sleep 5s\n",
    "#done\n",
    "\n",
    "\n",
    "# Aggregate data\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    outfile=${ancestry}/autosomes/genotypes_for_relatedness_ld_prune_filter.genome\n",
    "    head -1 `ls ${ancestry}/autosomes/data.sub.genome* | head -1` > ${outfile}\n",
    "    cat ${ancestry}/autosomes/data.sub.genome* | \\\n",
    "        grep -v FID1 >> ${outfile}\n",
    "\n",
    "    # Remove temporary files\n",
    "    rm ${ancestry}/autosomes/data.sub.*\n",
    "    rm ${ancestry}/autosomes/tmp_sh*.sh\n",
    "#done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBS filtering\n",
    "For individual pairs with greater than 0.9 IBS score, only the individual with the lower genotype missing call rate is retained. I create a list of individuals to remove that will be combined with the IBD list for final filtering but removed from the LD pruned data before running IBD filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EC2 command line\n",
    "cd /shared/data/studies/phs000428_retirement/genotype/original/processing\n",
    "\n",
    "# Get list of individuals with IBS > 0.9\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    echo -e \"\\n\\n================ ${ancestry} ================\\n\\n\"\n",
    "    Rscript /shared/bioinformatics/software/R/merge_genome_missing.R \\\n",
    "        --genome ${ancestry}/autosomes/genotypes_for_relatedness_ld_prune_filter.genome \\\n",
    "        --imiss ${ancestry}/autosomes/autosome_missing_call_rate.imiss \\\n",
    "        --type IBS \\\n",
    "        --out ${ancestry}/autosomes/genotypes_for_relatedness_ld_prune_ibs_gt_0.9_filter\n",
    "#done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because no individuals need to be removed, I proceed with IBD filtering without additional removal steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IBD filtering\n",
    "For individual pairs with greateer than 0.4 IBD score, only the individual with the lower genotype missing call rate is retained. I create a list of individuals to remove that will be combined with the IBS list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 command line\n",
    "cd /shared/data/studies/phs000428_retirement/genotype/original/processing\n",
    "\n",
    "# Get list of individuals with IBD > 0.4\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    echo -e \"\\n\\n================ ${ancestry} ================\\n\\n\"\n",
    "    Rscript /shared/bioinformatics/software/R/merge_genome_missing.R \\\n",
    "        --genome ${ancestry}/autosomes/genotypes_for_relatedness_ld_prune_filter.genome \\\n",
    "        --imiss ${ancestry}/autosomes/autosome_missing_call_rate.imiss \\\n",
    "        --type IBD \\\n",
    "        --pi_hat_threshold 0.4 \\\n",
    "        --out ${ancestry}/autosomes/genotypes_for_relatedness_ld_prune_ibd_gt_0.4_filter\n",
    "#done\n",
    "\n",
    " wc -l ea/autosomes/genotypes_for_relatedness_ld_prune_ibd_gt_0.4_filter\n",
    "'''1 - 1 = 0'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No individuals need to be removed. I can proceed without additional removal steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Merge autosomes and chrX\n",
    "The data processed through to HWE filtering for both the autosomes and chrX are merged before applying the final subject filtering steps.\n",
    "\n",
    "__Note:__ there was no chrX data, thus no merging is to be done. We will, however, keep the naming convention for the data for coding convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "cp ea/autosomes/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_lte_0.03_filter.* ea/\n",
    "\n",
    "# rename data for convenience in next steps\n",
    "for ext in {.bim,.fam,.bed}; do\n",
    "cp ea/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_lte_0.03_filter${ext}\\\n",
    "    ea/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_ld_prune_chr_all_filter${ext}\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excessive homozygosity filter\n",
    "Excessive homozygosity checks for inbreeding and population substructure. This check is implemented using PLINK. According to their documentation, the statistics used for this filtering are not LD-sensitive, i.e., an LD pruned dataset is recommended as input. Additionally, the documentation states that only autosomal data are used, so concerns of chrX biasing results are irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "\n",
    "# make files for naming convention\n",
    "for ext in {.bim,.fam,.bed}; do\n",
    "cp ea/genotypes_b37_dbsnp138_flipped_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_lte_0.03_filter${ext}\\\n",
    "    ea/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_failed_sex_check_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_filter.all_chr${ext}\n",
    "done\n",
    "\n",
    "# Get homozygosity stats\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    echo -e \"\\n\\n================ ${ancestry} ================\\n\\n\"\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile ${ancestry}/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_ld_prune_chr_all_filter \\\n",
    "        --het \\\n",
    "        --out ${ancestry}/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_ld_prune_chr_all_filter\n",
    "\n",
    "   # Identify problematic subjects\n",
    "    perl -lane 'if ($F[5] < -0.2 || $F[5] > 0.5) { print $F[0].\" \".$F[1]; }' ${ancestry}/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_ld_prune_chr_all_filter.het \\\n",
    "    > ${ancestry}/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_ld_prune_homozygosity_check_chr_all_filter.remove\n",
    "\n",
    "    # Remove problematic subjects\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile ${ancestry}/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_failed_sex_check_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_filter.all_chr \\\n",
    "        --remove ${ancestry}/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_ld_prune_homozygosity_check_chr_all_filter.remove \\\n",
    "        --make-bed \\\n",
    "        --out ${ancestry}/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_failed_sex_check_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_homozygosity_check_filter.all_chr\n",
    "\n",
    "    echo -e \"\\nNumber of ${ancestry} subjects removed: $(wc -l  ${ancestry}/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_ld_prune_homozygosity_check_chr_all_filter.remove)\\n\\n\"\n",
    "#done\n",
    "\n",
    "'''\n",
    "Number of ea subjects removed: 0 ea/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_ld_prune_homozygosity_check_chr_all_filter.remove\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding variants for 1000G phase 3\n",
    "\n",
    "RefSeq IDs (rsIDs) for variants can vary depending on the dbSNP build used and variant IDs do not all use RefSeq nomenclature. To provide a common nomenclature that will make comparisons across data sets feasible, I use a script that recodes all variant names to match 1000G phase 3 variants by position and alleles. The 1000G Phase 3 data I used for STRUCTURE are from /share/nas03/bioinformatics_group/data/ref_panels/1000G/2013.05/plink on MIDAS, but from correspondence with Nathan Gaddis I learned that /share/nas03/bioinformatics_group/data/ref_panels/1000G/2014.10/ also contains 1000G Phase 3 data derived from the May 2013 release. The difference is that it was downloaded from the IMPUTE2 website and reformatted to be directly compatible with IMPUTE2.\n",
    "\n",
    "The data in /share/nas03/bioinformatics_group/data/ref_panels/1000G/2014.10/ is used for variant name recoding, but the 1000G genotype information is acquired from /share/nas03/bioinformatics_group/data/ref_panels/1000G/2013.05/plink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/\n",
    "\n",
    "mkdir 1000g_name_recoding\n",
    "\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    for ext in {bed,bim,fam}; do\n",
    "        cp  ${ancestry}/genotypes_b37_dbsnp138_structure_variant_missing_lte_0.03_hwe_p_gte_0.0001_subject_missing_chrx_failed_sex_check_ibs_gt_0.9_ibd_gt_0.4_subject_missing_lte_0.03_homozygosity_check_filter.all_chr.${ext} 1000g_name_recoding/${ancestry}_chr_all.${ext}\n",
    "    done\n",
    "#done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variant ID updating\n",
    "\n",
    "Because the 1000G data and the study data have RefSeq IDs (rsIDs) from different dbSNP builds, I standardize them using convert_to_1000g_ids.pl. In the study data set, certain indels may be represented as two variants, a monomorphic variant and an indel with the - symbol for one of the alleles. For example:\n",
    "\n",
    "`1   rs201826967  0.809   57873968   0   G`<br>`1   rs11284630   0.809   57873969   -   A`\n",
    "\n",
    "These two variants represent a G:GA indel and is coded as such in the 1000 Genomes data. The script to update the names to 1000 Genomes IMPUTE2 format will assign the same ID to these two variants. The duplicated IDs will cause problems for PLINK filtering, so I will remove the variant from a set of duplicate IDs that has the lower genotype call rate. Duplicates may arise for other reasons, and they will be filtered based on the same criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/1000g_name_recoding\n",
    "mkdir 1000g_data\n",
    "\n",
    "# Break out data by chr\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    #for chr in {1..23}; do\n",
    "    for chr in {1..22}; do\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --memory 2048 \\\n",
    "            --bfile ${ancestry}_chr_all \\\n",
    "            --chr ${chr} \\\n",
    "            --make-bed \\\n",
    "            --out ${ancestry}_chr${chr}\n",
    "    done\n",
    "#done\n",
    "\n",
    "\n",
    "# Rename study autosome variant IDs\n",
    "#Note I had to chmod +x convert_to_1000g...\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    for chr in {1..22}; do\n",
    "        /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "            --job_name recode_to_1000g_${chr} \\\n",
    "            --script_prefix ${ancestry}_chr${chr}_id_rename \\\n",
    "            --mem 6 \\\n",
    "            --nslots 1 \\\n",
    "            --priority 0 \\\n",
    "            --program /shared/bioinformatics/software/perl/id_conversion/convert_to_1000g_p3_ids.pl \\\n",
    "            --file_in ${ancestry}_chr${chr}.bim \\\n",
    "            --file_out ${ancestry}_chr${chr}_renamed.bim \\\n",
    "            --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr$chr.legend.gz \\\n",
    "            --file_in_header 0 \\\n",
    "            --file_in_id_col 1 \\\n",
    "            --file_in_chr_col 0 \\\n",
    "            --file_in_pos_col 3 \\\n",
    "            --file_in_a1_col 4 \\\n",
    "            --file_in_a2_col 5 \\\n",
    "            --chr ${chr}\n",
    "    done\n",
    "#done\n",
    "\n",
    "\n",
    "## Rename study chrX variant IDs\n",
    "#chr=23\n",
    "#for ancestry in {ea,aa}; do\n",
    "#    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#        --job_name recode_to_1000g_${chr} \\\n",
    "#        --script_prefix ${ancestry}_chr${chr}_id_rename \\\n",
    "#        --mem 6 \\\n",
    "#        --nslots 1 \\\n",
    "#        --priority 0 \\\n",
    "#        --program /shared/bioinformatics/software/perl/id_conversion/convert_to_1000g_p3_ids.pl \\\n",
    "#        --file_in ${ancestry}_chr${chr}.bim \\\n",
    "#        --file_out ${ancestry}_chr${chr}_renamed.bim \\\n",
    "#        --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chrX_NONPAR.legend.gz \\\n",
    "#        --file_in_header 0 \\\n",
    "#        --file_in_id_col 1 \\\n",
    "#        --file_in_chr_col 0 \\\n",
    "#        --file_in_pos_col 3 \\\n",
    "#        --file_in_a1_col 4 \\\n",
    "#        --file_in_a2_col 5 \\\n",
    "#        --chr ${chr}\n",
    "#done\n",
    "\n",
    "\n",
    "# Rename 1000G autosome variant IDs\n",
    "for chr in {1..22}; do\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name recode_to_1000g_${chr} \\\n",
    "        --script_prefix ${ancestry}_chr${chr}_id_rename \\\n",
    "        --mem 8 \\\n",
    "        --nslots 1 \\\n",
    "        --priority 0 \\\n",
    "        --program /shared/bioinformatics/software/perl/id_conversion/convert_to_1000g_p3_ids.pl \\\n",
    "        --file_in /shared/data/ref_panels/1000G/2013.05/plink/ALL.chr${chr}.bim \\\n",
    "        --file_out 1000g_data/chr${chr}_renamed.bim \\\n",
    "        --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr$chr.legend.gz \\\n",
    "        --file_in_header 0 \\\n",
    "        --file_in_id_col 1 \\\n",
    "        --file_in_chr_col 0 \\\n",
    "        --file_in_pos_col 3 \\\n",
    "        --file_in_a1_col 4 \\\n",
    "        --file_in_a2_col 5 \\\n",
    "        --chr ${chr}\n",
    "done\n",
    "\n",
    "\n",
    "# Rename 1000G chrX variant IDs\n",
    "#chr=23\n",
    "#/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#    --job_name recode_to_1000g_${chr} \\\n",
    "#    --script_prefix ${ancestry}_chr${chr}_id_rename \\\n",
    "#    --mem 8 \\\n",
    "#    --priority 0 \\\n",
    "#    --program /shared/bioinformatics/software/perl/id_conversion/convert_to_1000g_p3_ids.pl \\\n",
    "#    --file_in /shared/data/ref_panels/1000G/2013.05/plink/ALL.chrX.bim \\\n",
    "#    --file_out 1000g_data/chr${chr}_renamed.bim \\\n",
    "#    --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chrX_NONPAR.legend.gz \\\n",
    "#    --file_in_header 0 \\\n",
    "#    --file_in_id_col 1 \\\n",
    "#    --file_in_chr_col 0 \\\n",
    "#    --file_in_pos_col 3 \\\n",
    "#    --file_in_a1_col 4 \\\n",
    "#    --file_in_a2_col 5 \\\n",
    "#    --chr ${chr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate variant ID\n",
    "<a id=\"variant_dups\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/1000g_name_recoding\n",
    "\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    #for chr in {1..23}; do\n",
    "    for chr in {1..22}; do\n",
    "        # Append _X (where X is a number) to the end of the variant IDs for all but 1st occurrence of duplicates\n",
    "        perl -lane 'BEGIN { %idCounts = (); }\n",
    "                    if (exists($idCounts{$F[1]})) {\n",
    "                        $idCounts{$F[1]}++;\n",
    "                        print join(\"\\t\",$F[0],$F[1].\"_\".$idCounts{$F[1]},$F[2],$F[3],$F[4],$F[5]);\n",
    "                    } else {\n",
    "                        $idCounts{$F[1]} = 1;\n",
    "                        print;\n",
    "                    }' ${ancestry}_chr${chr}_renamed.bim > \\\n",
    "            ${ancestry}_chr${chr}_renamed_dups.bim\n",
    "\n",
    "        # Generate list of duplicate SNPs\n",
    "        grep -P \"_[1-9]\" ${ancestry}_chr${chr}_renamed_dups.bim |\n",
    "            perl -lane 'print substr($F[1], 0, index($F[1],\"_\")).\"\\n\".$F[1];' > \\\n",
    "            ${ancestry}_chr${chr}_renamed_dups.dupvar_list\n",
    "    done\n",
    "\n",
    "    for chr in $(wc -l *.dupvar_list | perl -lane 'if ($F[0] != 0) { $F[1] =~ /chr(\\d+)/; print $1; }'); do\n",
    "# Get call rates for duplicate SNPs\n",
    "        echo ======================${chr}========================\n",
    "        /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --memory 2048 \\\n",
    "            --bed ${ancestry}_chr${chr}.bed \\\n",
    "            --bim ${ancestry}_chr${chr}_renamed_dups.bim \\\n",
    "            --fam ${ancestry}_chr${chr}.fam \\\n",
    "            --extract ${ancestry}_chr${chr}_renamed_dups.dupvar_list \\\n",
    "            --allow-no-vars\n",
    "            --missing \\\n",
    "            --out ${ancestry}_chr${chr}_renamed_dups\n",
    "\n",
    "        # Create remove list that contains the duplicate with the higher missing rate\n",
    "        tail -n +2 ${ancestry}_chr${chr}_renamed_dups.lmiss | \\\n",
    "            perl -lane 'BEGIN { %missingness = (); }\n",
    "                        if ($F[1] =~ /^(\\S+)\\_/) {\n",
    "                            $duplicateName = $1\n",
    "                        } else {\n",
    "                            $duplicateName = $F[1].\"_2\";\n",
    "                        }\n",
    "                        if (exists($missingness{$duplicateName})) {\n",
    "                            if ($missingness{$duplicateName} > $F[4]) {\n",
    "                                print $duplicateName;\n",
    "                            } else {\n",
    "                                print $F[1];\n",
    "                            }\n",
    "                        } else {\n",
    "                            $missingness{$F[1]} = $F[4];\n",
    "                        }' \\\n",
    "                > ${ancestry}_chr${chr}_renamed_dups.remove\n",
    "\n",
    "        /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "            --noweb \\\n",
    "            --memory 2048 \\\n",
    "            --bed ${ancestry}_chr${chr}.bed \\\n",
    "            --bim ${ancestry}_chr${chr}_renamed_dups.bim \\\n",
    "            --fam ${ancestry}_chr${chr}.fam \\\n",
    "            --exclude ${ancestry}_chr${chr}_renamed_dups.remove \\\n",
    "            --make-bed \\\n",
    "            --out ${ancestry}_chr${chr}_renamed_dups_removed\n",
    "\n",
    "        # Remove \"_2\" from variant IDs\n",
    "        perl -i.bak -lne 's/\\_2//; print;' ${ancestry}_chr${chr}_renamed_dups_removed.bim\n",
    "    done\n",
    "#done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: there were no duplicates in the above steps and therefore we got errors. Thus, we don't use:\n",
    "* \\${ancestry}_chr\\${chr}_renamed_dups_removed.bim\n",
    "in the next section. \n",
    "\n",
    "Instead, we use:\n",
    "\n",
    "* \\${ancestry}_chr\\${chr}_renamed.bim\n",
    "\n",
    "**Note**: could have used the PLINK flag `--allow-no-vars`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge chromosome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/1000g_name_recoding\n",
    "\n",
    "# Add chr where duplicates were removed to merge list\n",
    "for ancestry in {ea,aa}; do\n",
    "    echo -e \"\\n\\n================ ${ancestry} ================\\n\\n\"\n",
    "    for chr in $(wc -l *.dupvar_list | perl -lane 'if ($F[0] != 0) { $F[1] =~ /chr(\\d+)/; if ($1 ne \"1\") { print $1; } }'); do\n",
    "        baseName=${ancestry}_chr${chr}_renamed\n",
    "        echo ${baseName}.bed ${baseName}.bim ${baseName}.fam\n",
    "    done > ${ancestry}_renamed.chr_merge\n",
    "\n",
    "    # Add all other chr to merge list\n",
    "    for chr in $(wc -l *.dupvar_list | perl -lane 'if ($F[0] == 0) { $F[1] =~ /chr(\\d+)/; print $1; }'); do\n",
    "        baseName=${ancestry}_chr${chr}\n",
    "        echo ${baseName}.bed ${baseName}_renamed.bim ${baseName}.fam\n",
    "    done >> ${ancestry}_renamed.chr_merge\n",
    "\n",
    "    # Merge chromosomes\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --merge-list ${ancestry}_renamed.chr_merge \\\n",
    "        --make-bed \\\n",
    "        --out ${ancestry}_chr_all_renamed\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge flipped chrX with autosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/1000g_name_recoding\n",
    "\n",
    "# Extract flipped autosomes\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile ${ancestry}_chr_all_renamed \\\n",
    "        --autosome \\\n",
    "        --make-bed \\\n",
    "        --out ${ancestry}_chr_all_renamed_flipped\n",
    "        #--out ${ancestry}_autosomes_renamed\n",
    "\n",
    "#    # Merge autosomes with flipped chrX\n",
    "#    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "#        --noweb \\\n",
    "#        --memory 2048 \\\n",
    "#        --bfile ${ancestry}_autosomes_renamed \\\n",
    "#        --bmerge ${ancestry}_chr23_renamed_flipped \\\n",
    "#        --make-bed \\\n",
    "#        --out ${ancestry}_chr_all_renamed_flipped\n",
    "#done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allele discordance\n",
    "As a way of standardizing the data, I use 1000G phase 3 data as a reference. The study data may not match the 1000G phase 3 data for several reasons including\n",
    "\n",
    "* Discordant names\n",
    "* Discordant positions\n",
    "* Discordant alleles (swapped major and minor alleles)\n",
    "* Polymorphic alleles not fixed by strand flipping\n",
    "* Discordant allele frequencies\n",
    "\n",
    "I perform checks for these discordances using the 1000G Phase 3 data derived from\n",
    "`data/ref_panels/1000G/2014.10/` derived from the May 2013 release. These data were downloaded from the [IMPUTE2 website](https://mathgen.stats.ox.ac.uk/impute/1000GP_Phase3.html) and reformatted to be directly compatible with IMPUTE2. These data will be used for ID recoding and MAF calculations.\n",
    "\n",
    "To determine if any study data variants have flipped alleles, I compare the variants to the appropriate 1000 Genomes Phase 3 reference superpopulation. For example, African ancestry is compared to AFR, European ancestry is compared to EUR, and Hispanic ancestry is compared to AMR.\n",
    "\n",
    "Discordance checks are used mainly to\n",
    "\n",
    "1. Determine allele frequency discordances to remove prior to imputation\n",
    "2. Determine if alleles are properly coded in reference to the forward/positive genome strand\n",
    "\n",
    "A lare number of discordant variants indicates potential allele flipping/mismatching issues. If the number of discordant heterozygous variants is less than approximately 10,000, then it is unlikely that there were major issues with flipping or mismatching that indicate coding alleles to the wrong strand.\n",
    "\n",
    "### Preparing study data\n",
    "The allele discordance scrip requires as input a file of MAFs, so I calculate this using PLINK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/1000g_name_recoding\n",
    "\n",
    "# Calculate allele frequencies\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile ${ancestry}_chr_all_renamed_flipped \\\n",
    "        --freq \\\n",
    "        --out ${ancestry}_chr_all_renamed_flipped\n",
    "#done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing 1000G phase 3 data\n",
    "\n",
    "MAF data are needed for 1000 Genomes data in addition to the study data, so I calculate these for the superpopulations(s) that matches the study group subject ancestries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/1000g_name_recoding/1000g_data\n",
    "\n",
    "for ancestry in {ea,aa}; do\n",
    "    echo \"==========${ancestry}==========\"\n",
    "    # Get list of study variant IDs\n",
    "    perl -lane 'if ($F[0] <= 23) { print $F[1]; }' ../${ancestry}_chr_all_renamed_flipped.bim | \\\n",
    "        sort > ../${ancestry}_chr_all_sorted_variants.txt\n",
    "done\n",
    "\n",
    "# Calculate autosome and chrX MAFs for 1000G AFR\n",
    "#pop=\"AFR\"\n",
    "#ancestry=\"aa\"\n",
    "#\n",
    "#chr=3\n",
    "##for chr in {1..22}; do\n",
    "#for chr in {3..4}; do\n",
    "#    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#        --job_name ${pop}_${chr} \\\n",
    "#        --script_prefix ${pop}_chr${chr}.maf \\\n",
    "#        --mem 6 \\\n",
    "#        --priority 0 \\\n",
    "#        --program /shared/bioinformatics/software/perl/stats/calculate_maf_from_impute2_hap_file.pl \\\n",
    "#            --hap /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr${chr}.hap.gz\\\n",
    "#            --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr${chr}.legend.gz \\\n",
    "#            --sample /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3.sample \\\n",
    "#            --chr ${chr} \\\n",
    "#            --out ${ancestry}_${pop}_overlap_chr${chr}.maf \\\n",
    "#            --extract ../${ancestry}_chr_all_sorted_variants.txt \\\n",
    "#            --keep_groups ${pop}\n",
    "#done\n",
    "#\n",
    "#chr=23\n",
    "#/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#    --job_name ${pop}_${chr} \\\n",
    "#    --script_prefix ${pop}_chr${chr}.maf \\\n",
    "#    --mem 6.8 \\\n",
    "#    --priority 0 \\\n",
    "#    --program /shared/bioinformatics/software/perl/stats/calculate_maf_from_impute2_hap_file.pl \\\n",
    "#        --hap /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chrX_NONPAR.hap.gz\\\n",
    "#        --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chrX_NONPAR.legend.gz \\\n",
    "#        --sample /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3.sample \\\n",
    "#        --chr ${chr} \\\n",
    "#        --extract ../${ancestry}_chr_all_sorted_variants.txt \\\n",
    "#        --out ${ancestry}_${pop}_overlap_chr${chr}.maf \\\n",
    "#        --keep_groups ${pop}\n",
    "\n",
    "\n",
    "# Calculate autosome and chrX MAFs for 1000G EUR\n",
    "pop=\"EUR\"\n",
    "ancestry=\"ea\"\n",
    "for chr in {1..22}; do\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name ${pop}_${chr} \\\n",
    "        --script_prefix ${pop}_chr${chr}.maf \\\n",
    "        --mem 6.8 \\\n",
    "        --priority 0 \\\n",
    "        --program /shared/bioinformatics/software/perl/stats/calculate_maf_from_impute2_hap_file.pl \\\n",
    "            --hap /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr${chr}.hap.gz\\\n",
    "            --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr${chr}.legend.gz \\\n",
    "            --sample /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3.sample \\\n",
    "            --chr ${chr} \\\n",
    "            --out ${ancestry}_${pop}_overlap_chr${chr}.maf \\\n",
    "            --extract ../${ancestry}_chr_all_sorted_variants.txt \\\n",
    "            --keep_groups ${pop}\n",
    "done\n",
    "\n",
    "#chr=23\n",
    "#/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#    --job_name ${pop}_${chr} \\\n",
    "#    --script_prefix ${pop}_chr${chr}.maf \\\n",
    "#    --mem 7 \\\n",
    "#    --priority 0 \\\n",
    "#    --program /shared/bioinformatics/software/perl/stats/calculate_maf_from_impute2_hap_file.pl \\\n",
    "#        --hap /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chrX_NONPAR.hap.gz\\\n",
    "#        --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chrX_NONPAR.legend.gz \\\n",
    "#        --sample /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3.sample \\\n",
    "#        --chr ${chr} \\\n",
    "#        --extract ../${ancestry}_chr_all_sorted_variants.txt \\\n",
    "#        --out ${ancestry}_${pop}_overlap_chr${chr}.maf \\\n",
    "#        --keep_groups ${pop}\n",
    "\n",
    "# Merge per chr MAFs for AA subject overlap with AFR\n",
    "#ancestry=\"aa\"\n",
    "#pop=\"AFR\"\n",
    "#head -n 1 ${ancestry}_${pop}_overlap_chr1.maf > ${ancestry}_${pop}_overlap_chr_all.maf\n",
    "#tail -q -n +2 ${ancestry}_${pop}_overlap_chr{1..23}.maf \\\n",
    "#    >> ${ancestry}_${pop}_overlap_chr_all.maf\n",
    "\n",
    "# Merge per chr MAFs for EA subject overlap with EUR\n",
    "ancestry=\"ea\"\n",
    "pop=\"EUR\"\n",
    "head -n 1 ${ancestry}_${pop}_overlap_chr1.maf > ${ancestry}_${pop}_overlap_chr_all.maf\n",
    "#tail -q -n +2 ${ancestry}_${pop}_overlap_chr{1..23}.maf \\\n",
    "tail -q -n +2 ${ancestry}_${pop}_overlap_chr{1..22}.maf \\\n",
    "    >> ${ancestry}_${pop}_overlap_chr_all.maf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Discordance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/1000g_name_recoding\n",
    "\n",
    "# Run discordance checks for each ancestry group\n",
    "#pop=\"AFR\"\n",
    "#ancestry=\"aa\"\n",
    "#/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#    --job_name ${ancestry}_crosscheck \\\n",
    "#    --script_prefix ${ancestry}_chr_all_renamed_1000g_discordance_check \\\n",
    "#    --mem 6 \\\n",
    "#    --priority 0 \\\n",
    "#    --program \"Rscript /shared/bioinformatics/software/R/check_study_data_against_1000G.R \\\n",
    "#        --study_bim_file ${ancestry}_chr_all_renamed_flipped.bim \n",
    "#        --study_frq_file ${ancestry}_chr_all_renamed_flipped.frq \n",
    "#        --ref_maf_file 1000g_data/${ancestry}_${pop}_overlap_chr_all.maf \n",
    "#        --out_prefix ${ancestry}_chr_all_renamed_1000g_discordance_check\"\n",
    "#\n",
    "\n",
    "pop=\"EUR\"\n",
    "ancestry=\"ea\"\n",
    "/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name ${ancestry}_crosscheck \\\n",
    "    --script_prefix ${ancestry}_chr_all_renamed_1000g_discordance_check \\\n",
    "    --mem 6 \\\n",
    "    --priority 0 \\\n",
    "    --program \"Rscript /shared/bioinformatics/software/R/check_study_data_against_1000G.R \\\n",
    "        --study_bim_file ${ancestry}_chr_all_renamed_flipped.bim\n",
    "        --study_frq_file ${ancestry}_chr_all_renamed_flipped.frq\n",
    "        --ref_maf_file 1000g_data/${ancestry}_${pop}_overlap_chr_all.maf\n",
    "        --out_prefix ${ancestry}_chr_all_renamed_1000g_discordance_check\"\n",
    "\n",
    "# Print summary of discordances\n",
    "for ancestry in {ea,aa}; do\n",
    "    echo \"${ancestry}_chr_all_renamed_1000g_discordance_check.summary\"\n",
    "    cat ${ancestry}_chr_all_renamed_1000g_discordance_check.summary\n",
    "done\n",
    "\n",
    "\n",
    "'''\n",
    "=========================ea=============================\n",
    "discordant_positions    0\n",
    "discordant_names        0\n",
    "discordant_alleles      534\n",
    "discordant_alleles_not_fixed_by_strand_flip     489\n",
    "discordant_alleles_polymorphic_in_study_not_fixed_by_strand_flip        0\n",
    "at_cg_snps_freq_diff_gt_0.2     0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/processing/1000g_name_recoding\n",
    "\n",
    "# Flip discordant alleles that are fixed by flipping\n",
    "#for ancestry in {ea,aa}; do\n",
    "ancestry=\"ea\"\n",
    "    comm -23 <(tail -n +2 ${ancestry}_chr_all_renamed_1000g_discordance_check.discordant_alleles | cut -f2,2 | sort -u) \\\n",
    "        <(tail -n +2 ${ancestry}_chr_all_renamed_1000g_discordance_check.discordant_alleles_not_fixed_by_strand_flip | cut -f2,2 | sort -u) \\\n",
    "        > ${ancestry}_chr_all_renamed_1000g_discordance_check.flip\n",
    "\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile ${ancestry}_chr_all_renamed_flipped \\\n",
    "        --flip ${ancestry}_chr_all_renamed_1000g_discordance_check.flip \\\n",
    "        --make-bed \\\n",
    "        --out ${ancestry}_chr_all_renamed_final_flip\n",
    "#done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observed genotype finalization\n",
    "As a starting point for haplotype phasing and imputation, I store the final QC processed PLINK binary fileset in a new directory `final`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/\n",
    "\n",
    "mkdir final\n",
    "\n",
    "# Copy file sets to final directory\n",
    "for ancestry in {ea,aa}; do\n",
    "    for ext in {bed,bim,fam}; do\n",
    "        cp processing/1000g_name_recoding/${ancestry}_chr_all_renamed_final_flip.${ext} final/${ancestry}_chr_all.${ext}\n",
    "    done\n",
    "done\n",
    "\n",
    "\n",
    "# compress\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original/final\n",
    "for f in *; do\n",
    "    gzip $f\n",
    "done &\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Final upload to S3\n",
    "Once the QC process has been verified, I can delete the processing files on S3 and upload the compressed final {.bim,.fam,.bed} files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EC2 ##\n",
    "cd /shared/data/studies/phs000634_lung_cancer/genotype/original\n",
    "\n",
    "aws s3 cp final s3://rti-common/dbGaP/phs000634_lung_cancer/genotype/original/final  --recursive --quiet &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "812px",
    "left": "0px",
    "right": "1468px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

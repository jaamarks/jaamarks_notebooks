{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGC UHS4 FOU GWAS\n",
    "__Author:__ Jesse Marks\n",
    "\n",
    "This document logs the steps taken to perform a GWAS on the UHS4 data using the frequency of opioid use (FOU) phenotype. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software and tools\n",
    "The software and tools used for processing these data are\n",
    "\n",
    "* [Amazon Elastic Compute Cloud(EC2)](https://aws.amazon.com/ec2/)\n",
    "* GNU bash version 4.1.2\n",
    "* [PLINK v1.9 beta 3.45](https://www.cog-genomics.org/plink/)\n",
    "* [EIGENSOFT v4.2](https://www.hsph.harvard.edu/alkes-price/software/)\n",
    "* [R v3.2.3](https://www.r-project.org/)\n",
    "* R packages: MASS, moments\n",
    "* [RVtests](https://render.githubusercontent.com/view/ipynb?commit=3bb8e661ad8b75af027ed2748133452ec251aaed&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f525449496e7465726e6174696f6e616c2f6271756163685f6e6f7465626f6f6b732f336262386536363161643862373561663032376564323734383133333435326563323531616165642f6865726f696e5f70726f6a6563742f646576656c6f702f32303138303131305f756873325f756873335f666f755f677761732e6970796e623f746f6b656e3d41664d79344e373237626e764465456f46535a697770346b48776246577964706b7335617570495a7741253344253344&nwo=RTIInternational%2Fbquach_notebooks&path=heroin_project%2Fdevelop%2F20180110_uhs2_uhs3_fou_gwas.ipynb&repository_id=105297875&repository_type=Repository)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description\n",
    "### genotype data\n",
    "\n",
    "Downloaded from `s3://rti-heroin/ngc_vidus_fou/data/genotype`\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "### phenotype data\n",
    "Downloaded from `s3://rti-midas-data/studies/vidus/phenotypes/unprocessed/GWAS-Cohort-n938_passed_g_qc_only_opioid_FOU.csv`\n",
    "There are 300 subjects in this FOU file. For more information on about these data see `//RTPNFIL02/eojohnson/VIDUS dx/Phenotype data/documentation/Phenotype QC_recoding documentation.pdf`\n",
    "\n",
    "* female (sex): 0=male & 1=female\n",
    "* ageatint: Age at time of interview\n",
    "* useropioid6mfq: Combined heroin and prescription use variable to generate opioid use in past 6 months.\n",
    "\n",
    "We will perform a Box-Cox transformation on the FOU phenotype variable so that ultimately our phenotype variable will be:\n",
    "$$zscore(boxcox(\\text{useropioid6mfq}+1))$$\n",
    "\n",
    "### Variable information\n",
    "The data have already been filtered to\n",
    "* Remove subjects with Useropioid6mfq == 0\n",
    "* Remove duplicate subjects by keeping only the more recent data record\n",
    "* Remove subjects with previously reported sex discrepancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data and Create Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create directory structure ##\n",
    "study=\"vidus\"\n",
    "anlist=\"ea\" \n",
    "genD=/shared/jmarks/heroin/$study/genotype/observed/ # location of QC'ed genotype data\n",
    "gwasD=/shared/jmarks/heroin/$study/gwas/fou # base processing dir\n",
    "phenD=/shared/jmarks/heroin/$study/phenotype # base phenotype dir\n",
    "eig=$phenD/processing/eig # location of PCA processing dir\n",
    "mkdir -p $genD $gwasD $phenD/{final,processing,unprocessed} $eig/results \n",
    "\n",
    "## Dowload imputed genotype data ##\n",
    "cd /shared/jmarks/heroin/vidus/genotype/imputed\n",
    "/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name download_imputed_data \\\n",
    "    --script_prefix s3.download \\\n",
    "    --mem 3.5 \\\n",
    "    --nslots 1 \\\n",
    "    --priority 0 \\\n",
    "    --program aws s3 sync s3://rti-heroin/ngc_vidus_fou/data/genotype/imputed/ea .\n",
    "\n",
    "## Dowload observed genotype data ##\n",
    "cd /shared/jmarks/heroin/vidus/genotype/observed\n",
    "aws s3 cp s3://rti-heroin/ngc_vidus_fou/data/genotype/observed/ea/ea_chr_all.bed.gz .\n",
    "aws s3 cp s3://rti-heroin/ngc_vidus_fou/data/genotype/observed/ea/ea_chr_all.bim.gz .\n",
    "aws s3 cp s3://rti-heroin/ngc_vidus_fou/data/genotype/observed/ea/ea_chr_all.fam.gz .\n",
    "\n",
    "## Download semi-processed phenotype data ##\n",
    "cd /shared/jmarks/heroin/vidus/phenotype/unprocessed\n",
    "aws s3 cp s3://rti-midas-data/studies/vidus/phenotypes/unprocessed/GWAS-Cohort-n938_passed_g_qc_only_opioid_FOU.csv ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Files for Analysis\n",
    "We follow the process outlined in the NGC protocol for preperations of the phenotype file, even if we don't ultimately use RVTESTS for the analysis. This is so that the phenotype processing steps are consistent.\n",
    "\n",
    "## Phenotype processing\n",
    "Create phenotype files for the GWAS. We follow the instructions of the NGC protocol distributed by Eric Johnson. This protocol mandates that we create a phenotype file and a covariate file in PED format, which is what rvtests requires. See the NGC protocol for more information on this format. There are several initial filters and processing steps to be applied to the subject data.\n",
    "\n",
    "* extract ids of subjects passing genotype QC\n",
    "* Map sex coding per the NGC protocol, to 1=female & 2=male. \n",
    "\n",
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $phenD\n",
    "## Extract Variables of interest ##\n",
    "R\n",
    "df <- read.csv(\"unprocessed/GWAS-Cohort-n938_passed_g_qc_only_opioid_FOU.csv\")\n",
    "vars <- c(\"gwas_code\", \"female\", \"ageatint\", \"useropioid6mfq\")\n",
    "newdf <- df[,vars]\n",
    "newdf$gwas_code <- sprintf(\"%04d\", newdf$gwas_code)\n",
    "write.table(newdf, \"processing/vidus.phenotype.table\", quote=F, sep=\" \", row.names = F)\n",
    "\n",
    "## map sex code ##\n",
    "for an in $anlist; do\n",
    "    awk 'NR>1{if ( $2==0) { $2=2} else { $2=1 }} {print $0}' \\\n",
    "        $phenD/processing/vidus.phenotype.table > \\\n",
    "        $phenD/processing/$study.$an.phenotype_table.sex_mapped\n",
    "done\n",
    "\n",
    "## filter phenotype data to subjects that passed genotype QC ##\n",
    "for an in $anlist; do\n",
    "    cut -d ' ' -f2 $genD/*fam |\n",
    "    perl -lne '/(_93-)(\\d+)/; print $2.\"\\t\".$_'  >\\\n",
    "        $phenD/processing/$study.$an.genotype.IDs.4digit\n",
    "done\n",
    "\n",
    "# also map the 4 digit number in the phenotype file to the whole genotype ID\n",
    "for an in $anlist; do\n",
    "    awk ' FNR==NR{ map[$1]=$2; next} FNR>=2{$1=map[$1]} {print $0};' \\\n",
    "        $phenD/processing/$study.$an.genotype.IDs.4digit \\\n",
    "        $phenD/processing/$study.$an.phenotype_table.sex_mapped > \\\n",
    "        $phenD/processing/$study.$an.phenotype_table.sex_mapped.passed_qc\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenotype visualization\n",
    "#### Box-Cox Transformation\n",
    "Remove individuals with a 0 for FOU and then shift the Box-Cox transformation to a left-anchored distribution at 1.0 (i.e. 1.0 being the lowest value: e.g., once per day or one day per month). Also, add constant 1 to all responses to deal with the fractional responses that are less than 1? \n",
    "\n",
    "| Ancestry | Samples Removed (FOU==0) | Total Samples |\n",
    "|----------|--------------------------|---------------|\n",
    "| EA       |                          | 300           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EA count:  300 \n",
      "\n",
      "EA count after removing samples with FOU==0:  300 \n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): unable to start png() device\n",
     "output_type": "error",
     "traceback": [
      "Error in png(tf, width, height, \"in\", pointsize, bg, res, antialias = antialias): unable to start png() device\nTraceback:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Plot with title \"EA FOU Z-scores\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### R console ###\n",
    "library(MASS)\n",
    "options(repr.plot.width=10, repr.plot.height=17)\n",
    "# note that I copied over the phenotype data to my local machine to produce the plots\n",
    "setwd('C:/Users/jmarks/OneDrive - Research Triangle Institute/Projects/heroin/ngc/vidus/fou/phenotype/processing/')\n",
    "phenotype <- \"useropioid6mfq\"\n",
    "\n",
    "ea.fou.data <- read.table(\"vidus.ea.phenotype_table.sex_mapped.passed_qc\", header = T)\n",
    "#aa.fou.data <- read.table(\"uhs4.aa.phenotype_table.sex_mapped.passed_qc\", header = T)\n",
    "\n",
    "cat(\"EA count: \", length(get(phenotype, ea.fou.data)), \"\\n\\n\")\n",
    "#cat(\"AA count: \", length(aa.fou.data$useropioid6mfq), \"\\n\\n\\n\\n\")\n",
    "\n",
    "\n",
    "## Remove individuals with 0 for FOU\n",
    "ea.fou.data <- ea.fou.data[which(get(phenotype, ea.fou.data)!=0),]\n",
    "#aa.fou.data <- aa.fou.data[which(aa.fou.data$useropioid6mfq!=0),]\n",
    "cat(\"EA count after removing samples with FOU==0: \", length(get(phenotype, ea.fou.data)), \"\\n\\n\")\n",
    "#cat(\"AA count after removing samples with FOU==0: \", length(aa.fou.data$useropioid6mfq), \"\\n\\n\")\n",
    "#\n",
    "par(mfrow=c(2,2))\n",
    "## Perform boxcox transform ##\n",
    "ea.boxcox <- boxcox(useropioid6mfq+1 ~ ageatint + female, data=ea.fou.data)\n",
    "#aa.boxcox <- boxcox(useropioid6mfq+1 ~ age + sex_selfreport, data=aa.fou.data)\n",
    "ea.lambda <- ea.boxcox$x[which(ea.boxcox$y==max(ea.boxcox$y))]\n",
    "#aa.lambda <- aa.boxcox$x[which(aa.boxcox$y==max(aa.boxcox$y))]\n",
    "#\n",
    "## Convert to Z-scores ##\n",
    "ea.zscore <- scale((ea.fou.data$useropioid6mfq+1)^ea.lambda, center=T, scale=T)\n",
    "#aa.zscore <- scale((aa.fou.data$useropioid6mfq+1)^aa.lambda, center=T, scale=T)\n",
    "#\n",
    "hist(ea.fou.data$useropioid6mfq+1, breaks=30, col=\"red3\", \n",
    "     border=\"white\", main=\"EA FOU (useropioid6mfq)\", xlab=\"FOU\")\n",
    "#hist(aa.fou.data$useropioid6mfq+1, breaks=30, col=\"red3\", \n",
    "#     border=\"white\", main=\"AA FOU (useropioid6mfq)\", xlab=\"FOU\")\n",
    "hist((ea.fou.data$useropioid6mfq+1)^ea.lambda, breaks=30, col=\"red3\",\n",
    "     border=\"white\", main=\"EA FOU Box-Cox\", xlab=\"Transformed FOU\")\n",
    "#hist((aa.fou.data$useropioid6mfq+1)^aa.lambda, breaks=30, col=\"red3\",\n",
    "#     border=\"white\", main=\"AA FOU Box-Cox\", xlab=\"Transformed FOU\")\n",
    "hist(ea.zscore, breaks=30, col=\"red3\", border=\"white\", main=\"EA FOU Z-scores\", xlab=\"Z-score\", xlim=c(-2,3))\n",
    "#hist(aa.zscore, breaks=30, col=\"red3\", border=\"white\", main=\"AA FOU Z-scores\", xlab=\"Z-score\", xlim=c(-2,3))\n",
    "#\n",
    "ea.fou.data$useropioid6mfq <- ea.zscore\n",
    "#aa.fou.data$useropioid6mfq <- aa.zscore\n",
    "#\n",
    "#write.table(ea.fou.data,\"uhs4.ea.phenotype_table.sex_mapped.passed_qc.box_cox\" , sep = \"\\t\", row.names = F, quote=F)\n",
    "#write.table(aa.fou.data,\"uhs4.aa.phenotype_table.sex_mapped.passed_qc.box_cox\" , sep = \"\\t\", row.names = F, quote=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age + Sex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=5)\n",
    "\n",
    "#cat(\"========EA Age Table========\")\n",
    "#table(ea.fou.data$age)\n",
    "#cat(\"\\n\\n========AA Age Table========\")\n",
    "#table(aa.fou.data$age)\n",
    "\n",
    "cat(\"========EA Sex Table========\")\n",
    "table(ea.fou.data$sex)\n",
    "cat(\"\\n\\n========AA Sex Table========\")\n",
    "table(aa.fou.data$sex)\n",
    "\n",
    "par(mfrow=c(1,2))\n",
    "\n",
    "# Plot age\n",
    "hist(ea.fou.data$age, breaks=30, col=\"red3\", border=\"white\",\n",
    "     main=\"EA Age Distribution\", xlab=\"Age in Years\")\n",
    "hist(aa.fou.data$age, breaks=30, col=\"red3\", border=\"white\",\n",
    "     main=\"AA Age Distribution\", xlab=\"Age in Years\")\n",
    "\n",
    "par(mfrow=c(1,2))\n",
    "# Plot sex\n",
    "hist(ea.fou.data$sex, breaks=2, col=\"blue3\", border=\"white\", \n",
    "     main=\"EA Sex Distribution\", xlab=\"1=Female, 2=Male\", labels=T, ylim= c(0,700))\n",
    "hist(aa.fou.data$sex, breaks=2, col=\"blue3\", border=\"white\", \n",
    "     main=\"AA Sex Distribution\", xlab=\"1=Female, 2=Male\", labels=T, ylim= c(0,700))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## upload to EC2\n",
    "cd /shared/jmarks/heroin/uhs4/phenotype/processing\n",
    "scp -i ~/.ssh/gwas_rsa *box_cox ec2-user@34.206.166.72:/shared/jmarks/heroin/uhs4/phenotype/processing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control for Population Stratification (EIGENSTRAT)\n",
    "In a GWAS model, one should control for population stratification (or ancestry structure). Population stratification in GWA studies can lead to spurious correlations or reduced power. One can control for stratification by including in the GWAS statisical model the top genotype principal components (PCs) as covariates. These genotype PCs capture the phenotypic variance explained by population stratification.\n",
    "\n",
    "Here we use the software tool EIGENSTRAT that performs a PCA on the genotype data. EIGENSTRAT is run on LD-pruned observed genotypes for each ancestry group.\n",
    "\n",
    "### Construct subject-filtered PLINK file sets\n",
    "Generate a new set of genotype data filtered by the phenotype information. Perform LD-pruning on these observed genotype data for the PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate new set of genotype data ##\n",
    "for an in aa ea; do\n",
    "    awk 'NR>=2{print $1,$1}' $phenD/processing/$study.$an.phenotype_table.sex_mapped.passed_qc.box_cox > \\\n",
    "        $phenD/processing/$study.$an.final_ids\n",
    "\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --bfile $genD/uhs4.merged2.$an \\\n",
    "        --keep $phenD/processing/$study.$an.final_ids \\\n",
    "        --make-bed \\\n",
    "        --out $eig/$study.$an.genotypes\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove high-LD region variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove high-LD region variants\n",
    "for an in aa ea; do\n",
    "    # Generate list of variants in known high-LD regions\n",
    "    perl -lane 'if (($F[0]==5 && $F[3] >= 43964243 && $F[3] <= 51464243) || ($F[0]==6 && $F[3] >= 24892021 && $F[3] <= 33392022) || ($F[0]==8 && $F[3] >= 7962590 && $F[3] <= 11962591) || ($F[0]==11 && $F[3] >= 45043424 && $F[3] <= 57243424)) { print $F[1].\"\\n\"; }' \\\n",
    "        $eig/$study.$an.genotypes.bim  > $eig/$study.$an.high_ld_regions.remove\n",
    "\n",
    "    # Remove SNPs in known high-LD regions\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --bfile $eig/$study.$an.genotypes \\\n",
    "        --exclude $eig/$study.$an.high_ld_regions.remove \\\n",
    "        --make-bed \\\n",
    "        --out $eig/${an}_high_ld_regions_removed\n",
    "done &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linkage disequilibrium pruning\n",
    "Linkage disequilibrium (LD) pruning eliminates a large degree of redundancy in the data and reduces the influence of chromosomal artifacts. The objective of LD pruning is to select a subset of variants based off of LD such that the variants in the subset are indepdendent. This filtering will not carry forward to the final processed results, but this step improves the quality of EIGENSTRAT calculations. Consequently, the LD pruned data will be used as input for those calculations.\n",
    "\n",
    "LD pruning is implemented using PLINK `--indep-pairwise.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove high-LD region variants\n",
    "for an in aa ea; do\n",
    "    # Run per chromosome LD pruning for each chr\n",
    "    for chr in {1..23}; do\n",
    "         /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "            --job_name ${an}_${chr}_ld_prune \\\n",
    "            --script_prefix $eig/${an}_${chr}_ld_prune \\\n",
    "            --mem 3.5 \\\n",
    "            --nslots 1 \\\n",
    "            --priority 0 \\\n",
    "            --program /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "                --noweb \\\n",
    "                --memory 3500 \\\n",
    "                --bfile $eig/${an}_high_ld_regions_removed \\\n",
    "                --indep-pairwise 1500 150 0.2 \\\n",
    "                --chr ${chr} \\\n",
    "                --out $eig/${an}_chr${chr}_ld_pruned\n",
    "    done\n",
    "done\n",
    "\n",
    "#Create LD pruned PLINK file sets\n",
    "for ancestry in aa ea; do\n",
    "    # Merge *prune.in files\n",
    "    cat $eig/${ancestry}_chr*_ld_pruned.prune.in > $eig/${ancestry}_chr_all_ld_pruned.prune.in\n",
    "    # Create new PLINK filesets with only lD pruned variants\n",
    "    /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 2048 \\\n",
    "        --bfile $eig/${ancestry}_high_ld_regions_removed \\\n",
    "        --extract $eig/${ancestry}_chr_all_ld_pruned.prune.in \\\n",
    "        --make-bed \\\n",
    "        --out $eig/${ancestry}_ld_pruned\n",
    "done\n",
    "\n",
    "\n",
    "# Clean up\n",
    "rm $eig/*ld_pruned.{prune.in,prune.out,log}\n",
    "rm $eig/*qsub*\n",
    "rm $eig/*nosex\n",
    "\n",
    "wc -l $eig/*bim\n",
    "wc -l $eig/*fam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename BIM/FAM file IDs\n",
    "Variant IDs in the PLINK bim file have the potential issue of being too long if encoded using the 1000 Genomes Phase 3 IMPUTE2 format. This will cause smartpca to throw an error. To resolve this the IDs are replaced by numeric values. The family IDs in the PLINK fam files similarly throw an error in smartpca should the number of characters in the IDs be more than 39. For this reason, we will apply an analogous renaming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count ID lengths greater than 39 characters\n",
    "for ancestry in aa ea; do\n",
    "    echo -e \"\\n\\n======== ${ancestry} ========\\n\\n\"\n",
    "    awk '{ if(length($1)+length($2)>39){print $2} }' $eig/${ancestry}_ld_pruned.fam | wc -l\n",
    "    awk '{ if(length($2)>39){print $2} }' $eig/${ancestry}_ld_pruned.bim | wc -l\n",
    "done\n",
    "\n",
    "for ancestry in aa ea; do\n",
    "    # Rename FAM file IDs\n",
    "    # Make new FAM\n",
    "    awk '{$1=\"ID_\"NR; $2=\"ID_\"NR; print $0}' $eig/${ancestry}_ld_pruned.fam \\\n",
    "        > $eig/${ancestry}_ld_pruned_id_renamed.fam\n",
    "    awk '{ if(length($1)+length($2)>39){print $2} }' $eig/${ancestry}_ld_pruned_id_renamed.fam | wc -l\n",
    "\n",
    "#    # Rename BIM file IDs\n",
    "#    # Make new BIM\n",
    "#    awk '{$2=\"ID_\"NR; print $0}' $eig/${ancestry}_ld_pruned.bim \\\n",
    "#        > $eig/${ancestry}_ld_pruned_id_renamed.bim\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run EIGENSTRAT\n",
    "__NOTE__: For `smartpca` to run, the BIM and FAM file IDs need to be less than 39 characters in length. Often this is not a problem, but with a BIM file that has IDs renamed to the 1000 Genomes Phase 3 format, the IDs for indels can exceed the character limit. Also, the EIGENSOFT bin directory should be in ~/.bashrc as an addition to the PATH variable. If it is not, it can be added as following\n",
    "\n",
    "`export PATH=$PATH:/shared/bioinformatics/software/third_party/EIG-6.1.4/bin/` # Add EIGENSOFT bin to path\n",
    "\n",
    "The `smartpca.pl` program documentation is shown below:\n",
    "\n",
    "\n",
    "DOCUMENTATION of `smartpca.pl` program:\n",
    "\n",
    "This program calls the `smartpca` program (see ../POPGEN/README). \n",
    "For this to work, the bin directory containing `smartpca` MUST be in your path. \n",
    "See `./example.perl` for a toy example.\n",
    "```\n",
    "../bin/smartpca.pl \n",
    "-i example.geno  : genotype file in any format (see ../CONVERTF/README)\n",
    "-a example.snp   : snp file in any format (see ../CONVERTF/README)\n",
    "-b example.ind   : indiv file in any format (see ../CONVERTF/README)\n",
    "-k k             : (Default is 10) number of principal components to output\n",
    "-o example.pca   : output file of principal components.  Individuals removed\n",
    "                   as outliers will have all values set to 0.0 in this file.\n",
    "-p example.plot  : prefix of output plot files of top 2 principal components.\n",
    "                   (labeling individuals according to labels in indiv file)\n",
    "-e example.eval  : output file of all eigenvalues\n",
    "-l example.log   : output logfile\n",
    "-m maxiter       : (Default is 5) maximum number of outlier removal iterations.\n",
    "                   To turn off outlier removal, set -m 0.\n",
    "-t topk          : (Default is 10) number of principal components along which \n",
    "                   to remove outliers during each outlier removal iteration.\n",
    "-s sigma         : (Default is 6.0) number of standard deviations which an\n",
    "                   individual must exceed, along one of topk top principal\n",
    "           components, in order to be removed as an outlier.\n",
    "\n",
    "OPTIONAL FLAGS:\n",
    "-w poplist       : compute eigenvectors using populations in poplist only,\n",
    "                   where poplist is an ASCII file with one population per line\n",
    "-y plotlist      : output plot will include populations in plotlist only, \n",
    "                   where plotlist is an ASCII file with one population per line\n",
    "-z badsnpname    : list of SNPs which should be excluded from the analysis\n",
    "-q YES/NO        : If set to YES, assume that there is a single population and\n",
    "                   the population field contains real-valued phenotypes.\n",
    "           (Corresponds to qtmode parameter in smartpca program.)\n",
    "           The default value for this parameter is NO.\n",
    "\n",
    "Estimated running time of the smartpca program is \n",
    "  2.5e-12 * nSNP * NSAMPLES^2 hours            if not removing outliers.\n",
    "  2.5e-12 * nSNP * NSAMPLES^2 hours * (1+m)    if m outlier removal iterations.\n",
    "Thus, under the default of up to 5 outlier removal iterations, running time is \n",
    "  up to 1.5e-11 * nSNP * NSAMPLES^2 hours.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run smartpca\n",
    "for ancestry in aa ea; do\n",
    "    famfile=\"$eig/${ancestry}_ld_pruned_id_renamed.fam\"\n",
    "    bimfile=\"$eig/${ancestry}_ld_pruned.bim\"\n",
    "    bedfile=\"$eig/${ancestry}_ld_pruned.bed\"\n",
    "\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name $study.smartpca.$ancestry \\\n",
    "        --script_prefix $eig/results/smartpca.$study.${ancestry} \\\n",
    "        --mem 7.5 \\\n",
    "        --nslots 1 \\\n",
    "        --priority 0 \\\n",
    "        --program /shared/bioinformatics/software/third_party/EIG-6.1.4/bin/smartpca.perl \\\n",
    "            -i $bedfile \\\n",
    "            -a $bimfile \\\n",
    "            -b $famfile \\\n",
    "            -o $eig/results/${ancestry}_ld_pruned.pca \\\n",
    "            -p $eig/results/${ancestry}_ld_pruned.plot \\\n",
    "            -e $eig/results/${ancestry}_ld_pruned.eval \\\n",
    "            -l $eig/results/${ancestry}_ld_pruned.pca.log \\\n",
    "            -m 0\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab top 10 eigenvectors from PCA \n",
    "for ancestry in aa ea; do\n",
    "    echo \"FID IID EV1 EV2 EV3 EV4 EV5 EV6 EV7 EV8 EV9 EV10\" > $eig/results/${ancestry}_ld_pruned_top10_eigenvecs.txt\n",
    "    tail -n +2 $eig/results/${ancestry}_ld_pruned.pca.evec | \\\n",
    "        perl -lne 's/:/ /; @F=split; print join(\" \",$F[0],$F[1],$F[2],$F[3],$F[4],$F[5],$F[6],$F[7],$F[8],$F[9],$F[10],$F[11]);' \\\n",
    "        >> $eig/results/${ancestry}_ld_pruned_top10_eigenvecs.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View PCs from EIGENSTRAT\n",
    "Copy results over to local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## local machine ##\n",
    "cd ~/Desktop/Projects/heroin/ngc/uhs4/phenotype/processing/eig\n",
    "scp -i ~/.ssh/gwas_rsa ec2-user@34.206.166.72:/shared/jmarks/heroin/uhs4/phenotype/processing/eig/results/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PCA data\n",
    "setwd(\"C:/Users/jmarks/OneDrive - Research Triangle Institute/Projects/heroin/ngc/uhs4/phenotype/processing/eig/\")\n",
    "options(stringsAsFactors=F)\n",
    "ea.evec <- read.table(\"ea_ld_pruned.pca.evec\",\n",
    "                      comment.char=\"#\", sep=\"\", row.names=1)\n",
    "ea.evec[1:5,]\n",
    "aa.evec <- read.table(\"aa_ld_pruned.pca.evec\",\n",
    "                      comment.char=\"#\", sep=\"\", row.names=1)\n",
    "aa.evec[1:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### R console ###\n",
    "\n",
    "# Function for plotting off-diagonal scatterplots\n",
    "plot.offdiag <- function(x, y, colors=label.colors){\n",
    "    #Make x and y axes equal\n",
    "    limits <- c(min(x,y), max(x,y)) * 1.3\n",
    "    par(usr = c(limits, limits))\n",
    "    points(x,y, col=colors, pch=16)\n",
    "}\n",
    "\n",
    "# Function for plotting diagonal density plots\n",
    "plot.diag <- function(x, colors=label.colors){\n",
    "    d <- density(x, bw=0.01, kernel=\"gaussian\")\n",
    "    #Update plot axes limits\n",
    "    par(usr = c(range(d$x), range(d$y)*1.3))\n",
    "    points(d$x,d$y, type=\"l\")\n",
    "    #Add PC values\n",
    "    points(x=x, y=jitter(rep(mean(d$y),times=d$n),factor=5), col=label.colors, pch=16)\n",
    "}\n",
    "\n",
    "## EA ##\n",
    "#Run PCA and get % variance\n",
    "ea.dspace <- ea.evec[1:10] #transformed dataspace\n",
    "\n",
    "#Color label samples\n",
    "label.colors <- rgb(0,80,190,80, maxColorValue=255) #blue\n",
    "\n",
    "options(repr.plot.width=8, repr.plot.height=8)\n",
    "#Redefine outer margin\n",
    "par(oma = c(4, 1, 2, 1))\n",
    "pairs(x=ea.dspace[,6:10], panel=plot.offdiag, diag.panel=plot.diag, \n",
    "      labels=paste0(\"PC\",6:10), label.pos=0.9, cex.labels=1.8)\n",
    "par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 1.5, 0), new=TRUE)\n",
    "plot(0, 0, type = \"n\", bty = \"n\", xaxt = \"n\", yaxt = \"n\", main=\"UHS4 EA\", cex.main=1)\n",
    "\n",
    "\n",
    "par(oma = c(4, 1, 2, 1))\n",
    "pairs(x=ea.dspace[,1:5], panel=plot.offdiag, diag.panel=plot.diag, \n",
    "      labels=paste0(\"PC\",1:5), label.pos=0.9, cex.labels=1.8)\n",
    "par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 1.5, 0), new=TRUE)\n",
    "plot(0, 0, type = \"n\", bty = \"n\", xaxt = \"n\", yaxt = \"n\", main=\"UHS4 EA\", cex.main=1)\n",
    "\n",
    "## AA ##\n",
    "#Run PCA and get % variance\n",
    "aa.dspace <- aa.evec[1:10] #transformed dataspace\n",
    "\n",
    "#Color label samples\n",
    "label.colors <- rgb(0,80,190,80, maxColorValue=255) #blue\n",
    "\n",
    "options(repr.plot.width=8, repr.plot.height=8)\n",
    "#Redefine outer margin\n",
    "par(oma = c(4, 1, 2, 1))\n",
    "pairs(x=aa.dspace[,6:10], panel=plot.offdiag, diag.panel=plot.diag, \n",
    "      labels=paste0(\"PC\",6:10), label.pos=0.9, cex.labels=1.8)\n",
    "par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 1.5, 0), new=TRUE)\n",
    "plot(0, 0, type = \"n\", bty = \"n\", xaxt = \"n\", yaxt = \"n\", main=\"UHS4 AA\", cex.main=1)\n",
    "\n",
    "\n",
    "par(oma = c(4, 1, 2, 1))\n",
    "pairs(x=aa.dspace[,1:5], panel=plot.offdiag, diag.panel=plot.diag, \n",
    "      labels=paste0(\"PC\",1:5), label.pos=0.9, cex.labels=1.8)\n",
    "par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 1.5, 0), new=TRUE)\n",
    "plot(0, 0, type = \"n\", bty = \"n\", xaxt = \"n\", yaxt = \"n\", main=\"UHS4 AA\", cex.main=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PC Selection\n",
    "Determine which PCs (eigenvectors) contribute the most influence and include them in the GWAS as covariates. Include the PCs which contribute to at least %75 of the variance. Make PED format phenotype and covariate file according to the NGC protocol.\n",
    "\n",
    "\n",
    "#### Create ped file\n",
    "The GWAS software tool accepts a phenotype file and a covariate file. We will create those files here and refer to them as ped and cov files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pedfile <- function(phen_file, pca_file, phenotype, sex_var, covariates, study, ancestry){\n",
    "    \n",
    "    # phenotype file\n",
    "    pheno_data <- read.delim(phen_file, sep=\"\")\n",
    "    pca_data <- read.delim(pca_file, sep=\"\")\n",
    "    other_pedcols <- c(\"fid\", \"iid\", \"patid\", \"matid\", sex_var)\n",
    "    ped_width <- length(other_pedcols) + length(phenotype)\n",
    "    ped_length <- nrow(pheno_data)\n",
    "    ped_file <- data.frame(matrix(ncol=ped_width, nrow=ped_length))\n",
    "    colnames(ped_file) <- c(other_pedcols, phenotype)\n",
    "    ped_file[phenotype] <- pheno_data[phenotype]\n",
    "    ped_file[sex_var] <- pheno_data[sex_var]\n",
    "    ped_file[\"fid\"] <- pheno_data[1]\n",
    "    ped_file[\"iid\"] <- pheno_data[1]\n",
    "    # covariate file\n",
    "    num_cols <- 14 + length(covs)\n",
    "    covar_data <- data.frame(matrix(ncol=num_cols, nrow=ped_length))\n",
    "    colnames(covar_data) <- c(\"fid\", \"iid\", \"patid\", \"matid\", covs,\n",
    "                             \"PC1\", \"PC2\",\"PC3\",\"PC4\",\"PC5\",\"PC6\",\"PC7\",\"PC8\",\"PC9\",\"PC10\")\n",
    "    covar_data[,1:4] <- ped_file[, 1:4]\n",
    "    for (i in covs){\n",
    "        covar_data[,i] <- pheno_data[,i]\n",
    "    }\n",
    "    \n",
    "    covar_data[, (num_cols-9):num_cols] <- pca_data[,3:12]\n",
    "    write.table(ped_file, paste(study,\"_\", ancestry, \"_phen.ped\", sep=\"\"), sep = \"\\t\", row.names = F, quote=F)\n",
    "    write.table(covar_data, paste(study,\"_\", ancestry, \"_cov.ped\", sep=\"\"), sep = \"\\t\", row.names = F, quote=F)\n",
    "    head(ped_file)\n",
    "    #head(covar_data)\n",
    "    \n",
    "    } # end function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression analysis\n",
    "We use a regression model of the general structure:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\text{Phenotype = PC1 + PC2 + ... + PC10}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_analysis <- function(cov_file, phen_file, phenotype_name, model_type, ancestry){\n",
    "    options(stringsAsFactors=F)\n",
    "    \n",
    "    cov_data <- read.delim(cov_file, sep=\"\")\n",
    "    phen_data <- read.delim(phen_file, sep=\"\")\n",
    "    pc_names <- paste0(\"PC\", 1:10)\n",
    "    merge_data <- merge(x=phen_data[,c(\"iid\", phenotype_name)], y=cov_data[, c(\"iid\", pc_names)], by=\"iid\")\n",
    "    \n",
    "    model.str <- paste0(phenotype_name, \"~\", paste(pc_names, collapse=\" + \")) \n",
    "    cat(\"MODEL FORMULA:\\n\\n\", model.str, \"\\n\")\n",
    "    \n",
    "    # Get model fits\n",
    "    if (model_type==\"continuous\"){\n",
    "        model_fit <- lm(formula=as.formula(model.str), data=merge_data)\n",
    "        pve_calc <- \"Mean Sq\"\n",
    "    }\n",
    "    else if (model_type==\"logistic\"){\n",
    "        model_fit <- glm(formula=as.formula(model.str), data=merge_data, family=binomial(link=\"logit\"))\n",
    "        pve_calc <- \"Deviance\"\n",
    "    }\n",
    "    \n",
    "    # Get sequential (type I) sum of squares\n",
    "    anova_model <- anova(model_fit)\n",
    "    \n",
    "    # Calculate percent variance explained and sort\n",
    "    variance_explained <- cbind(anova_model[pc_names,], \n",
    "                    PVE=round(anova_model[pc_names, pve_calc]/sum(anova_model[pc_names, pve_calc])*100, digits=2))\n",
    "    pve_sorted <- variance_explained[order(variance_explained$PVE, decreasing=T),]\n",
    "    \n",
    "    # Output regression info\n",
    "    cat(paste(\"\\n\\n================\", ancestry,  \"group ================\\n\"))\n",
    "    summary(model_fit)\n",
    "    pve_sorted\n",
    "    \n",
    "    # Percent Variance Explained Visualization\n",
    "    options(repr.plot.width=13, repr.plot.height=5)\n",
    "\n",
    "    # Set graphical parameters\n",
    "    cex.factor <- 0.9\n",
    "    barplot_ylim <- c(0, max(variance_explained$PVE)*1.2)\n",
    "\n",
    "    pv_list <- vector(length = 10)\n",
    "    total <- 0\n",
    "    for (i in 1:nrow(pve_sorted)){\n",
    "        pv_list[i] <- row.names(pve_sorted[i,])\n",
    "        total <- total + pve_sorted[i, \"PVE\"]\n",
    "        #print(total)\n",
    "        if (total >= 75) break\n",
    "    }\n",
    "\n",
    "    topPCs <- pv_list[which(pv_list != \"FALSE\")]\n",
    "    cat(\"Top PCs: \",topPCs, \"\\n\")\n",
    "    cat(paste(\"PVE:     \", total))\n",
    "\n",
    "    # Visualize PVE\n",
    "    par(mfrow=c(1,2))\n",
    "    barplot(height=variance_explained$PVE, names.arg=rownames(variance_explained), beside=T, cex.names=cex.factor, \n",
    "            col=\"red3\", border=\"red3\", ylim=barplot_ylim, \n",
    "            main=paste(ancestry,\"Percent Variance Explained\"), ylab=\"PVE\")\n",
    "    plot(cumsum(variance_explained$PVE), type=\"b\", main=paste(ancestry, \"PVE Cumulative Sum\"), ylab=\"PVE\", \n",
    "         lwd=2, col=\"red3\", pch=17, xaxt=\"n\", xlab=\"\", ylim=c(0,100))\n",
    "    axis(side=1, at=c(1:10), labels=rownames(variance_explained), cex.axis=cex.factor)\n",
    "\n",
    "    par(mfrow=c(1,2))\n",
    "    barplot(height=pve_sorted$PVE, names.arg=rownames(pve_sorted), beside=T, cex.names=cex.factor, \n",
    "            col=\"red3\", border=\"red3\", ylim=barplot_ylim, main=paste(ancestry,\"Percent Variance Explained (Sorted PCs)\"), ylab=\"PVE\")\n",
    "    plot(cumsum(pve_sorted$PVE), type=\"b\", main=paste(ancestry,\"PVE Cumulative Sum (Sorted PCs)\"), ylab=\"PVE\", \n",
    "         lwd=2, col=\"red3\", pch=17, xaxt=\"n\", xlab=\"\", ylim=c(0,100))\n",
    "    axis(side=1, at=c(1:10), labels=rownames(pve_sorted), cex.axis=cex.factor)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study <- \"UHS4\"\n",
    "ancestry <- \"AFR\" # EUR or AFR\n",
    "phenotype <- \"totopioid_tot_30d\"\n",
    "sex_var <-  \"sex_selfreport\"\n",
    "covs <- c(\"sex_selfreport\", \"age\")\n",
    "setwd(\"C:/Users/jmarks/OneDrive - Research Triangle Institute/Projects/heroin/ngc/uhs4/phenotype/processing/\")\n",
    "phen_file <- \"C:/Users/jmarks/OneDrive - Research Triangle Institute/Projects/heroin/ngc/uhs4/phenotype/processing/eig/uhs4.aa.phenotype_table.sex_mapped.passed_qc.box_cox\"\n",
    "pca_file <- \"C:/Users/jmarks/OneDrive - Research Triangle Institute/Projects/heroin/ngc/uhs4/phenotype/processing/eig/aa_ld_pruned_top10_eigenvecs.txt\"\n",
    "model_type <- \"continuous\" # continuous or logistic\n",
    "cov2 <- paste(study, ancestry, \"cov.ped\", sep=\"_\")\n",
    "phen2 <- paste(study, ancestry, \"phen.ped\", sep=\"_\")\n",
    "\n",
    "create_pedfile(phen_file=phen_file, pca_file=pca_file, phenotype=phenotype,\n",
    "               sex_var=sex_var, covariates=cov_file, study=study, ancestry=ancestry)\n",
    "regression_analysis(cov_file=cov2, phen_file=phen2,\n",
    "                    phenotype_name=phenotype, model_type=model_type,\n",
    "                    ancestry=ancestry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"C:/Users/jmarks/OneDrive - Research Triangle Institute/Projects/heroin/ngc/uhs4/phenotype/processing/\")\n",
    "\n",
    "study <- \"UHS4\"\n",
    "ancestry <- \"EUR\" # EUR or AFR\n",
    "phenotype <- \"totopioid_tot_30d\"\n",
    "covs <- c(\"age\", \"sex_selfreport\")\n",
    "phen_file <- \"C:/Users/jmarks/OneDrive - Research Triangle Institute/Projects/heroin/ngc/uhs4/phenotype/processing/eig/uhs4.ea.phenotype_table.sex_mapped.passed_qc.box_cox\"\n",
    "pca_file <- \"C:/Users/jmarks/OneDrive - Research Triangle Institute/Projects/heroin/ngc/uhs4/phenotype/processing/eig/ea_ld_pruned_top10_eigenvecs.txt\"\n",
    "model_type <- \"continuous\" # continuous or logistic\n",
    "cov2 <- paste(study, ancestry, \"cov.ped\", sep=\"_\")\n",
    "phen2 <- paste(study, ancestry, \"phen.ped\", sep=\"_\")\n",
    "\n",
    "create_pedfile(phen_file=phen_file, pca_file=pca_file, phenotype=phenotype,\n",
    "               sex_var=sex_var, covariates=cov_file, study=study, ancestry=ancestry)\n",
    "regression_analysis(cov_file=cov2, phen_file=phen2,\n",
    "                    phenotype_name=phenotype, model_type=model_type,\n",
    "                    ancestry=ancestry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alter IID\n",
    "The imputation files have a unique ID that we must match with our IID. Specifically, the ID\n",
    "in the imputation files is of the for: <br>\n",
    "`iid_iid` <br>\n",
    "so we match our phen and cov ped files to match this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bash ##\n",
    "cd /cygdrive/c/Users/jmarks/Desktop/Projects/heroin/ngc/uhs4/phenotype/processing\n",
    "\n",
    "# AA\n",
    "awk '{OFS=\"_\"} { print $2,$2 } ' UHS4_AFR_phen.ped > new_id\n",
    "awk 'NR==FNR{ map[NR]=$1; next} FNR>=2{$2=map[FNR]} { print $0}' \\\n",
    "    new_id UHS4_AFR_phen.ped > UHS4_NGCW1_AFR_phen.ped\n",
    "awk 'BEGIN{OFS=\"\\t\"} NR==FNR{ map[NR]=$1; next} FNR>=2{$2=map[FNR] } {print $0}' \\\n",
    "    new_id UHS4_AFR_cov.ped > UHS4_NGCW1_AFR_cov.ped\n",
    "\n",
    "\n",
    "# EA\n",
    "awk '{OFS=\"_\"} { print $2,$2 } ' UHS4_EUR_phen.ped > new_id\n",
    "awk 'NR==FNR{ map[NR]=$1; next} FNR>=2{$2=map[FNR]} { print $0}' \\\n",
    "    new_id UHS4_EUR_phen.ped > UHS4_NGCW1_EUR_phen.ped\n",
    "awk 'BEGIN{OFS=\"\\t\"} NR==FNR{ map[NR]=$1; next} FNR>=2{$2=map[FNR] } {print $0}' \\\n",
    "    new_id UHS4_EUR_cov.ped > UHS4_NGCW1_EUR_cov.ped\n",
    "\n",
    "scp -i ~/.ssh/gwas_rsa *NGCW1* ec2-user@34.206.166.72:/shared/jmarks/heroin/uhs4/phenotype/processing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genotype Data\n",
    "Prepare genotype data for analysis software.\n",
    "## Inflate imputation results\n",
    "The imputed genotype data from the Michigan Imputation Server have already been inflated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run GWAS\n",
    "### Autosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command line # \n",
    "study=\"UHS4\" # should match study_name in phenotype file\n",
    "version=001\n",
    "ngc=\"fou\"\n",
    "phenotype=\"totopioid_tot_30d\"\n",
    "for ancestry in aa ea; do\n",
    "\n",
    "    if [[ $ancestry == \"aa\" ]]; then\n",
    "        covars=\"age,sex_selfreport,PC9,PC5,PC2,PC8\"\n",
    "        pop=AFR\n",
    "    elif [[ $ancestry == \"ha\" ]]; then\n",
    "        pop=AMR\n",
    "    else\n",
    "        covars=\"age,sex_selfreport,PC9,PC1,PC7,PC6\"\n",
    "        pop=EUR\n",
    "    fi\n",
    "\n",
    "    genD=/shared/jmarks/heroin/uhs4/genotype/imputed/v1/$ancestry\n",
    "    procD=/shared/jmarks/heroin/uhs4/gwas/fou/$ancestry/$version\n",
    "    phenD=/shared/jmarks/heroin/uhs4/phenotype/final\n",
    "\n",
    "    mkdir -p $procD/final\n",
    "    for chr in {1..22};do\n",
    "        mkdir -p $procD/processing/chr$chr\n",
    "    done\n",
    "\n",
    "#####################################################################################\n",
    "    # Run RVtest for autosomes\n",
    "    for chr in {1..22}; do\n",
    "        /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "            --job_name ${ancestry}_${chr}_rvtest \\\n",
    "            --script_prefix $procD/processing/chr$chr/${ancestry}_${chr}_rvtest \\\n",
    "            --mem 7.5 \\\n",
    "            --nslots 2 \\\n",
    "            --priority 0 \\\n",
    "                --program /shared/bioinformatics/software/third_party/rvtests/executable/rvtest \\\n",
    "                --inVcf $genD/chr${chr}.dose.vcf.gz \\\n",
    "                --pheno $phenD/${study}_NGCW1_${pop}_phen.ped \\\n",
    "                --pheno-name $phenotype \\\n",
    "                --covar $phenD/${study}_NGCW1_${pop}_cov.ped \\\n",
    "                --covar-name $covars \\\n",
    "                --meta score \\\n",
    "                --dosage DS \\\n",
    "                --out $procD/processing/chr$chr/$study.$pop.1000G.$ngc.chr$chr\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChrX  TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results processing\n",
    "\n",
    "### Unfiltered results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command line # \n",
    "cd /shared/sandbox/ngc_vidus-fou/data/assoc_tests\n",
    "\n",
    "# Concatenate chr results together\n",
    "ancestry=\"EUR\"\n",
    "echo -e \"\\n\\n ======== ${ancestry} ======== \\n\\n\"\n",
    "for chr in {1..22}; do\n",
    "    zgrep -P \"^${chr}\\s\" VIDUS_${ancestry}_1000G_fou_chr${chr}.MetaScore.assoc.gz\n",
    "done |\n",
    "    gzip -c > VIDUS_${ancestry}_1000G_fou.gz\n",
    "\n",
    "# Make results table\n",
    "ancestry=\"EUR\"\n",
    "outfile=VIDUS_${ancestry}_1000G_fou.assoc.table\n",
    "echo -e \"VARIANT_ID\\tCHR\\tPOSITION\\tP\\tTYPE\" > $outfile\n",
    "infile=VIDUS_${ancestry}_1000G_fou.gz\n",
    "echo \"Processing ${infile}\"\n",
    "zcat ${infile} | \\\n",
    "    perl -lane 'if (($F[2] eq \"A\" || $F[2] eq \"C\" || $F[2] eq \"G\" || $F[2] eq \"T\") && (($F[3] eq \"A\" || $F[3] eq \"C\" || $F[3] eq \"G\" || $F[3] eq \"T\"))) {\n",
    "                    print join(\"\\t\",$F[0].\":\".$F[1],$F[0],$F[1],$F[15],\"snp\");\n",
    "                } else {\n",
    "                    print join(\"\\t\",$F[0].\":\".$F[1],$F[0],$F[1],$F[15],\"indel\");\n",
    "                }' >> $outfile\n",
    "\n",
    "# Make Q-Q and manhattan plots\n",
    "ancestry=EUR\n",
    "# Plot all chromosomes\n",
    "sh /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name gwas_plots_${ancestry} \\\n",
    "    --script_prefix VIDUS_${ancestry}_1000G_fou.assoc.plot \\\n",
    "    --mem 30.6 \\\n",
    "    --priority 0 \\\n",
    "    --program Rscript /shared/bioinformatics/software/R/generate_gwas_plots.R \\\n",
    "        --in VIDUS_${ancestry}_1000G_fou.assoc.table \\\n",
    "        --in_chromosomes autosomal_nonPAR \\\n",
    "        --in_header \\\n",
    "        --out VIDUS_${ancestry}_1000G_fou.assoc.plot.all_chr \\\n",
    "        --col_id VARIANT_ID \\\n",
    "        --col_chromosome CHR \\\n",
    "        --col_position POSITION \\\n",
    "        --col_p P \\\n",
    "        --col_variant_type TYPE \\\n",
    "        --generate_snp_indel_manhattan_plot \\\n",
    "        --manhattan_odd_chr_color red3 \\\n",
    "        --manhattan_even_chr_color dodgerblue3 \\\n",
    "        --manhattan_points_cex 1.5 \\\n",
    "        --generate_snp_indel_qq_plot \\\n",
    "        --qq_lines \\\n",
    "        --qq_points_bg black \\\n",
    "        --qq_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAF > 0.01 and imputation quality > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command line # \n",
    "cd /shared/sandbox/ngc_vidus-fou/data/assoc_tests\n",
    "\n",
    "# Get list of variants to filter by imputation quality\n",
    "ancestry=\"ea\"\n",
    "for chr in {1..22}; do\n",
    "    echo -e \"${ancestry} chr${chr}...\"\n",
    "    zcat ../../genotype/imputed/vidus_imputed/chr${chr}.info.gz | \\\n",
    "        tail -n +2 | \\\n",
    "        awk '{ if($5 > 0.01 && $7 > 0.3){ print $1\":\"$2\":\"$3 } }' \\\n",
    "        > ${ancestry}_chr${chr}_variants_maf_gt_0.01_rsq_gt_0.3.keep\n",
    "done\n",
    "\n",
    "# Filter results files\n",
    "ancestry=EUR\n",
    "for chr in {1..22}; do\n",
    "    echo \"chr${chr}...\"\n",
    "    awk '{ if(NR==FNR){ map[$1]=1; next } { if(map[$1\":\"$2\":\"$3\":\"$4]==1){ print $0 } } }' \\\n",
    "        ea_chr${chr}_variants_maf_gt_0.01_rsq_gt_0.3.keep \\\n",
    "        <(zgrep -P \"^${chr}\\s\" VIDUS_${ancestry}_1000G_fou_chr${chr}.MetaScore.assoc.gz) \\\n",
    "        > VIDUS_${ancestry}_1000G_fou_chr${chr}.tmp\n",
    "done \n",
    "cat VIDUS_${ancestry}_1000G_fou_chr*tmp | gzip -c > VIDUS_${ancestry}_1000G_fou_maf_gt_0.01_rsq_gt_0.3.gz\n",
    "\n",
    "# Clean up\n",
    "rm *tmp\n",
    "\n",
    "# Make results table\n",
    "ancestry=\"EUR\"\n",
    "outfile=VIDUS_${ancestry}_1000G_fou_maf_gt_0.01_rsq_gt_0.3.assoc.table\n",
    "echo -e \"VARIANT_ID\\tCHR\\tPOSITION\\tP\\tTYPE\" > $outfile\n",
    "infile=VIDUS_${ancestry}_1000G_fou_maf_gt_0.01_rsq_gt_0.3.gz\n",
    "echo \"Processing ${infile}\"\n",
    "zcat ${infile} | \\\n",
    "    perl -lane 'if (($F[2] eq \"A\" || $F[2] eq \"C\" || $F[2] eq \"G\" || $F[2] eq \"T\") && (($F[3] eq \"A\" || $F[3] eq \"C\" || $F[3] eq \"G\" || $F[3] eq \"T\"))) {\n",
    "                    print join(\"\\t\",$F[0].\":\".$F[1],$F[0],$F[1],$F[15],\"snp\");\n",
    "                } else {\n",
    "                    print join(\"\\t\",$F[0].\":\".$F[1],$F[0],$F[1],$F[15],\"indel\");\n",
    "                }' >> $outfile\n",
    "\n",
    "# Make Q-Q and manhattan plots\n",
    "ancestry=\"EUR\"\n",
    "# Plot all chromosomes\n",
    "sh /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name gwas_plots_${ancestry} \\\n",
    "    --script_prefix VIDUS_${ancestry}_1000G_fou_maf_gt_0.01_rsq_gt_0.3.assoc.plot \\\n",
    "    --mem 30.6 \\\n",
    "    --priority 0 \\\n",
    "    --program Rscript /shared/bioinformatics/software/R/generate_gwas_plots.R \\\n",
    "        --in VIDUS_${ancestry}_1000G_fou_maf_gt_0.01_rsq_gt_0.3.assoc.table \\\n",
    "        --in_chromosomes autosomal_nonPAR \\\n",
    "        --in_header \\\n",
    "        --out VIDUS_${ancestry}_1000G_fou_maf_gt_0.01_rsq_gt_0.3.assoc.plot.all_chr \\\n",
    "        --col_id VARIANT_ID \\\n",
    "        --col_chromosome CHR \\\n",
    "        --col_position POSITION \\\n",
    "        --col_p P \\\n",
    "        --col_variant_type TYPE \\\n",
    "        --generate_snp_indel_manhattan_plot \\\n",
    "        --manhattan_odd_chr_color red3 \\\n",
    "        --manhattan_even_chr_color dodgerblue3 \\\n",
    "        --manhattan_points_cex 1.5 \\\n",
    "        --generate_snp_indel_qq_plot \\\n",
    "        --qq_lines \\\n",
    "        --qq_points_bg black \\\n",
    "        --qq_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Plots\n",
    "The NGC protocol calls for the submission of the samples projected onto 1000G superpopulation PCA space (EUR, AFR, EAS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p /shared/sandbox/ngc_vidus-fou/cohort_projected_on_1000g/1000g\n",
    "cd /shared/sandbox/ngc_vidus-fou/cohort_projected_on_1000g\n",
    "\n",
    "cp ../eigenstrat/ea_ld_pruned.bim .\n",
    "awk '{print $2}' ea_ld_pruned.bim > all_pruned_variant_ids\n",
    "\n",
    "cd 1000g\n",
    "# Rename 1000G autosome variant IDs\n",
    "ancestry=ea\n",
    "for chr in {1..22}; do\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name recode_to_1000g_${chr} \\\n",
    "        --script_prefix ${ancestry}_chr${chr}_id_rename \\\n",
    "        --mem 8 \\\n",
    "        --nslots 1 \\\n",
    "        --priority 0 \\\n",
    "        --program /shared/bioinformatics/software/perl/id_conversion/convert_to_1000g_p3_ids.pl \\\n",
    "        --file_in /shared/data/ref_panels/1000G/2013.05/plink/ALL.chr${chr}.bim \\\n",
    "        --file_out chr${chr}_renamed.bim \\\n",
    "        --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr$chr.legend.gz \\\n",
    "        --file_in_header 0 \\\n",
    "        --file_in_id_col 1 \\\n",
    "        --file_in_chr_col 0 \\\n",
    "        --file_in_pos_col 3 \\\n",
    "        --file_in_a1_col 4 \\\n",
    "        --file_in_a2_col 5 \\\n",
    "        --chr ${chr}\n",
    "done\n",
    "\n",
    "# get list of all variant IDs\n",
    "touch all_1000g_variants_renamed\n",
    "for chr in {1..22};do\n",
    "awk '{ print $2 }' chr${chr}_renamed.bim >> all_1000g_variants_renamed\n",
    "done\n",
    "\n",
    "sort all_1000g_variants_renamed > all_1000g_variants_renamed_sorted\n",
    "sort ../all_study_variants_renamed > all_study_variants_renamed_sorted\n",
    "\n",
    "# get overlap between 1000g variants and study variants (pruned)\n",
    "comm ../all_study_variants_renamed_sorted all_1000g_variants_renamed_sorted > ../variant_overlap\n",
    "\n",
    "# Get subject IDs by ancestry\n",
    "awk 'BEGIN { FS=\"\\t\"; OFS=\"\\t\" } { if($7==\"African\"){print $1,$1} }'  /shared/data/ref_panels/1000G/igsr_samples.tsv \\\n",
    "    > 1000g_subject_IDs\n",
    "awk 'BEGIN { FS=\"\\t\"; OFS=\"\\t\" } { if($7==\"East Asian\"){print $1,$1} }'  /shared/data/ref_panels/1000G/igsr_samples.tsv \\\n",
    "    >> 1000g_subject_IDs\n",
    "awk 'BEGIN { FS=\"\\t\"; OFS=\"\\t\" } { if($7==\"European\"){print $1,$1} }' /shared/data/ref_panels/1000G/igsr_samples.tsv \\\n",
    "    >> 1000g_subject_IDs\n",
    "\n",
    "\n",
    "\n",
    "# create binary filesets with ld pruned snps\n",
    "for chr in {1..22}; do\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name chr${chr}_filter \\\n",
    "        --script_prefix ancestry_partition_chr${chr} \\\n",
    "        --mem 8 \\\n",
    "        --priority 0 \\\n",
    "        --program /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink  \\\n",
    "            --noweb \\\n",
    "            --memory 10000 \\\n",
    "            --bim chr${chr}_renamed.bim \\\n",
    "            --fam /shared/data/ref_panels/1000G/2013.05/plink/ALL.chr${chr}.fam \\\n",
    "            --bed /shared/data/ref_panels/1000G/2013.05/plink/ALL.chr${chr}.bed \\\n",
    "            --bfile /shared/data/ref_panels/1000G/2013.05/plink/ALL.chr${chr} \\\n",
    "            --keep 1000g_subject_IDs \\\n",
    "            --extract ../variant_overlap \\\n",
    "            --make-bed \\\n",
    "            --out 1000g_chr${chr}_ld_pruned\n",
    "done\n",
    "\n",
    "touch autosome_merge_list.txt\n",
    "for chr in {1..22};do\n",
    "   echo \"1000g_chr${chr}_ld_pruned\" >> autosome_merge_list.txt\n",
    "done\n",
    "\n",
    "# merge 1000g autosomes\n",
    "/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name merge_plink_filesets \\\n",
    "    --script_prefix merge_plink_filesets \\\n",
    "    --mem 4 \\\n",
    "    --priority 0 \\\n",
    "    --program /shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "        --noweb \\\n",
    "        --memory 4000 \\\n",
    "        --merge-list autosome_merge_list.txt \\\n",
    "        --snps-only just-acgt \\\n",
    "        --make-bed \\\n",
    "        --out 1000g_all_auto_ld_pruned\n",
    "\n",
    "cd /shared/sandbox/ngc_vidus-fou/cohort_projected_on_1000g\n",
    "\n",
    "# filter study data to the variants that overlap with 1000g\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --memory 2048 \\\n",
    "    --bfile ea_ld_pruned \\\n",
    "    --extract variant_overlap \\\n",
    "    --exclude study_and_1000g_combined_ld_pruned-merge.missnp \\\n",
    "    --make-bed \\\n",
    "    --out ea_ld_pruned_1000g_overlap\n",
    "\n",
    "# Attempt merge 1000g with study data. produced 8 snps that were ambiguous (will remove)\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --memory 4000 \\\n",
    "    --bfile 1000g/1000g_all_auto_ld_pruned \\\n",
    "    --bmerge ea_ld_pruned_1000g_overlap \\\n",
    "    --snps-only just-acgt \\\n",
    "    --make-bed \\\n",
    "    --out study_and_1000g_combined_ld_pruned\n",
    "\n",
    "\n",
    "# Exclude ambiguous snps (polymorphic) from study data\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --memory 2048 \\\n",
    "    --bfile ea_ld_pruned_ld_pruned_1000g_overlap \\\n",
    "    --exclude study_and_1000g_combined_ld_pruned-merge.missnp \\\n",
    "    --make-bed \\\n",
    "    --out ea_ld_pruned_1000g_overlap_removed_ambig\n",
    "\n",
    "\n",
    "# Exclude ambiguous snps (polymorphic) from 1000g data\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --memory 2048 \\\n",
    "    --bfile 1000g/1000g_all_auto_ld_pruned \\\n",
    "    --exclude study_and_1000g_combined_ld_pruned-merge.missnp \\\n",
    "    --make-bed \\\n",
    "    --out 1000g/1000g_all_auto_ld_pruned_removed_ambig\n",
    "\n",
    "# Attempt merge 1000g with study data.\n",
    "/shared/bioinformatics/software/third_party/plink-1.90-beta-4.10-x86_64/plink \\\n",
    "    --noweb \\\n",
    "    --memory 4000 \\\n",
    "    --bfile 1000g/1000g_all_auto_ld_pruned_removed_ambig \\\n",
    "    --bmerge ea_ld_pruned_1000g_overlap_removed_ambig \\\n",
    "    --snps-only just-acgt \\\n",
    "    --make-bed \\\n",
    "    --out study_and_1000g_combined_ld_pruned_removed_ambig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename BIM/FAM file IDs\n",
    "BIM file IDs have the potential issue of being too long if encoded using the 1000 Genomes Phase 3 IMPUTE2 format. This will cause smartpca to throw an error. To resolve this the IDs are replaced by numeric values. FAM file IDs are treated similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC2 command line #\n",
    "cd /shared/sandbox/ngc_vidus-fou/cohort_projected_on_1000g\n",
    "\n",
    "\n",
    "# make not a case nor control in fam file\n",
    "awk '{$6= \"-9\"} {print $0}' study_and_1000g_combined_ld_pruned_removed_ambig.fam > final.fam\n",
    "\n",
    "# rename study IIDs\n",
    "awk 'NR<=300 { $2=\"ID_\"NR; } {print $0}' final.fam > final_renamed.fam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenstrat on LD pruned snps - study & 1000g merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p /shared/sandbox/ngc_vidus-fou/cohort_projected_on_1000g/results\n",
    "cd /shared/sandbox/ngc_vidus-fou/cohort_projected_on_1000g\n",
    "\n",
    "# Run smartpca\n",
    "/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name study_vs_1000g_smartpca \\\n",
    "    --script_prefix smartpca_study_vs_1000g_ \\\n",
    "    --mem 8 \\\n",
    "    --nslots 2 \\\n",
    "    --priority 0 \\\n",
    "    --program /shared/bioinformatics/software/third_party/EIG-6.1.4/bin/smartpca.perl \\\n",
    "        -i study_and_1000g_combined_ld_pruned_removed_ambig.bed \\\n",
    "        -a study_and_1000g_combined_ld_pruned_removed_ambig.bim \\\n",
    "        -b final_renamed.fam \\\n",
    "        -o results/study_and_1000g_ld_snps.pca \\\n",
    "        -p results/study_and_1000g_ld_snps.plot \\\n",
    "        -e results/study_and_1000g_ld_snps.eval \\\n",
    "        -l results/study_and_1000g_ld_snps.pca.log \\\n",
    "        -m 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /shared/sandbox/ngc_vidus-fou/cohort_projected_on_1000g/results\n",
    " \n",
    "# Get subject IDs by ancestry\n",
    "awk 'BEGIN { FS=\"\\t\"; OFS=\"\\t\" } { if($7==\"African\"){print $1} }'  /shared/data/ref_panels/1000G/igsr_samples.tsv \\\n",
    "    > AFR_1000g_subject_IDs\n",
    "awk 'BEGIN { FS=\"\\t\"; OFS=\"\\t\" } { if($7==\"East Asian\"){print $1} }'  /shared/data/ref_panels/1000G/igsr_samples.tsv \\\n",
    "    > EAS_1000g_subject_IDs\n",
    "awk 'BEGIN { FS=\"\\t\"; OFS=\"\\t\" } { if($7==\"European\"){print $1} }' /shared/data/ref_panels/1000G/igsr_samples.tsv \\\n",
    "    > EUR_1000g_subject_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /shared/sandbox/ngc_vidus-fou/cohort_projected_on_1000g/results\n",
    "# Load PCA data\n",
    "options(stringsAsFactors=F)\n",
    "study.vs_1000 <- read.table(\"study_and_1000g_ld_snps.pca.evec\", comment.char=\"#\", sep=\"\", row.names=1)\n",
    "\n",
    "# Function for plotting off-diagonal scatterplots\n",
    "plot.offdiag <- function(x, y, colors=label.colors){\n",
    "    #Make x and y axes equal\n",
    "    limits <- c(min(x,y), max(x,y)) * 1.3\n",
    "    par(usr = c(limits, limits))\n",
    "    points(x,y, col=colors, pch=16)\n",
    "}\n",
    "\n",
    "# Function for plotting diagonal density plots\n",
    "plot.diag <- function(x, colors=label.colors){\n",
    "    d <- density(x, bw=0.01, kernel=\"gaussian\")\n",
    "    #Update plot axes limits\n",
    "    par(usr = c(range(d$x), range(d$y)*1.3))\n",
    "    points(d$x,d$y, type=\"l\")\n",
    "    #Add PC values\n",
    "    points(x=x, y=jitter(rep(mean(d$y),times=d$n),factor=5), col=label.colors, pch=16)\n",
    "}\n",
    "\n",
    "#Run PCA and get % variance\n",
    "dspace <- study.vs_1000[1:10] #transformed dataspace\n",
    "\n",
    "AFR = scan(file=\"AFR_1000g_subject_IDs\", what=character())\n",
    "EAS = scan(file=\"EAS_1000g_subject_IDs\", what=character())\n",
    "EUR = scan(file=\"EUR_1000g_subject_IDs\", what=character())\n",
    "\n",
    "#Color label samples\n",
    "sample.names <- row.names(study.vs_1000)\n",
    "label.colors <- rep(NA, length(sample.names))\n",
    "label.colors[grepl(x=sample.names, pattern=\"80059|_93-\", ignore.case=F)] <- rgb(255,0,0,80, maxColorValue=255) #red\n",
    "label.colors[grepl(x=sample.names, pattern=paste(EUR,collapse=\"|\"), ignore.case=F)] <- rgb(0,0,255,80, maxColorValue=255) #blue\n",
    "label.colors[grepl(x=sample.names, pattern=paste(EAS,collapse=\"|\"), ignore.case=F)] <- rgb(0,255,0,80, maxColorValue=255) #green\n",
    "label.colors[grepl(x=sample.names, pattern=paste(AFR,collapse=\"|\"), ignore.case=F)] <- rgb(255,215,0,80, maxColorValue=255) #gold\n",
    "legend.cols <- c(rgb(255,215,0,255, maxColorValue=255), rgb(0,255,0,255, maxColorValue=255),\n",
    "                 rgb(0,0,255,255, maxColorValue=255), rgb(255,0,0,255, maxColorValue=255))\n",
    "\n",
    "options(repr.plot.width=8, repr.plot.height=8)\n",
    "#Redefine outer margin\n",
    "par(oma = c(4, 1, 2, 1))\n",
    "pairs(x=dspace[,1:4], panel=plot.offdiag, diag.panel=plot.diag, \n",
    "      labels=paste0(\"PC\",1:4), label.pos=0.9, cex.labels=1.8)\n",
    "par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 1.5, 0), new=TRUE)\n",
    "plot(0, 0, type = \"n\", bty = \"n\", xaxt = \"n\", yaxt = \"n\", main=\"Lung Cancer in Never Smokers vs 1000G\", cex.main=1)\n",
    "legend(\"bottom\", c(\"AFR\", \"EAS\", \"EUR\", \"LCNS\"), \n",
    "       pch=19, col=legend.cols,\n",
    "       xpd=TRUE, horiz=TRUE, inset=c(0,-0.02), \n",
    "       bty=\"n\", cex=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 data transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy phenotype data\n",
    "cd /shared/sandbox/ngc_vidus-fou/phenotype\n",
    "aws s3 cp ./ s3://rti-heroin/ngc_vidus_fou/data/phenotype --recursive --exclude=\"*\" --include=\"*ped.gz\" --quiet &\n",
    "\n",
    "cd /shared/sandbox/ngc_vidus-fou/data/assoc_tests\n",
    "# Copy association test results\n",
    "aws s3 cp ./ s3://rti-heroin/ngc_vidus_fou/results/rvtest/ --recursive --exclude=\"*\" --include=\"*MetaScore*gz*\" --quiet &\n",
    "aws s3 cp ./ s3://rti-heroin/ngc_vidus_fou/results/figures/ --recursive --exclude=\"*\" --include=\"*.png.gz\" --quiet &\n",
    "\n",
    "\n",
    "# copy imputation files\n",
    "cd /shared/sandbox/ngc_vidus-fou/genotype/imputed/vidus_imputed\n",
    "aws s3 cp ./ s3://rti-heroin/ngc_vidus_fou/data/genotype/imputed/${ancestry}/ --recursive --exclude \"*\" --include \"*.log\"\n",
    "aws s3 cp ./ s3://rti-heroin/ngc_vidus_fou/data/genotype/imputed/${ancestry}/ --recursive --exclude \"*\" --include \"*.info.gz\" \n",
    "aws s3 cp ./ s3://rti-heroin/ngc_vidus_fou/data/genotype/imputed/${ancestry}/ --recursive  --quiet --exclude \"*\" --include \"*dose.vcf.gz\"\n",
    "aws s3 cp ./ s3://rti-heroin/ngc_vidus_fou/data/genotype/imputed/${ancestry}/ --recursive --quiet --exclude \"*\" --include \"*dose.vcf.gz.tbi\" &\n",
    "\n",
    "\n",
    "# copy original genotype data\n",
    "cd /shared/sandbox/ngc_vidus-fou/genotype/original/final\n",
    "aws s3 cp ./ s3://rti-heroin/ngc_vidus_fou/data/genotype/original/ea/ --recursive --quiet &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "714.716px",
    "left": "0px",
    "right": "1315.28px",
    "top": "110.284px",
    "width": "245.526px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fwGWAS - Naive Method (baseline model)\n",
    "**Author:** Jesse Marks <br>\n",
    "**Date:** September 10, 2018 <br>\n",
    "**Programming Language:** Python3\n",
    "\n",
    "This is the first method we are testing for the functional weighting GWAS (fwGWAS) method comparison. We are referring to this method as the Naive Method or the baseline model. This approach&mdash;based off of the 2016 Nature Genetics paper by Sveinbjornsson et al.&mdash;uses different P-value thresholds for each sequence variant functional category. More specifically, sequence variants are grouped into four categories: <br>\n",
    "i) **loss-of-function variants** <br>\n",
    "ii) **moderate-impact variants** <br>\n",
    "iii) **low-impact variants** <br>\n",
    "iv) **other** <br>\n",
    "\n",
    "A different P-value threshold will be applied to each of these four categories based off of there functional annotation and its putative functional effects. We use the software SnpEff to annotate the variants.\n",
    "\n",
    "This notebook details the methods (functions) developed to carry out the Naive Method. A proof of concept has been performed using the data stored at:\n",
    "\n",
    "`/share/storage/Johnson/fwGWAS/data/SCZ/SCZ2/daner_PGC_SCZ49.sh2_mds10_1000G-frq_2.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SnfEff Software\n",
    "[SnpEff](http://snpeff.sourceforge.net/index.html) is a variant annotation and effect prediction tool that we will be using to perform the sequence variant annotations. It is located at: <br>\n",
    "`/share/storage/Johnson//share/storage/Johnson/software/SnpEff/`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input file\n",
    "Converting GWAS Results to Variant Call Format (VCF) is the first step because SnpEff expects an input file in VCF format. The function we developed to perform the conversion **expects the GWAS results to have very specific header names**. Because of this, if the input file does not work properly you might have to either rename the column headers or, less desired, modify the code in this function to match your headers. Specifically, the function is expecting the GWAS result to have (at least) the following 7 columns:\n",
    "\n",
    "* CHR\n",
    "* SNP\n",
    "* BP\n",
    "* A1\n",
    "* A2 \n",
    "* P\n",
    "\n",
    "The VCF file will have the header:\n",
    "\n",
    "```\n",
    "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\n",
    "```\n",
    "\n",
    "The mapping will be:\n",
    "```\n",
    "CHR --> #CHROM\n",
    "BP --> POS\n",
    "SNP --> ID\n",
    "A1 --> REF\n",
    "A2 --> ALT\n",
    "P --> INFO\n",
    "```\n",
    "The columns `QUAL` and `FILTER` in the VCF file can be left empty, or rather map a period to each entry&mdash;this is the approach shown in the examples in the SnpEff manual. The final VCF file should look like the following:\n",
    "\n",
    "```\n",
    "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\n",
    "22\t17675324\trs5748937\tT\tC\t.\t.\t0.7533\n",
    "22\t17798848\trs77501298\tC\tG\t.\t.\t0.646\n",
    "22\t17699299\trs5748957\tT\tG\t.\t.\t0.6269\n",
    "22\t17450765\trs61738794\tA\tG\t.\t.\t0.7285\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Main\n",
    "Execute all functions in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Python3 ###\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Carryout all the functions necessary to \n",
    "    perform the fwGWAS naive method.\n",
    "    \"\"\"\n",
    "    ### Variables to alter\n",
    "    data_dir = '/share/storage/Johnson/fwGWAS/data/SCZ/SCZ2/'\n",
    "    rtvf_in = data_dir + 'daner_PGC_SCZ49.sh2_mds10_1000G-frq_2.gz'\n",
    "    processing_dir = '/share/storage/Johnson/fwGWAS/method_comp/fwGWAS_SCZ2_Test5/'\n",
    "    rtvf_out = processing_dir + 'scz2-gw.vcf'\n",
    "    \n",
    "    ### DO NOT alter below this line\n",
    "    ##########################################################\n",
    "    \n",
    "    # Convert GWAS results to VCF format\n",
    "    se_inF = results_to_vcf_format(in_file=rtvf_in,\n",
    "                                   out_file=rtvf_out)\n",
    "    se_outF = se_inF[:-4] + '-ann.vcf'\n",
    "\n",
    "    # Run SnpEff to obtain annotations\n",
    "    ex_inF = snp_eff(base_dir=processing_dir, \n",
    "                     in_file=se_inF, \n",
    "                     out_file=se_outF)\n",
    "    ex_outF = ex_inF[:-4] + '-cleaned'\n",
    "\n",
    "    # Extract annotations, IDs, and P-values\n",
    "    ga_inF = extract_ann(in_file=ex_inF,\n",
    "                         out_file=ex_outF)\n",
    "    ga_outF = ga_inF + '-grouped'\n",
    "    \n",
    "    # Group variants into the four function annotation categories\n",
    "    ff_inF = group_annotations(in_file=ga_inF,\n",
    "                               out_file=ga_outF)\n",
    "    ff_outF = ff_inF + '-filtered-fw'\n",
    "    \n",
    "    # Filter using the four fw-thresholds\n",
    "    rs_inF1 = filter_fw(in_file=ff_inF,\n",
    "                        out_file=ff_outF)\n",
    "    \n",
    "    fs_outF = ff_inF + 'filtered-std'\n",
    "    \n",
    "    # Filter using the standard GWAS threshold (5e-8)\n",
    "    rs_inF2 = filter_standard(in_file=ga_outF, \n",
    "                             out_file=fs_outF)\n",
    "    rs_out = rtvf_out[:-4] + '-results-summary'\n",
    "    \n",
    "    # Get results summary\n",
    "    results_summary(in_file=rs_inF1,\n",
    "                    in_file2=rs_inF2, \n",
    "                    out_file=rs_out)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** using the SCZ2 test case (15,358,497 variants), this pipeline ran in ~9min.\n",
    "```\n",
    "00:09:00\tLogging\n",
    "00:09:05\tChecking for updates...\n",
    "00:09:08\tDone.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function1&mdash;Convert results to vcf format\n",
    "Note, a future feature could be to add a catch to report an error if the header names of the input file are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_file = /share/storage/Johnson/fwGWAS/data/SCZ/SCZ2/daner_PGC_SCZ49.sh2_mds10_1000G-frq_2.gz\n",
    "# out_file = /share/storage/Johnson/fwGWAS/method_comp/fwGWAS_SCZ2_Test4/scz2-gw.vcf\n",
    "def results_to_vcf_format(in_file, out_file):\n",
    "    \"\"\"\n",
    "    The SnpEff software expects, as input, a file in VCF format. \n",
    "    This function performs the conversion of the GWAS results \n",
    "    to VCF format so that SnpEff can obtain the annotations.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file - GWAS results file. \n",
    "    out_file - Name (and path) of the VCF file to be created.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    import gzip\n",
    "    try:\n",
    "        with gzip.open(in_file, 'rt') as inF:\n",
    "            with open(out_file, 'wt') as outF:\n",
    "                line = inF.readline()\n",
    "    \n",
    "                head_line = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "                outF.write('\\t'.join(head_line) + '\\n')\n",
    "                split_line = line.split()\n",
    "     \n",
    "                pval_index = split_line.index('P')\n",
    "                chr_index = split_line.index('CHR')\n",
    "                rsid_index = split_line.index('SNP')\n",
    "                position_index = split_line.index('BP')\n",
    "                ref_allele_index = split_line.index('A1')\n",
    "                alt_allele_index = split_line.index('A2')\n",
    "\n",
    "                # skip the header now\n",
    "                line = inF.readline()\n",
    "                while(line):\n",
    "                    split_line = line.split()\n",
    "     \n",
    "                    f1 = split_line[chr_index]\n",
    "                    f2 = split_line[position_index]\n",
    "                    f3 = split_line[rsid_index]\n",
    "                    f4 = split_line[ref_allele_index]\n",
    "                    f5 = split_line[alt_allele_index]\n",
    "                    f6 = '.'\n",
    "                    f7 = '.'\n",
    "                    f8 = split_line[pval_index]\n",
    "     \n",
    "                    vcf_list = [f1, f2, f3, f4, f5, f6, f7, f8]\n",
    "                    outF.write('\\t'.join(vcf_list) + '\\n')\n",
    "                    line = inF.readline()\n",
    "    except (OSError):\n",
    "        print(\"Please gzip your input file.\")\n",
    "    return out_file; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function2&mdash;Obtain variant annotations with SnpEff \n",
    "\n",
    "**Note**: adjust the java memory specification as needed. Default allocation is 2GB; here I specified 8GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = '/share/storage/Johnson/fwGWAS/method_comp/fwGWAS_SCZ2_Test4/'\n",
    "# in_file = base_dir + 'scz2-gw.vcf'\n",
    "# out_file = base_dir + 'scz2-gw-ann.vcf'\n",
    "def snp_eff(base_dir, in_file, out_file):\n",
    "    \"\"\"\n",
    "    This function executes the SnpEff software that annotates the\n",
    "    sequence variants using the Genome Build 37 as the reference.'\n",
    "    \n",
    "    INPUT:\n",
    "    base_dir - path were results should be saved.\n",
    "    in_file - name (and path) of VCF file for input to SnpEff\n",
    "    out_file - name of the output annotated VCF.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    \n",
    "    import subprocess\n",
    "\n",
    "    ### DO NOT modify these variables\n",
    "    ###########################################################################\n",
    "    config_path = '/share/storage/Johnson/software/SnpEff/snpEff/snpEff.config' \n",
    "    snpEff_path = '/share/storage/Johnson/software/SnpEff/snpEff/snpEff.jar'\n",
    "    snp_eff = base_dir + 'snp-eff.sh'\n",
    "    # -t for multithreading implies -noStats (speeds process way up)\n",
    "    command_list = ['java', '-Xmx8g', '-jar', snpEff_path, '-c', config_path, '-v',\n",
    "                    '-t', 'GRCh37.75', in_file, '>', out_file]\n",
    "    command_string = ' '.join(command_list)\n",
    "    ###########################################################################\n",
    "\n",
    "    # save command as a bash script\n",
    "    with open(snp_eff, 'w') as outF:\n",
    "        message = '#!/usr/bin/bash\\n'\n",
    "        message += command_string\n",
    "        outF.write(message)\n",
    "\n",
    "    # execute bash script\n",
    "    run_command = ['bash', snp_eff]\n",
    "    subprocess.run(run_command)\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function3&mdash;extract annotation information\n",
    "We might want to add the rsID field, in the future. This would change down stream behavior that we would need to address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = '/share/storage/Johnson/fwGWAS/method_comp/fwGWAS_SCZ2_Test4/'\n",
    "# in_file = base_dir + 'scz2-gw-ann.vcf'\n",
    "# out_file = base_dir +'scz2-gw-ann-cleaned'\n",
    "def extract_ann(in_file, out_file):\n",
    "    \"\"\"\n",
    "    Extract the annotation information from the SnpEff\n",
    "    results VCF file. The unique ID and GWAS P-value\n",
    "    for each variant is extracted as well.\n",
    "    \n",
    "    INPUT: \n",
    "    in_file - The name of the file that was output from SnpEff.\n",
    "              The file should be in vcf format and have in the \n",
    "              INFO field the pval+annotation for each variant.\n",
    "    out_file - Name of the file for which to save the results \n",
    "               of this function to. This file will have the \n",
    "               following three fields:\n",
    "          1. unique ID (CHR:POSTION:A1:A2)\n",
    "          2. sequence variant annotation (e.g. stop-gain,)\n",
    "          3. P-value\n",
    "    OUTPUT: \n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(in_file, 'r') as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    "\n",
    "            while line[0] == '#':\n",
    "                line = inF.readline()\n",
    "     \n",
    "            while(line):\n",
    "                split_line = line.split()\n",
    "                unique_id = split_line[0] + ':' + split_line[1] + \\\n",
    "                    ':' + split_line[3] + ':' + split_line[4]\n",
    "    #             rsID = splitLine[2]\n",
    "                info_field = split_line[7]\n",
    "                all_annotations = info_field.split(';')\n",
    "                pval = all_annotations[0]\n",
    "                functional_annotations = all_annotations[1].split(',')\n",
    "                for item in functional_annotations:\n",
    "                    output = unique_id + '\\t' + item.split('|')[1] + '\\t' + pval\n",
    "                    outF.write(output + '\\n')\n",
    "                line = inF.readline()  \n",
    "    return out_file;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function4&mdash;Group Variants into Four Annotational Categories\n",
    "\n",
    "Sequence variant annotation of each function group as described by the 2016 Nature paper by Sveinbjornsson et al.\n",
    "1. loss-of-function (stop-gain & stop-loss, frameshift indel, donor and acceptor splice-site, and initiator codon variants)\n",
    "2. moderate-impact (missense, in-frame indel and splice region variants)\n",
    "3. low-impact (synonymous, 3' and 5' UTR, and upstream and downstream variants)\n",
    "4. other (all other variants)\n",
    "\n",
    "**Note**: there are some variant annotations whose classification is in discordance when considering the Nature paper vs the SnpEff report on (putative) variant impact. For example, initiator codon variants are considered to be in the loss of function group according to the Nature paper where as the SnpEff software annotations the impact as low. There could be issues with this when considering *other* variants. One of these *other* variants might actually be a loss of impact variant or even a moderate impact. The threshold for *other* variants is set more stringent so that we might filter one of these variants out when in actuality we should have lower the threshold. This is just a side-note; I have not tried to determine if there are any instances of this yet. We should take a closer look at it though.\n",
    "\n",
    "### SnpEff annotation (Sequence Ontology terms)\n",
    "\n",
    "<br>\n",
    "\n",
    "**loss-of-function**\n",
    "* stop_gained \n",
    "* stop_lost\n",
    "* frameshift_variant\n",
    "* splice_donor_variant\n",
    "* splice_acceptor_variant\n",
    "* initiator_codon_variant (note that SnpEff indicates that the impact of these variants are LOW)\n",
    "\n",
    "<br>\n",
    "\n",
    "**moderate-impact-variants**\n",
    "* missense_variant\n",
    "* inframe_insertion\n",
    "* splice_region_variant (impact LOW)\n",
    "\n",
    "<br>\n",
    "\n",
    "**low-impact variants**\n",
    "* synonymous_variant\n",
    "* 3_prime_UTR_variant\n",
    "* 5_prime_UTR_variant\n",
    "* upstream_gene_variant\n",
    "* downstream_gene_variant\n",
    "\n",
    "**other**\n",
    "* All other variant annotations detailed in SnpEff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = '/share/storage/Johnson/fwGWAS/method_comp/fwGWAS_SCZ2_Test4/'\n",
    "# in_file = base_dir + 'scz2-gw-ann-cleaned.vcf'\n",
    "# out_file = base_dir + 'scz2-gw-ann-cleaned-grouped'\n",
    "\n",
    "def group_annotations(in_file, out_file):\n",
    "    \"\"\"\n",
    "    Categorized the variants into groups based off\n",
    "    of their annotations.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file - the file name (and path) of the file\n",
    "              that contains the variant annotations.\n",
    "    out_file - the file name (and path) of the output file\n",
    "               that will essentially append the variant group\n",
    "               to the in_put file.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    with open(in_file, 'r') as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    "            group_dict = {}\n",
    "            # add loss-of-function variants\n",
    "            group_dict['loss-of-function variants'] = ['stop_gained', \n",
    "                                                      'stop_lost', \n",
    "                                                      'frameshift_variant', \n",
    "                                                      'splice_donor_variant', \n",
    "                                                      'splice_acceptor_variant', \n",
    "                                                      'initiator_codon_variant']\n",
    "            # add moderate-impact variants\n",
    "            group_dict['moderate-impact variants'] = ['missense_variant', \n",
    "                                                     'inframe_insertion', \n",
    "                                                     'splice_region_variant']\n",
    "            # add low-impact variants\n",
    "            group_dict['low-impact variants'] = ['synonymous_variant', \n",
    "                                                '3_prime_UTR_variant', \n",
    "                                                '5_prime_UTR_variant', \n",
    "                                                'upstream_gene_variant', \n",
    "                                                'downstream_gene_variant']\n",
    "            ## Group variants based on their categorization.\n",
    "            while(line):\n",
    "                split_line = line.split()\n",
    "                # Search for ann in dict.\n",
    "                for item in group_dict:\n",
    "                    if split_line[1] in group_dict[item]:\n",
    "                        split_line.append(item)\n",
    "                        break\n",
    "                # If the variant was not in any of the three groups;\n",
    "                # then it is categorized as an 'other' variant.\n",
    "                if len(split_line) == 3:\n",
    "                    split_line.append('other')\n",
    "                outF.write('\\t'.join(split_line) + '\\n')\n",
    "                line = inF.readline()\n",
    "    return out_file;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function5&mdash;Filter variants based off of the fwThresholds\n",
    "1. Loss of function; $5.5 \\times 10^{-7}$ \n",
    "2. Moderate impact; $1.1 \\times 10^{-7}$ \n",
    "3. Low impact; $1.0 \\times 10^{-8}$ \n",
    "4. Other; $1.7 \\times 10^{-9}$ \n",
    "\n",
    "These thresholds are based off of the estimated enrichment of categories among association signals of 1000G and the resulting significance thresholds - detailed in `Weighting Sequence Variants` 2016 Nature paper by Sveinbjornsson et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = '/share/storage/Johnson/fwGWAS/method_comp/fwGWAS_SCZ2_Test4/'\n",
    "# in_file = base_dir + 'scz2-gw-ann-cleaned-grouped'\n",
    "# out_file = base_dir + 'scz2-gw-ann-cleaned-grouped-filtered-fw'\n",
    "\n",
    "def filter_fw(in_file, out_file):\n",
    "    \"\"\"\n",
    "    This function filters the variants by comparing the sequence\n",
    "    variant P-values obtained from the GWAS results with the \n",
    "    functional-weighted threshold.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file - name (and path) of the input file that contains the \n",
    "              variant groupings.\n",
    "    out_file - name (and path) of the output file that will be the\n",
    "               fw-threshold filtered file.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    with open(in_file) as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    "            loss_func = 5.5e-7\n",
    "            mod_impact = 1.1e-7\n",
    "            low_impact = 1.0e-8\n",
    "            other = 1.7e-9\n",
    "            thresh_dict = {'loss-of-function variants': loss_func,\n",
    "                           'moderate-impact variants': mod_impact,\n",
    "                           'low-impact variants': low_impact,\n",
    "                           'other': other}\n",
    "            while(line):\n",
    "                split_line = line.split('\\t')\n",
    "                group = split_line[3].strip()\n",
    "                pval = float(split_line[2])\n",
    "                if pval <= thresh_dict[group]:\n",
    "                    outF.write(line)\n",
    "                line = inF.readline()\n",
    "    return out_file;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Function6&mdash;Filter variants based off of the standard P-value\n",
    "Filter the sequence variants by the standard genome-wide significance (WGS) P-Value threshold of $5\\times 10^{-8}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = '/share/storage/Johnson/fwGWAS/method_comp/fwGWAS_SCZ2_Test4/'\n",
    "# in_file = base_dir + 'scz2-gw-ann-cleaned-grouped'\n",
    "# out_file = base_dir + 'scz2-gw-ann-cleaned-grouped-filtered-standard'\n",
    "\n",
    "def filter_standard(in_file, out_file):\n",
    "    \"\"\"\n",
    "    This function filters the variants by comparing the sequence\n",
    "    variant pvalues obtained from the GWAS results with the \n",
    "    standard GWAS threshold of 5e-8.\n",
    "         \n",
    "    INPUT:\n",
    "    in_file - name (and path) of the input file that contains the \n",
    "              variant groupings.\n",
    "    out_file - name (and path) of the output file that will be the\n",
    "               standard-threshold filtered file.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    with open(in_file) as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    "            bf_threshold = 5e-8\n",
    "            #\n",
    "            while(line):\n",
    "                split_line = line.split('\\t')\n",
    "                group = split_line[3].strip()\n",
    "                pval = float(split_line[2])\n",
    "                if pval <= bf_threshold:\n",
    "                    outF.write(line)\n",
    "                line = inF.readline()\n",
    "    return out_file;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function7&mdash;Report Results\n",
    "Results comparison: compare the sequence variants that were deemed significant when using the fw-thresholds vs the standard WGS P-value threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = '/share/storage/Johnson/fwGWAS/method_comp/fwGWAS_SCZ2_Test4/'\n",
    "# fw_file = base_dir + 'scz2-gw-ann-cleaned-grouped-filtered-fw'\n",
    "# std_file = base_dir + 'scz2-gw-ann-cleaned-grouped-filtered-standard'\n",
    "# out_file = base_dir + 'scz2-gw-results-summary'\n",
    "\n",
    "def results_summary(in_file, in_file2, out_file):\n",
    "    \"\"\"\n",
    "    The function takes as input the two results files from the threshold filtering\n",
    "    performed above and outputs the summary statistics. Specifically, the output file \n",
    "    will contain two counts-dictionaries. One dict will count the number of variants \n",
    "    in each functional group that was exclusive to the fw-thresholded sequence\n",
    "    variants. The other will be for the variants exclusive to the standard WGS P-value\n",
    "    thresholded results.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file -  name of the fw-thresholded file\n",
    "    in_file2 - name of the standard thresholded file\n",
    "    out_file     - Name of the file to which the summary statistics will be saved.\n",
    "    \n",
    "    OUTPUT:\n",
    "    Nothing is returned from this function, however three files are output. One is\n",
    "    the out_file provided as input, and then two additional files are created.\n",
    "    \n",
    "    additional01 - File assumes the name <out_file>-fw-variants and includes a list of \n",
    "                   the variants that were deemed significant only when the fw-thresholds\n",
    "                   were applied as thresholds of significance.\n",
    "    additional02 - File assumes the name <out_file>-std-variants and includes a list of\n",
    "                   the variants that were deemed significant only when the standard\n",
    "                   threshold (5e-8) was applied.\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "    ## compare the two filtered files and print the variants \n",
    "    #  Exclusive to the fw-thresholded variants\n",
    "    bash_command = 'bash -c \"comm -23 <(sort {0}) <(sort {1})\"'.format(in_file, in_file2)\n",
    "    fw_exclusive = subprocess.run(bash_command, shell=True, stdout=subprocess.PIPE, encoding='utf-8').stdout\n",
    "    # Exlusive to the standard thresholded variants (5e-8)\n",
    "    bash_command2 = 'bash -c \"comm -13 <(sort {0}) <(sort {1})\"'.format(in_file, in_file2)\n",
    "    standard_exclusive = subprocess.run(bash_command2, shell=True, stdout=subprocess.PIPE, encoding='utf-8').stdout\n",
    "    # Variants deemed siginificant using both thresholding methods\n",
    "    bash_command3 = 'bash -c \"comm -12 <(sort {0}) <(sort {1})\"'.format(in_file, in_file2)\n",
    "    both_methods = subprocess.run(bash_command3, shell=True, stdout=subprocess.PIPE, encoding='utf-8').stdout\n",
    "    with open(out_file, 'w') as outF:\n",
    "        for count,string in enumerate([fw_exclusive, standard_exclusive, both_methods]):\n",
    "            counts_dict = {'loss-of-function variants':0,\n",
    "                           'moderate-impact variants':0,\n",
    "                           'low-impact variants':0,\n",
    "                           'other':0}\n",
    "            if count == 0:\n",
    "#                 message = '####\\n####The following lines detail the number of sequence variants that '\\\n",
    "#                       'were statistically significant when compared against the functional ' \\\n",
    "#                       'weighted thresholds based off of their functional annotation. ' \\\n",
    "#                       'Note, these variants were not deemed significant when compared ' \\\n",
    "#                       'against the standard GWAS threshold of 5e-8.\\n\\n'\n",
    "                message = '####\\n####Novel variants.\\n\\n'\n",
    "\n",
    "            elif count == 1:\n",
    "#                 message = '\\n\\n####\\n####The following lines detail the number of sequence variants that '\\\n",
    "#                       'were statistically significant when compared against the standard GWAS ' \\\n",
    "#                       'threshold of 5e-8, but were not deemed significant based off of the function '\\\n",
    "#                       'weighted thresholds.\\n\\n'\n",
    "                message = '\\n\\n####\\n####Variants not replicated.\\n\\n'\n",
    "\n",
    "            else:\n",
    "#                 message = '\\n\\n####\\n####The following lines detail the number of sequence variants that '\\\n",
    "#                         'were statistically significant when compared against BOTH the standard GWAS '\\\n",
    "#                         'threshold and the fw-thresholds. In otherwords, these are the variants that were '\\\n",
    "#                         'replicated.\\n\\n'\n",
    "               message = '\\n\\n####\\n####Variants that were replicated.\\n\\n'\n",
    "\n",
    "            split_lines = string.splitlines()\n",
    "            for line in split_lines:\n",
    "                ann = line.split('\\t')[3]\n",
    "                counts_dict[ann] += 1\n",
    "            outF.write(message)\n",
    "            dict_sum = str(sum(counts_dict.values()))\n",
    "            dict_sum = '\\nTotal number of elements: {}'.format(dict_sum)\n",
    "            outF.write(str(counts_dict) + dict_sum + '\\n')\n",
    "    with open(out_file+'-fw-variants', 'w') as fwF:\n",
    "        fwF.write(fw_exclusive)\n",
    "    with open(out_file+'-std-variants', 'w') as stdF:\n",
    "        stdF.write(standard_exclusive)\n",
    "    return ;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension of NGC Heroin FOU Results \n",
    "**Author:** Jesse Marks\n",
    "\n",
    "We have preliminary results from a very large-scale GWAS for cigarette smoking and alcohol consumption phenotypes. We will search for those SNPs in our NGC meta-analysis results. Supplemental tables S6-S10 are here:\n",
    "`\\rcdcollaboration01.rti.ns\\GxG\\Analysis\\GSCAN\\shared MS version 1\\`\n",
    "\n",
    "The phenotypes of interest to us include:\n",
    "\n",
    "1) **Age of smoking initiation (AI)** - supplemental table 6\n",
    "\n",
    "2) **Cigarettes per day (CPD)**- supplemental table 7\n",
    "\n",
    "3) **Smoking cessation (SC)** - supplemental table 8\n",
    "\n",
    "4) **smoking initiation (SI)** - supplemental table 9\n",
    "\n",
    "5) **Drinks Per Week (DPW)** - supplemental table 10\n",
    "\n",
    "We are interested in seeing whether these associations extend over to opioid addiction. The NGC FOU meta-analysis results are located on the share drive at:\n",
    "`s3://rti-midas-data/studies/ngc/meta/040/processing/fou/aand+adaa+alive+cats+cogend+start+uhs1+uhs2-3+vidus+yale-penn.aa+ea.fou.chr*.maf_gt_0.01.rsq_gt_0.3.with_cohort_data.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data + Create SNP list\n",
    "The data are located on AWS S3. Create a list of SNPs for the lookup from the GSCAN Excell sheet. Copy the SNPs from each of the five Excell sheets (supplemental tables) into separate files and then combine them while removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## local ##\n",
    "\n",
    "# Create directory structure locally\n",
    "cd ~/Desktop/Projects/heroin/ngc/gscan_lookup/fou\n",
    "aws s3 cp s3://rti-midas-data/studies/ngc/meta/040/processing/fou/aand+adaa+alive+cats+cogend+start+uhs1+uhs2-3+vidus+yale-penn.aa+ea.fou.maf_gt_0.03.rsq_gt_0.3.table.gz .\n",
    "\n",
    "# populate these files with the SNPs from respective Excel sheets\n",
    "touch age_of_initiation.tsv  cig_per_day.tsv  smoking_cessation.tsv  smoking_initiation.tsv drink_week.tsv\n",
    "wc -l *tsv\n",
    "\"\"\"\n",
    "   11 age_of_initiation.tsv\n",
    "   56 cig_per_day.tsv\n",
    "  101 drink_week.tsv\n",
    "   25 smoking_cessation.tsv\n",
    "  377 smoking_initiation.tsv\n",
    "  570 total\n",
    "\"\"\"\n",
    "\n",
    "# combine SNPs into one file, make sure SNPs are not listed twice\n",
    "head -1 age_of_initiation.tsv > combined_snp_list.tsv\n",
    "for file in age* cig* smoking* drink*;do\n",
    "    tail -n +2 $file >> combined_snp_list.tsv\n",
    "done\n",
    "\n",
    "# filter so that there are no duplicated SNPs (no header either)\n",
    "tail -n +2 combined_snp_list.tsv | sort -u > combined_snp_list_filtered.tsv\n",
    "\n",
    "# convert to 1000g_p3 format\n",
    "awk '{print $3\":\"$2\":\"$4\":\"$5\"\\t\"$1}' combined_snp_list_filtered.tsv > combined-snp_list-filtered-1000g_p3-chr.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "wc -l combined-snp_list-filtered-1000g_p3-chr.tsv\n",
    "557 combined-snp_list-filtered-1000g_p3-chr.tsv\n",
    "\n",
    "head combined-snp_list-filtered-1000g_p3-chr.tsv\n",
    "rs12027999:154206358:T:C        1\n",
    "rs2072659:154548521:C:G 1\n",
    "rs45444697:155034632:C:G        1\n",
    "rs10753661:165119792:G:A        1\n",
    "rs28680958:173848808:G:A        1\n",
    "rs2901785:174104743:G:A 1\n",
    "rs34973462:175993820:C:T        1\n",
    "rs147052174:179783167:G:T       1\n",
    "rs3820277:18436657:G:T  1\n",
    "rs35656245:190957480:G:A        1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNP lookup\n",
    "I need to create a dictionary of the GSCAN SNPs and then see if each SNP in the meta-analysis is in the dictionary. I think this makes more sense than vice-versa; in particular, creating a dictionary for each SNP in the meta-analysis and then searching to see if the GSCAN SNPs are in the dictionary. This latter strategy would require a large amount of memory to create the Python dictionary. I think the former strategy makes more computational sense.\n",
    "\n",
    "Also note that there are some SNPs in the meta-analysis which have the format of chr:position:a1:a2 instead of rsid:position:a1:a2. I think the reason is that these SNPs of the former format did not have an associated rsID available. If a GSCAN SNP is not found in the lookup, then we need to output the SNPs that were not found and deal with those later. It might be the case that they we have to convert them from rsid:position:a1:a2 format to chr:position:a1:a2 and then perform the search again with just these SNPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs12027999:154206358:T:C\t1\n",
      "\n",
      "VARIANT_ID\tCHR\tPOSITION\tP\tTYPE\n",
      " rs699737:117270868:C:G\t1\t117270868\t0.7131\tsnp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Python3 ###\n",
    "\"\"\"\n",
    "*SNP lookup*\n",
    "\n",
    "    Make sure the IDs are of the same format for the snp-list\n",
    "    and the IDs in the meta-analysis results. e.g. 1000g_p3 or rsID only\n",
    "\"\"\"\n",
    "import gzip\n",
    "\n",
    "################################################################################\n",
    "date = \"20190114\"  # enter today's date\n",
    "#ancestry = \"ea\"\n",
    "\n",
    "#if ancestry==\"aa\":\n",
    "#    pop = \"afr\"\n",
    "#elif ancestry==\"ea\":\n",
    "#    pop = \"eur\"\n",
    "#else:\n",
    "#    pop = \"afr+eur\"\n",
    "\n",
    "## dict to hold gscan snps and the number of times they were found.\n",
    "## we can tell which SNPs did not show up in any of the meta files\n",
    "gscan_dict =  {}\n",
    "base_dir = \"C:\\\\Users\\\\jmarks\\\\Desktop\\\\gscan_lookup\\\\fou\"\n",
    "snp_list = \"{}\\\\combined-snp_list-filtered-1000g_p3-chr.tsv\".format(base_dir)\n",
    "\n",
    "#for chrom in range(1,23):\n",
    "out_file = \"{}\\\\results\\\\{}-ngc-meta-fou-aa+ea.maf_gt_0.01.rsq_gt_0.3-gscan-lookup.txt\".format(base_dir, date)\n",
    "results = \"{}\\\\aand+adaa+alive+cats+cogend+start+uhs1+uhs2-3+vidus+yale-penn.aa+ea.fou.maf_gt_0.01.rsq_gt_0.3.table.gz\".format(base_dir)\n",
    "not_found = \"{}\\\\results\\\\{}-ngc-meta-fou-gscan-snps-not-found\".format(base_dir, date)\n",
    "################################################################################\n",
    "\n",
    "with gzip.open(results, 'rt') as metF, open(snp_list) as gscanF, open(out_file, \"wt\") as outF:\n",
    "    gscan_line = gscanF.readline()\n",
    "    met_head = metF.readline()\n",
    "    met_line = metF.readline()\n",
    "    print(gscan_line)\n",
    "    print(met_head, met_line)\n",
    "\n",
    "    outF.write(met_head)\n",
    "\n",
    "    ## create a dictionary containing the gscan snps\n",
    "    if len(gscan_dict) == 0:\n",
    "        while gscan_line:\n",
    "            key = gscan_line.split()[0]\n",
    "            gscan_dict[key] = 0\n",
    "            gscan_line = gscanF.readline()\n",
    "\n",
    "\n",
    "    while met_line:\n",
    "        met_id = met_line.split()[0] # the 1000g_p3 ID in the meta-analysis\n",
    "\n",
    "        if met_id in gscan_dict:\n",
    "            gscan_dict[met_id] += 1\n",
    "            outF.write(met_line)\n",
    "        met_line = metF.readline()\n",
    "        \n",
    "# report SNPs not found\n",
    "with open(not_found, \"wt\") as notF:\n",
    "    for key, value in gscan_dict.items():\n",
    "        if value==0:\n",
    "            notF.write(key + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "~/Desktop/gscan_lookup/fou/results\n",
    "$ head *\n",
    "==> 20190114-ngc-meta-fou-aa+ea.maf_gt_0.01.rsq_gt_0.3-gscan-lookup.txt <==\n",
    "VARIANT_ID      CHR     POSITION        P       TYPE\n",
    "rs4912332:58815243:C:T  1       58815243        0.8664  snp\n",
    "rs10914684:33795572:G:A 1       33795572        0.9134  snp\n",
    "rs34973462:175993820:C:T        1       175993820       0.6957  snp\n",
    "rs951740:44011737:G:A   1       44011737        0.4434  snp\n",
    "rs11264100:35591626:A:G 1       35591626        0.3141  snp\n",
    "rs147052174:179783167:G:T       1       179783167       0.04811 snp\n",
    "rs3820277:18436657:G:T  1       18436657        0.5824  snp\n",
    "rs12088813:66407700:A:C 1       66407700        0.4966  snp\n",
    "rs35656245:190957480:G:A        1       190957480       0.3217  snp\n",
    "\n",
    "==> 20190114-ngc-meta-fou-gscan-snps-not-found <==\n",
    "rs184083806:96981736:T:C\n",
    "rs2145451:29316842:T:C\n",
    "rs4886550:78243579:A:G\n",
    "rs12442563:83893243:G:T\n",
    "rs72836318:44121579:T:C\n",
    "rs3076896:146283610:G:A\n",
    "rs12611472:225353649:T:C\n",
    "rs28813180:158083918:G:A\n",
    "rs561222871:100260679:C:T\n",
    "rs11739827:166803321:G:T\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

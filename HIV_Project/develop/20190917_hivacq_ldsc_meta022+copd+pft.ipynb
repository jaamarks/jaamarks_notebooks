{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LD Score Regression: Meta022 + COPD + 3 LDHub Lung Function + 2 Pulminary Lung Function\n",
    "**Author**: Jesse Marks <br>\n",
    "**GitHub Issue:** [#126](https://github.com/RTIInternational/bioinformatics/issues/126)\n",
    "**Results Uploaded:** `s3://rti-hiv/ldsc/meta022_copd_pft/v04`\n",
    "\n",
    "\n",
    "This Jupyter Notebook documents the steps taken to perform LD Score Regression (LDSC)—a tool for estimating heritability and genetic correlation—on our European-specific meta-analysis results. In particular, we perform LDSC on our in-house meta-analysis (labeled 022) compared to: the COPD GWAS results, two sets of GWAS results for pulminary lung function, and 3 GWAS results for lung function on LDHub. We are going to utilize the [LD score regression pipeline](https://github.com/RTIInternational/ld-regression-pipeline) that Alex Waldrop developed to perform LD score regression.\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "Note that our in-house HIV acquisition meta-analysis results have A2 coded as the effect allele. LDHub expects A1 to be coded as the effect allele (see [ldsc on github](https://github.com/bulik/ldsc/wiki/Summary-Statistics-File-Format)). We will have to take this into account before we construct our file to upload to LDHub.\n",
    "\n",
    "**workflow ID number:**\n",
    "`80d9cb63-b831-453c-928e-b590b69198ed`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "* In-house HIV acquisition meta-analysis (the reference phenotype)\n",
    "* LDHub cross-sectional Pulminary Function Tests (PFTs)\n",
    "* COPD\n",
    "* in-house longitudinal PFTs\n",
    "\n",
    "### In-house Meta022\n",
    "The 022 meta-analysis for HIV acquisition has `n=18,245` and includes:\n",
    "* McLaren EA (n=13,581)\n",
    "* UHS1-4 EA (n=3013)\n",
    "* WIHS1 EA (n=720)\n",
    "* VIDUS EA (n=931)\n",
    "\n",
    "\n",
    "### Three LDHub Lung Function Studies\n",
    "PMID 28166213. Note that there are new lung function results on LDHub, however they have not provided a PMID for all of the studies, therefore we cannot distinguish which data are the newest.\n",
    "* Forced expiratory volume in 1 second (FEV1)\n",
    "* Forced Vital capacity(FVC)\n",
    "* Forced expiratory volume in 1 second (FEV1)/Forced Vital capacity(FVC)\n",
    "\n",
    "\n",
    "### COPD\n",
    "The inhouse COPD data. `s3://rti-nd/LDSC/COPDGWAS_HobbsEtAl/modGcNoOtherMinMissSorted.withchrpos.txt.gz`\n",
    "\n",
    "\n",
    "### Two Pulminary Lung Function GWAS\n",
    "* What is the `N`? \n",
    "* What is the chromosome?\n",
    "```css\n",
    "@jaamarks GWAS results for PFT decline (https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0100776 ) are available here for comparison to HIV acquisition, once you have the new in-house+McLaren GWAS meta:\n",
    "/rti-shares/gxg/R21_GxNutrients/PriorGWASresults/MAres_FEV1_Longitudinal_All_291120121.tbl\n",
    "/rti-shares/gxg/R21_GxNutrients/PriorGWASresults/MAres_FEV1_Longitudinal_sub_291120121.tbl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create WorkFlow inputs\n",
    "**Workflow guideline:**\n",
    "1. Create Excel phenotype file locally then upload to EC2 instance\n",
    "2. Clone https://github.com/RTIInternational/ld-regression-pipeline\n",
    "3. Then edit full_ld_regression_wf_template.json to include the reference data of choice\n",
    "4. Use dockerized tool to finish filling out the json file that will be input for workflow\n",
    "5. Perform LDSC using the WDL workflow\n",
    "   - If necessary, get results from LDHub\n",
    "   - Merge data Create final plots with dockerized tool \n",
    " \n",
    "<br><br>\n",
    "\n",
    "Here is an example entry in the Excel Phenotype File:\n",
    "\n",
    "**trait\tplot_label\tsumstats_path\tpmid\tcategory\tsample_size\tid_col\tchr_col\tpos_col\teffect_allele_col\tref_allele_col\teffect_col\tpvalue_col\tsample_size_col\teffect_type\tw_ld_chr**\n",
    "```\n",
    "COPDGWAS Hobbs et al.\tCOPD\ts3://rti-nd/LDSC/COPDGWAS_HobbsEtAl/modGcNoOtherMinMissSorted.withchrpos.txt.gz\t28166215\tRespiratory\t51772\t3\t1\t2\t4\t5\t10\t12\t\tbeta\ts3://clustername--files/eur_w_ld_chr.tar.bz2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EC2 ###\n",
    "\n",
    "# use screen tool and enter compute node\n",
    "screen \n",
    "qrsh -l h=ip-172-31-29-161\n",
    "\n",
    "# clone github repo\n",
    "cd /shared/jmarks/proj/hiv/ldsc/003\n",
    "git clone https://github.com/RTIInternational/ld-regression-pipeline\n",
    "    \n",
    "# edit file-input json\n",
    "cd ld-regression-pipeline\n",
    "mkdir workflow_inputs\n",
    "cp json_input/full_ld_regression_wf_template.json workflow_inputs\n",
    "cd workflow_inputs\n",
    "\n",
    "## vim edit full*json file (see README.md at https://github.com/RTIInternational/ld-regression-pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### local ###\n",
    "\n",
    "## edit phenotype file and upload to EC2 instance\n",
    "cd /home/jmarks/Projects/HIV/ldsc/meta022_copd_lung_function/v04/processing/cromwell/input\n",
    "scp -i ~/.ssh/gwas_rsa *xlsx ec2-user@54.84.72.140:/shared/jmarks/proj/hiv/ldsc/003/ld-regression-pipeline/workflow_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EC2 ###\n",
    "\n",
    "# create final workflow input (a json file)\n",
    "docker run -v /shared/jmarks/proj/hiv/ldsc/003/ld-regression-pipeline/workflow_inputs:/data/ \\\n",
    "    rticode/generate_ld_regression_input_json:1ddbd682cb1e44dab6d11ee571add34bd1d06e21 \\\n",
    "    --json-input /data/full_ld_regression_wf_template.json \\\n",
    "    --pheno-file /data/20190917_hiv_ldsc_phenotypes_local.xlsx >\\\n",
    "        /shared/jmarks/proj/hiv/ldsc/003/ld-regression-pipeline/workflow_inputs/final_wf_inputs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## zip appropriate files \n",
    "# Change to directory immediately above ld-regression-pipeline\n",
    "cd /shared/jmarks/proj/hiv/ldsc/003/ld-regression-pipeline\n",
    "cd ..\n",
    "# Make zipped copy of repo somewhere\n",
    "zip --exclude=*var/* --exclude=*.git/* -r \\\n",
    "    /shared/jmarks/proj/hiv/ldsc/003/ld-regression-pipeline/workflow_inputs/ld-regression-pipeline.zip \\\n",
    "    ld-regression-pipeline\n",
    "\n",
    "## download cromwell and the config file, if necessary\n",
    "cd /shared/jmarks/bin/cromwell\n",
    "#aws s3 cp s3://rti-cromwell-output/cromwell-config/cromwell_default_genomics_queue.conf .\n",
    "#wget https://github.com/broadinstitute/cromwell/releases/download/44/cromwell-44.jar\n",
    "\n",
    "## run ldsc workflow on AWS EC2 instance\n",
    "java -Dconfig.file=/shared/jmarks/bin/cromwell/cromwell_default_genomics_queue.conf \\\n",
    "    -jar cromwell-44.jar \\\n",
    "    run /shared/jmarks/proj/hiv/ldsc/003/ld-regression-pipeline/workflow/full_ld_regression_wf.wdl \\\n",
    "    -i /shared/jmarks/proj/hiv/ldsc/003/ld-regression-pipeline/workflow_inputs/final_wf_inputs.json \\\n",
    "    -p /shared/jmarks/proj/hiv/ldsc/003/ld-regression-pipeline/workflow_inputs/ld-regression-pipeline.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy workflow ID\n",
    "You will need this to find the results on S3 at `rti-cromwell-output/cromwell-execution/full_ld_regression_wf/<id-number>`\n",
    "\n",
    "Get this ID by looking at the log, example: <br>\n",
    "`/shared/jmarks/bin/cromwell/cromwell-workflow-logs/workflow.cffd947c-9345-41f1-a146-3e3454404fa3.log`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Workflow Results to Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/jmarks/Projects/HIV/ldsc/meta022_copd_lung_function/v04/processing/cromwell/input\n",
    "scp -i ~/.ssh/gwas_rsa   ec2-user@54.84.72.140:/shared/jmarks/proj/hiv/ldsc/003/ld-regression-pipeline/workflow_inputs/* .\n",
    "\n",
    "cd /home/jmarks/Projects/HIV/ldsc/20190916_meta022v3_copd_lung_function/processing/cromwell/output\n",
    "aws s3 cp s3://rti-hiv/ldsc/20190916_meta022v3_copd_lung_function/cromwell_output/call-plot_ld/PLOT.plot_ld_regression_wf/045969b0-44b6-404e-a280-167c9ae912be/call-make_plot_table/hiv_acq_meta022v3_vs_copd.ld_regression_results.tsv . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [LD Hub](http://ldsc.broadinstitute.org/ldhub/)\n",
    "```\n",
    "Important notes for your uploaded file:\n",
    "\n",
    "1. To save the uploading time, LD Hub only accepts zipped files as input (e.g. mydata.zip).\n",
    "\n",
    "2. Please check that there is ONLY ONE plain TXT file (e.g. mydata.txt) in your zipped file.\n",
    "\n",
    "3. Please make sure you do NOT zip any folder together with the plain txt file (e.g. /myfolder/mydata.txt), otherwise you will get an error: [Errno 2] No such file or directory\n",
    "\n",
    "4. Please do NOT zip multiple files (e.g. zip mydata.zip file1.txt file2.txt ..) or zip a file with in a folder (e.g. zip mydata.zip /path/to/my/file/mydata.txt).\n",
    "\n",
    "5. Please keep the file name of your plain txt file short (less than 50 characters), otherwise you may get an error: [Errno 2] No such file or directory\n",
    "\n",
    "6. Please zip your plain txt file using following command (ONE file at a time):\n",
    "\n",
    "For Windows system: 1) Locate the file that you want to compress. 2) Right-click the file, point to Send to, and then click Compressed (zipped) folder.\n",
    "\n",
    "For Linux and Mac OS system: zip mydata.zip mydata.txt\n",
    "\n",
    "Reminder: for Mac OS system, please do NOT zip you file by right click mouse and click \"Compress\" to zip your file, this will automatically create a folder called \"__MACOS\". You will get an error: [Errno 2] No such file or directory.\n",
    "\n",
    "Upload the trait of interest\n",
    "To save your upload time, we highly recommend you to use the SNP list we used in LD Hub to reduce the number of SNPs in your uploaded file. Click here to download our SNP list (w_hm3.noMHC.snplist.zip).\n",
    "\n",
    "Please upload the zipped file you just created. Click here to download an input example.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create input file \n",
    "\n",
    "The input file is created during the WDL workflow we ran above. LDHub requires the input data to be in a certain format, so there will be some minimal processing to do before we upload the reference phenotype file.\n",
    "\n",
    "**Note**: Here we have switched the A1 and A2 around because LDHub expects A1 to be the effect allele. Our results have A2 as the effect allele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download outputs for each ref chr from rftm_sumstats step ###\n",
    "\n",
    "cd /shared/jmarks/proj/hiv/ldsc/003/ldhub\n",
    "aws s3 sync  s3://rti-hiv/ldsc/meta022_copd_pft/v04/output/cromwell/80d9cb63-b831-453c-928e-b590b69198ed/call-munge_ref/MUNGE_REF_WF.munge_sumstats_wf/828b701e-8651-4794-925a-e24aa378d68f/call-munge_chr_wf/ .\n",
    "           # s3://rti-cromwell-output/cromwell-execution/full_ld_regression_wf/cad01742-2337-4c14-9f40-7b1e9965fddf/call-munge_ref/MUNGE_REF_WF.munge_sumstats_wf/7269da15-a598-4148-a255-0017f7d0dda3/call-munge_chr_wf/ .\n",
    "        \n",
    "mv  */MUNGE_CHR.munge_sumstats_chr_wf/*/call-rfmt_sumstats/hiv_acquisition_ea_specific_1df_meta_analysis_mclaren_ea+meta016_gc_applied_twice_exclude_singletons.chr*.standardized.phase3ID.munge_ready.txt .\n",
    "\n",
    "## Concat into single file ##\n",
    "cat hiv_acquisition_ea_specific_1df_meta_analysis_mclaren_ea+meta016_gc_applied_twice_exclude_singletons.chr1.standardized.phase3ID.munge_ready.txt >\\\n",
    "    hiv022_ld_hub_with_pvalues.txt\n",
    "for chr in {2..22}\n",
    "do\n",
    "    tail -n +2  hiv_acquisition_ea_specific_1df_meta_analysis_mclaren_ea+meta016_gc_applied_twice_exclude_singletons.chr$chr.standardized.phase3ID.munge_ready.txt >>\\\n",
    "        hiv022_ld_hub_with_pvalues.txt\n",
    "done\n",
    "#cp hiv022_ld_hub_with_pvalues.txt hiv_munge.txt\n",
    "\n",
    "\n",
    "## Remove unnecessary columns (need snpID, A1, A2 Beta, Pvalue) in that order ##\n",
    "# note that we swap our A1 and A2 values though\n",
    "head -1 hiv022_ld_hub_with_pvalues.txt | cut -f1,4,5,6,7 > tmp\n",
    "tail -n +2 hiv022_ld_hub_with_pvalues.txt | awk 'BEGIN{OFS=\"\\t\"}{print $1, $5, $4, $6, $7}'  >>\\\n",
    "    tmp && mv tmp hiv022_ld_hub_with_pvalues.txt\n",
    "\n",
    "\n",
    "## Add sample size column (sample = 18245.00) and change header names ##\n",
    "cat hiv022_ld_hub_with_pvalues.txt |\\\n",
    "    awk -v OFS=\"\\t\" -F\"\\t\" 'NR==1{print \"snpid\", \"A1\", \"A2\", \"BETA\", \"N\", \"P-value\"} \n",
    "    NR>1{print $1,$2,$3,$4,\"18245.00\", $5}' > \\\n",
    "    tmp && mv tmp hiv022_ld_hub_with_pvalues.txt\n",
    "    \n",
    "    \n",
    "# zip file\n",
    "zip hiv022_ld_hub_with_pvalues.txt.zip hiv022_ld_hub_with_pvalues.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/jmarks/Projects/HIV/ldsc/meta022_copd_pft/v04/processing/ldhub/input \n",
    "scp -i ~/.ssh/gwas_rsa   ec2-user@54.84.72.140:/shared/jmarks/proj/hiv/ldsc/003/ldhub/*zip ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload input file\n",
    "Follow the steps above to zip and upload input file. Essentially, \n",
    "* download the file created in the cell above to your local machine.\n",
    "* Then zip this file (and only this file).\n",
    "* Login to [LDHub](http://ldsc.broadinstitute.org/ldhub/) by clicking on `Get Started with LDHub` and then sign in with your Google email account.\n",
    "* Click `Go Test Center`\n",
    "* Click `Continue`\n",
    "* Upload zipped file by clicking `Choose File`, naming your trait, and clicking `Continue`.\n",
    "* Select traits of interest from LDHub by checking the box next to the trait of interest and then clicking `Submit your request`\n",
    "\n",
    "**Note**: keep browser open during LDSC analysis on LDHub.\n",
    "\n",
    "`hiv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download LDHub output\n",
    "You should see the following message after uploading your data:\n",
    "```\n",
    "Analysis in progress ...\n",
    "1) Please keep the browser open when uploading your file.\n",
    "\n",
    "2) The webpage will jump to the results page automatically after the QC and H2 analysis was done.\n",
    "\n",
    "3) The rg analysis will keep running in the backend. Each rg test may take about 20 seconds. A rg analysis of all traits may take up to five hours.\n",
    "```\n",
    "\n",
    "After this page, you will see the results page with the download ready once the anaylsis has finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Final Plot\n",
    "This is needed if there were additional phenotypes used from LDHub. If no phenotypes from LDHub were included, then the we need plot was already created during the WDL workflow. For example, you can find the plot in the following location:\n",
    "\n",
    "`s3://rti-cromwell-output/cromwell-execution/full_ld_regression_wf/cad01742-2337-4c14-9f40-7b1e9965fddf/call-plot_ld/PLOT.plot_ld_regression_wf/045969b0-44b6-404e-a280-167c9ae912be/call-plot_ld_regression_results/hiv_acq_meta022v3_vs_copd.ld_regression_results.pdf`\n",
    "\n",
    "We need to create a CSV file with the results that we want to plot. We will need to merge the results from the cromwell WDL workflow with the LDHub results. The easiest way to do this is to create an Excel spreadsheet with three different sheets. One sheet will be the output from LDHub that we downloaded earlier, the results from the cromwell WDL workflow, and then a sheet that contains the merged results. The cromwell workflow results can be found in the `cromwell_output/call-plot_ld/` folder. For example, `s3://rti-hiv/ldsc/20190911_meta022v3_copd_lung_function/cromwell_output/call-plot_ld/PLOT.plot_ld_regression_wf/045969b0-44b6-404e-a280-167c9ae912be/call-make_plot_table/hiv_acq_meta022v3_vs_copd.ld_regression_results.tsv`. \n",
    "\n",
    "The merged CSV file should have the header:\n",
    "```\n",
    "trait2\tTrait_Label\tTrait_Group\trg\tse\tz\tp\th2_obs\th2_obs_se\th2_int\th2_int_se\tgcov_int\tgcov_int_se\n",
    "```\n",
    "\n",
    "For an example file, see: <br>\n",
    "`s3://rti-hiv/ldsc/20190911_meta022v3_copd_lung_function/final/20190911_hivacq_ldsc_meta022v3_vs_COPD_and_ldhub_lung_function_results_table.csv`\n",
    "\n",
    "**Note**: I had to upload my results table to an EC2 instance in order to run the next cell which creates the plot of the merged results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## enter interactive mode ##\n",
    "# note that the image tag corresponds to the latest tag for this image\n",
    "docker run -it -v\"/shared/jmarks/proj/hiv/ldsc/003/plot:/data/\" \\\n",
    "    rticode/plot_ld_regression_results:be2d0b7d1d067d28b786e70228c50e2f732a0862  /bin/bash\n",
    "    \n",
    "Rscript /opt/plot_ld_regression/plot_ld_regression_results.R  \\\n",
    "    --input_file 20190917_hivacq_ldsc_meta022v4_copd_pft_rg_results_table.csv \\\n",
    "    --output_file 20190917_hivacq_ldsc_meta022v4_copd_pft_rg_results_table.pdf  \\\n",
    "    --comma_delimited \\\n",
    "    --title \"HIV Acquisition Meta-Analysis 022\"\n",
    "    #--group_order_file 20170729_hiv_aqcuisition_meta016_ldsc_copd_lung_function_plot_order.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy results to correct S3 bucket\n",
    "The results of all of the analyses for LDSC using the WDL workflow are saved automatically in an S3 folder:<br>\n",
    "`s3://rti-cromwell-output/cromwell-execution/full_ld_regression_wf/<id-number>`\n",
    "\n",
    "We will need to copy these results over to the correct S3 bucket corresponding to the project it was for. <br>\n",
    "**Note** be sure to upload a README file that explains the analysis.\n",
    "\n",
    "___\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Below is the README.txt file uploaded to that bucket too:\n",
    "\n",
    "```\n",
    "Author: Jesse Marks\n",
    "Date: 20190917\n",
    "GitHub Issue: 126\n",
    "\n",
    "This LDSC analysis is using the reference phenotype meta022, which is\n",
    "a meta-analysis for HIV acquisition and contains the samples:\n",
    "McLaren EA (n=13,581)\n",
    "UHS1-4 EA (n=3013)\n",
    "WIHS1 EA (n=720)\n",
    "VIDUS EA (n=931)\n",
    "\n",
    "We will compare this reference phenotype to:\n",
    "COPD\n",
    "3 Lung Function Cohorts in LDHub (PMID 28166213)\n",
    "    -Forced expiratory volumne in 1 second (FEV1)\n",
    "    -Forece Vital capacity (FVC)\n",
    "    -Forece expiratory volumne in 1 second (FEV1)/Foreced Vital capacity(FVC)\n",
    "2 pulminary lung function results we have in-house.\n",
    "    -s3://rti-shares/gxg/R21_GxNutrients/PriorGWASresults/MAres_FEV1_Longitudinal_All_291120121.tbl\n",
    "    -s3://rti-shares/gxg/R21_GxNutrients/PriorGWASresults/MAres_FEV1_Longitudinal_sub_291120121.tbl\n",
    "\n",
    "Note about the 2 pulminary lung function cohorts:\n",
    "    -The \"all\" (MAres_FEV1_Longitudinal_All_291120121.tbl) was anyone with any decline (any measurement, phenotype not as good)\n",
    "    -The \"sub\" (MAres_FEV1_Longitudinal_sub_291120121.tbl) was more restrictive and kept only participants with optimum measurements (every three years) so this is a smaller N (had one sig finding but no replication) (cleaner phenotype)\n",
    "\n",
    "\n",
    "###############################################################################################################################\n",
    "Update: we did not include the 2 pulminary lung function results in this analysis. We were having issues with the format of the data. In particular, the data seemed to be a interspered with binary format -- almost like the data were not successfully, only partially, converted to text files.\n",
    "\n",
    "Update2:  After finishing this LDSC analysis, we realized that our results were flipped when comparing to LDHub. This is because our results are coded such that A2 is the effect allele and LDHub expects A1 to be the effect allele. We fix this by flipping the sign for the genetic correlation (rg) for the traits recieve from LDHub in the final plot-file.\n",
    "\n",
    "\n",
    "###############################################################################################################################\n",
    "\n",
    "v03 is with the meta-analysis results at s3://rti-hiv/meta_new/022/results/v03/stats/final\n",
    "v04 is with the meta-analysis results at s3://rti-hiv/meta_new/022/results/v04/stats/final\n",
    "\n",
    "The version 4 results are a cleaner set of results; McLaren SNP filters were applied to remove\n",
    "SNPs with MAF < 1%, RSQ < 0.8, and any SNP not available in all samples of the McLaren meta.\n",
    "\n",
    "```\n",
    "**Note** We will also copy the input files and the plot we created to the S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/jmarks/Projects/HIV/ldsc/20190917_meta022v3_copd_lung_function/cromwell_input\n",
    "aws s3 sync . s3://rti-hiv/ldsc/20190917_meta022v3_copd_lung_function/cromwell_input/\n",
    "    \n",
    "cd /home/jmarks/Projects/HIV/ldsc/20190917_meta022v3_copd_lung_function/final\n",
    "aws s3 sync . s3://rti-hiv/ldsc/20190917_meta022v3_copd_lung_function/final/\n",
    "\n",
    "cd /home/jmarks/Projects/HIV/ldsc/20190917_meta022v3_copd_lung_function\n",
    "aws s3 cp README.txt s3://rti-hiv/ldsc/20190917_meta022v3_copd_lung_function/README.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

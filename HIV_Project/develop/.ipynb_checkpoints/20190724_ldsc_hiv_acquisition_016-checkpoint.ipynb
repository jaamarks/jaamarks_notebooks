{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LD Score Regression: WDL Pipeline\n",
    "**Author**: Jesse Marks\n",
    "**GitHub Issue:** [#126](https://github.com/RTIInternational/bioinformatics/issues/126)\n",
    "\n",
    "LD score regression (LDSC) analyses are needed for EUR-specific meta-analysis results for HIV acquisition. We currently have two sets of EUR-specific meta-analysis results\n",
    "* s3://rti-hiv/meta_new/016 \n",
    "* s3://rti-hiv/meta_new/019  \n",
    "\n",
    "The 016 meta-analysis has `n=4,664` and includes:\n",
    "* UHS1-4 EA (n=3013)\n",
    "* WIHS1 EA (n=720)\n",
    "* VIDUS EA (n=931)\n",
    "\n",
    "The 019 meta-analysis has `n=3,733` and includes:\n",
    "* UHS1-4 EA (n=3013)\n",
    "* WIHS1 EA (n=720)\n",
    "\n",
    "We are going to utilize the [LD score regression pipeline](https://github.com/RTIInternational/ld-regression-pipeline) that Alex Waldrop developed to perform LD score regression. \n",
    "\n",
    "<br><br>\n",
    "\n",
    "### workflow number:\n",
    "**600a3079-f75b-4de7-8517-78632b30bb1b**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create WorkFlow inputs\n",
    "Here is an example entry in the Excel Phenotype File:\n",
    "\n",
    "**trait\tplot_label\tsumstats_path\tpmid\tcategory\tsample_size\tid_col\tchr_col\tpos_col\teffect_allele_col\tref_allele_col\teffect_col\tpvalue_col\tsample_size_col\teffect_type\tw_ld_chr**\n",
    "```\n",
    "COPDGWAS Hobbs et al.\tCOPD\ts3://rti-nd/LDSC/COPDGWAS_HobbsEtAl/modGcNoOtherMinMissSorted.withchrpos.txt.gz\t28166215\tRespiratory\t51772\t3\t1\t2\t4\t5\t10\t12\t\tbeta\ts3://clustername--files/eur_w_ld_chr.tar.bz2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. upload Excel phenotype file to EC2 instance\n",
    "## 2. then edit full_ld_regression_wf_template.json to include the reference data of choice\n",
    "## 3. lastly use dockerized tool to finish filling out the json file that will be input for workflow\n",
    "\n",
    "\n",
    "# create final workflow input (a json file)\n",
    "docker run -v /shared/jmarks/hiv/ldsc/ld-regression-pipeline/workflow_inputs/:/data/ \\\n",
    "    rticode/generate_ld_regression_input_json:1ddbd682cb1e44dab6d11ee571add34bd1d06e21 \\\n",
    "    --json-input /data/full_ld_regression_wf_template.json \\\n",
    "    --pheno-file /data/hiv_acquisition_ldsc_phenotypes_local.xlsx >\\\n",
    "        /shared/jmarks/hiv/ldsc/ld-regression-pipeline/workflow_inputs/final_wf_inputs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## copy cromwell config file from S3 to EC2 instance\n",
    "cd /shared/jmarks/bin/cromwell\n",
    "aws s3 cp s3://rti-cromwell-output/cromwell-config/cromwell_default_genomics_queue.conf .\n",
    "    \n",
    "## zip appropriate files \n",
    "# Change to directory immediately above metaxcan-pipeline repo\n",
    "cd /shared/jmarks/hiv/ldsc/ld-regression-pipeline\n",
    "cd ..\n",
    "# Make zipped copy of repo somewhere\n",
    "zip --exclude=*var/* --exclude=*.git/* -r \\\n",
    "    /shared/jmarks/hiv/ldsc/ld-regression-pipeline/workflow_inputs/ld-regression-pipeline.zip \\\n",
    "    ld-regression-pipeline\n",
    "\n",
    "    \n",
    "## Run workflowâ€”Navigate to cromwell directory\n",
    "#cd ~/cromwell\n",
    "#java -Dconfig.file=/full/path/to/metaxcan-pipeline/var/cromwell_default_genomics_queue.conf -jar cromwell-36.jar \\\n",
    "#    run /path/to/metaxcan-pipeline/workflow/s-mulTiXcan_test_wf.wdl \\\n",
    "#    -i ~/PycharmProjects/metaxcan-pipeline/json_input/s-mulTiXcan_test_wf_example_input.json \\\n",
    "#    -p ~/Desktop/metaxcan-pipeline.zip\n",
    "\n",
    "cd /shared/jmarks/bin/cromwell\n",
    "java -Dconfig.file=/shared/jmarks/bin/cromwell/cromwell_default_genomics_queue.conf \\\n",
    "    -jar cromwell-44.jar \\\n",
    "    run /shared/jmarks/hiv/ldsc/ld-regression-pipeline/workflow/full_ld_regression_wf.wdl \\\n",
    "    -i /shared/jmarks/hiv/ldsc/ld-regression-pipeline/workflow_inputs/final_wf_inputs.json \\\n",
    "    -p /shared/jmarks/hiv/ldsc/ld-regression-pipeline/workflow_inputs/ld-regression-pipeline.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "workflow.ed5747ed-ccbe-4bc9-bb44-1f2d750a27eb.log \n",
    "\n",
    "600a3079-f75b-4de7-8517-78632b30bb1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ### run a workflow on AWS via CODE's AWS Cromwell-Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh -L localhost:8000:localhost:8000 ec2-user@3.87.9.200\n",
    "curl -X POST \"http://localhost:8000/api/workflows/v1\" -H \"accept: application/json\" \\\n",
    "    -F \"workflowSource=@/shared/jmarks/hiv/ldsc/ld-regression-pipeline/workflow/full_ld_regression_wf.wdl\" \\\n",
    "    -F \"workflowInputs=@/shared/jmarks/hiv/ldsc/ld-regression-pipeline/workflow_inputs/final_wf_inputs.json\" \\\n",
    "-F \"workflowDependencies=@/shared/jmarks/hiv/ldsc/ld-regression-pipeline/workflow_inputs/ld-regression-pipeline.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LD Hub\n",
    "```\n",
    "Important notes for your uploaded file:\n",
    "\n",
    "1. To save the uploading time, LD Hub only accepts zipped files as input (e.g. mydata.zip).\n",
    "\n",
    "2. Please check that there is ONLY ONE plain TXT file (e.g. mydata.txt) in your zipped file.\n",
    "\n",
    "3. Please make sure you do NOT zip any folder together with the plain txt file (e.g. /myfolder/mydata.txt), otherwise you will get an error: [Errno 2] No such file or directory\n",
    "\n",
    "4. Please do NOT zip multiple files (e.g. zip mydata.zip file1.txt file2.txt ..) or zip a file with in a folder (e.g. zip mydata.zip /path/to/my/file/mydata.txt).\n",
    "\n",
    "5. Please keep the file name of your plain txt file short (less than 50 characters), otherwise you may get an error: [Errno 2] No such file or directory\n",
    "\n",
    "6. Please zip your plain txt file using following command (ONE file at a time):\n",
    "\n",
    "For Windows system: 1) Locate the file that you want to compress. 2) Right-click the file, point to Send to, and then click Compressed (zipped) folder.\n",
    "\n",
    "For Linux and Mac OS system: zip mydata.zip mydata.txt\n",
    "\n",
    "Reminder: for Mac OS system, please do NOT zip you file by right click mouse and click \"Compress\" to zip your file, this will automatically create a folder called \"__MACOS\". You will get an error: [Errno 2] No such file or directory.\n",
    "\n",
    "Upload the trait of interest\n",
    "To save your upload time, we highly recommend you to use the SNP list we used in LD Hub to reduce the number of SNPs in your uploaded file. Click here to download our SNP list (w_hm3.noMHC.snplist.zip).\n",
    "\n",
    "Please upload the zipped file you just created. Click here to download an input example.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download outputs for each ref chr from rftm_sumstats step\n",
    "cd /shared/jmarks/hiv/ldsc/ldhub\n",
    "aws s3 sync s3://rti-cromwell-output/cromwell-execution/full_ld_regression_wf/ed5747ed-ccbe-4bc9-bb44-1f2d750a27eb/call-munge_ref/MUNGE_REF_WF.munge_sumstats_wf/e6c9491a-ca22-4ca0-8ad6-79d2b13a6dbe/call-munge_chr_wf/ .\n",
    "    \n",
    "mv  */MUNGE_CHR.munge_sumstats_chr_wf/*/call-rfmt_sumstats/hiv_acquisition_1df_meta_analysis_uhs1-4_ea+vidus_ea+wihs1_ea.chr*.exclude_singletons.1df.standardized.phase3ID.munge_ready.txt .\n",
    "\n",
    "# Concat into single file\n",
    "cat hiv_acquisition_1df_meta_analysis_uhs1-4_ea+vidus_ea+wihs1_ea.chr1.exclude_singletons.1df.standardized.phase3ID.munge_ready.txt >\\\n",
    "    hiv016_ld_hub_with_pvalues.txt\n",
    "for chr in {2..22}\n",
    "do\n",
    "    tail -n +2  hiv_acquisition_1df_meta_analysis_uhs1-4_ea+vidus_ea+wihs1_ea.chr$chr.exclude_singletons.1df.standardized.phase3ID.munge_ready.txt >>\\\n",
    "        hiv016_ld_hub_with_pvalues.txt\n",
    "done\n",
    "\n",
    "\n",
    "# Remove unnecessary columns (need snpID, A1, A2, Beta, Pvalue)\n",
    "cat hiv016_ld_hub_with_pvalues.txt | cut -f 1,4,5,6,7 > tmp && mv tmp hiv016_ld_hub_with_pvalues.txt\n",
    "\n",
    "# Add sample size column (sample = 46213.00)\n",
    "cat hiv016_ld_hub_with_pvalues.txt | awk -v OFS=\"\\t\" -F\"\\t\" '{print $1,$2,$3,$4,\"4664.000\",$5}' > hiv016_ld_hub.txt\n",
    "\n",
    "# Use vi to change column names to be:\n",
    "snpid A1 A2 BETA N P-value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter interactive mode\n",
    "docker run -it -v\"/shared/jmarks/hiv/ldsc/final/:/data/\" \\\n",
    "    rticode/plot_ld_regression_results:1ddbd682cb1e44dab6d11ee571add34bd1d06e21 /bin/bash\n",
    "    \n",
    "Rscript /opt/plot_ld_regression/plot_ld_regression_results.R  \\\n",
    "    --input_file 20170729_hiv_aqcuisition_meta016_ldsc_copd_lung_function_results_table.csv \\\n",
    "    --output_file 20170729_hiv_aqcuisition_meta016_ldsc_copd_lung_function_results_plot.pdf  \\\n",
    "    --comma_delimited\n",
    "    #--group_order_file 20170729_hiv_aqcuisition_meta016_ldsc_copd_lung_function_plot_order.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscript /opt/plot_ld_regression/plot_ld_regression_results.R \\\n",
    "    --input_file ftnd_revised_plot_table_7-29-19.csv \\\n",
    "    --output_file ftnd_ld_regression_results_7-29-19.pdf \\\n",
    "    --comma_delimited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

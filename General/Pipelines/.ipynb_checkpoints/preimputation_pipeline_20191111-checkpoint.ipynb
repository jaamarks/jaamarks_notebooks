{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pre-Imputation Automated Pipeline (chrX)\n",
    "**Author:** Jesse Marks <br>\n",
    "\n",
    "This notebook documents the procedures for the pre-imputation genotype data processing pipelineâ€”necessary for the submission to the [Michigan Imputation Server (MIS)](https://imputationserver.sph.umich.edu/start.html). To submit genotype data to MIS for imputation, you must create an account/profile on their website. \n",
    "\n",
    "The starting point (input data) for this pipeline is after the quality control (QC) of the observed genotype data. The QC genotype data should be oriented on the GRGh37 plus strand. When multiple data sets are to be merged for imputation, the intersection set of variants will be used for imputation; this is based on the finding from [Johnson et al.](https://link.springer.com/article/10.1007/s00439-013-1266-7). \n",
    "\n",
    "## Software and tools\n",
    "The software and tools used for porcessing these data are:\n",
    "* [Michigan Imputation Server](https://imputationserver.sph.umich.edu/index.html) (MIS)\n",
    "* [Amazon Web Services (AWS) - Cloud Computing Services](https://aws.amazon.com/)\n",
    "    * Linux AMI\n",
    "* [PLINK v1.90 beta 4.10](https://www.cog-genomics.org/plink/)\n",
    "* [bgzip](http://www.htslib.org/doc/tabix.html)\n",
    "* [BCF Tools](http://www.htslib.org/doc/bcftools.html)\n",
    "* Windows 10 with [Cygwin](https://cygwin.com/) installed\n",
    "* GNU bash version 4.2.46\n",
    "\n",
    "## Example Data Set\n",
    "The example cohort we test this pipeline on is [VIDUS](https://www.bccsu.ca/vidus/). There is only one ancestry associated with this cohort, namely European ancestry (EA).\n",
    "\n",
    "### QC Stats Summary:\n",
    "\n",
    "\n",
    "### Pre-Imputation Stats Summary\n",
    "| Data Set      | Initial Variants (Post-QC) | Variants Post-Filtering  | Intersection     |\n",
    "|---------------|----------------------------|--------------------------|------------------|\n",
    "|               |                            |                          |                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Directory Stucture & Download Data\n",
    "The following section needs to be modified each time to reflect:\n",
    "* where the genotype data (post-QC) are stored\n",
    "* where the base directory for the pre-imputation data processing will be\n",
    "* the study or studies involved\n",
    "* the ancesty group(s) involved\n",
    "* the data to be processed (all_chr or chr23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters \n",
    "base_dir=/shared/jmarks/hiv/wihs3/genotype/imputed/processing # DO NOT end in forward slash\n",
    "ancestry_list=\"aa ea\" # space delimited Ex. \"ea aa ha\"\n",
    "study_list=\"wihs3\" # space delimited \n",
    "#base_name=\"chr_all\" # chr_all chr23 \n",
    "\n",
    "# create directory structure\n",
    "mkdir -p ${base_dir}/{intersect,1000g,impute_prep}\n",
    "for study in ${study_list};do\n",
    "    mkdir ${base_dir}/${study}/strand_check\n",
    "\n",
    "    for ancestry in ${ancestry_list};do\n",
    "        mkdir -p ${base_dir}/${study}/genotype/${ancestry}\n",
    "        \n",
    "    done\n",
    "done\n",
    "\n",
    "\n",
    "## copy post-qc genotype data to correct directory\n",
    "## AND REMAME TO CORRECT NAMING SCHEMA <study_ancestry.$extension> \n",
    "## also unzip the Plink files\n",
    "\n",
    "#/shared/jmarks/hiv/cfar_coga/genotype/imputed/processing/cfar/genotype/aa\n",
    "#/shared/jmarks/hiv/cfar_coga/genotype/imputed/processing/cfar/genotype/ea\n",
    "#/shared/jmarks/hiv/cfar_coga/genotype/imputed/processing/cfar/genotype/ha\n",
    "#/shared/jmarks/hiv/cfar_coga/genotype/imputed/processing/coga/genotype/aa\n",
    "#/shared/jmarks/hiv/cfar_coga/genotype/imputed/processing/coga/genotype/ea\n",
    "#/shared/jmarks/hiv/cfar_coga/genotype/imputed/processing/coga/genotype/ha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRCh37 strand and allele discordance check\n",
    "### MAF for study data (all chromosomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the MAF report\n",
    "for study in ${study_list}; do\n",
    "    for ancestry in ${ancestry_list}; do\n",
    "        docker run -v \"${base_dir}/$study/:/data/\" rticode/plink:1.9 plink \\\n",
    "            --bfile /data/genotype/$ancestry/${study}_${ancestry} \\\n",
    "            --freq \\\n",
    "            --out /data/strand_check/${ancestry}\n",
    "    done\n",
    "done\n",
    "\n",
    "\n",
    "# Get list of variants from all studies\n",
    "studies=($study_list)  #studies=(uhs1 uhs2 uhs3_v1-2 uhs3_v1-3 uhs4) # array of study names\n",
    "num=${#studies[@]}\n",
    "\n",
    "## Get intersection set\n",
    "for ancestry in ${ancestry_list};do\n",
    "    bim_files=()\n",
    "    for (( i=0; i<${num}; i++ ));do\n",
    "        bim_files+=(${base_dir}/${studies[$i]}/genotype/$ancestry/*bim)\n",
    "    done\n",
    "    \n",
    "    echo -e \"\\nCalculating intersection between $ancestry ${study_list}...\\n\"\n",
    "    cat ${bim_files[@]}| cut -f2 | sort |  uniq -c | awk -v num=$num '$1 == num {print $2}' \\\n",
    "        > ${base_dir}/intersect/${ancestry}_variant_intersection.txt\n",
    "    wc -l ${base_dir}/intersect/${ancestry}_variant_intersection.txt\n",
    "done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAF for 1000G\n",
    "The current setup requires the 1000G MAF for autosomes and chrX to be processed separately. This pipeline is also currently set up to handle EUR and AFR populations. \n",
    "#### Autosomes\n",
    "Get 1000G MAF for chromosomes 1&ndash;22 (autosomes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate autosome MAFs for 1000G populations\n",
    "for ancestry in ${ancestry_list};do\n",
    "\n",
    "    if [ $ancestry == \"ea\" ]\n",
    "    then\n",
    "        pop=\"EUR\"\n",
    "    else\n",
    "        pop=\"AFR\"\n",
    "    fi\n",
    "    \n",
    "    for chr in {1..22}; do\n",
    "        /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "            --job_name ${pop}_${chr}_MAF \\\n",
    "            --script_prefix ${base_dir}/1000g/${pop}_chr${chr}.maf \\\n",
    "            --mem 6.8 \\\n",
    "            --nslots 3 \\\n",
    "            --priority 0 \\\n",
    "            --program /shared/bioinformatics/software/perl/stats/calculate_maf_from_impute2_hap_file.pl \\\n",
    "                --hap /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr${chr}.hap.gz\\\n",
    "                --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr${chr}.legend.gz \\\n",
    "                --sample /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3.sample \\\n",
    "                --chr ${chr} \\\n",
    "                --out ${base_dir}/1000g/${pop}_chr${chr}.maf \\\n",
    "                --extract ${base_dir}/intersect/${ancestry}_variant_intersection.txt \\\n",
    "                --keep_groups ${pop}\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chrX \n",
    "Get 1000G MAF for chromosome 23 (chrX)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr=23\n",
    "for ancestry in ${ancestry_list};do\n",
    "\n",
    "    if [ $ancestry == \"ea\" ]\n",
    "    then\n",
    "        pop=\"EUR\"\n",
    "    else\n",
    "        pop=\"AFR\"\n",
    "    fi\n",
    "\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name ${pop}_23_MAF \\\n",
    "        --script_prefix ${base_dir}/1000g/${pop}_chr${chr}.maf \\\n",
    "        --mem 6.8 \\\n",
    "        --nslots 1 \\\n",
    "        --priority 0 \\\n",
    "        --program /shared/bioinformatics/software/perl/stats/calculate_maf_from_impute2_hap_file.pl \\\n",
    "            --hap /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chrX_NONPAR.hap.gz\\\n",
    "            --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chrX_NONPAR.legend.gz \\\n",
    "            --sample /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3.sample \\\n",
    "            --chr $chr \\\n",
    "            --out ${base_dir}/1000g/${pop}_chr${chr}.maf \\\n",
    "            --extract ${base_dir}/intersect/${ancestry}_variant_intersection.txt \\\n",
    "            --keep_groups ${pop}\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge 1000G chromosomes\n",
    "Only need to perform this if there were multiple chromosomes for which the MAF was calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge per chr MAFs for each 1000G population\n",
    "for ancestry in ${ancestry_list};do\n",
    "    if [ $ancestry == \"ea\" ]\n",
    "    then\n",
    "        pop=\"EUR\"\n",
    "    else\n",
    "        pop=\"AFR\"\n",
    "    fi\n",
    "\n",
    "    head -n1 ${base_dir}/1000g/${pop}_chr1.maf > ${base_dir}/1000g/${pop}_chr_all.maf\n",
    "    for chr in {1..23}; do\n",
    "            tail -q -n +2 ${base_dir}/1000g/${pop}_chr${chr}.maf >> \\\n",
    "                ${base_dir}/1000g/${pop}_chr_all.maf\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autosome Discordant Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run discordance checks for each ancestry group\n",
    "for study in ${study_list}; do\n",
    "    for ancestry in ${ancestry_list};do\n",
    "        if [ $ancestry = \"ea\" ]; then\n",
    "            pop=EUR\n",
    "        else\n",
    "            pop=AFR\n",
    "        fi\n",
    "\n",
    "       /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "           --job_name ${ancestry}_${study}_crosscheck \\\n",
    "           --script_prefix ${base_dir}/$study/strand_check/${ancestry}_allele_discordance_check \\\n",
    "           --mem 6 \\\n",
    "           --nslots 3 \\\n",
    "           --priority 0 \\\n",
    "           --program \"Rscript /shared/bioinformatics/software/R/check_study_data_against_1000G.R\n",
    "               --study_bim_file ${base_dir}/${study}/genotype/${ancestry}/*bim\n",
    "               --study_frq_file ${base_dir}/${study}/strand_check/${ancestry}_chr_all.frq\n",
    "               --ref_maf_file ${base_dir}/1000g/${pop}_chr_all.maf\n",
    "               --out_prefix ${base_dir}/${study}/strand_check/${ancestry}_allele_discordance\"\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chrX Discordant Check\n",
    "Run this cell below if you are only processing chrX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for study in ${study_list}; do\n",
    "#    for ancestry in ${ancestry_list};do\n",
    "#        if [ $ancestry = \"ea\" ]; then\n",
    "#            pop=EUR\n",
    "#        else\n",
    "#            pop=AFR\n",
    "#        fi\n",
    "#\n",
    "#        # chr23 discordance check\n",
    "#        /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#            --job_name ${ancestry}_${study}_crosscheck \\\n",
    "#            --script_prefix ${base_dir}/${study}/strand_check/${ancestry}_allele_discordance_check \\\n",
    "#            --mem 6.8 \\\n",
    "#            --nslots 1 \\\n",
    "#            --priority 0 \\\n",
    "#            --program \"Rscript /shared/bioinformatics/software/R/check_study_data_against_1000G.R\n",
    "#                --study_bim_file ${base_dir}/data/${study}/genotype/${ancestry}/*bim\n",
    "#                --study_frq_file ${base_dir}/${study}/strand_check/${ancestry}_chr23.frq\n",
    "#                --ref_maf_file ${base_dir}/1000g/${pop}_chr23.maf\n",
    "#                --out_prefix ${base_dir}/${study}/strand_check/${ancestry}_allele_discordance\"\n",
    "#    done\n",
    "#done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolving allele discordances\n",
    "The allele discordances will be resolved by\n",
    "* Flipping allele discordances that are fixed by flipping\n",
    "* Removing SNPs with discordant names\n",
    "* Removing SNPs with discordant positions\n",
    "* Removing allele discordances that are not resolved by flipping\n",
    "* Removing alleles with large deviations from the reference population allele frequencies\n",
    "\n",
    "**Note**: that we could flip the SNPs that are in the snps.flip file we create here, however we are going to opt not to this time because we found that for this case flipping did not actually resolve the issue because most likely they were monomorphic variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply filters\n",
    "for study in ${study_list}; do\n",
    "    for ancestry in ${ancestry_list};do\n",
    "        echo -e \"\\n===============\\nProcessing ${study}_${ancestry}\\n\"\n",
    "        echo \"Making remove list\"\n",
    "        cat <(cut -f2,2 ${base_dir}/${study}/strand_check/${ancestry}_allele_discordance.discordant_alleles_not_fixed_by_strand_flip | tail -n +2) \\\n",
    "            <(cut -f2,2 ${base_dir}/${study}/strand_check/${ancestry}_allele_discordance.at_cg_snps_freq_diff_gt_0.2 | tail -n +2) \\\n",
    "            <(cut -f2,2 ${base_dir}/${study}/strand_check/${ancestry}_allele_discordance.discordant_names | tail -n +2) \\\n",
    "            <(cut -f2,2 ${base_dir}/${study}/strand_check/${ancestry}_allele_discordance.discordant_positions | tail -n +2) \\\n",
    "            <(cut -f2,2 ${base_dir}/${study}/strand_check/${ancestry}_allele_discordance.discordant_alleles_polymorphic_in_study_not_fixed_by_strand_flip | tail -n +2) | \\\n",
    "              sort -u > ${base_dir}/${study}/strand_check/${ancestry}_snps.remove\n",
    "\n",
    "        # Create flip list\n",
    "        echo \"Making flip list\"\n",
    "        comm -23 <(cut -f2,2 ${base_dir}/${study}/strand_check/${ancestry}_allele_discordance.discordant_alleles | tail -n +2 | sort -u) \\\n",
    "                 <(cut -f2,2 ${base_dir}/${study}/strand_check/${ancestry}_allele_discordance.discordant_alleles_not_fixed_by_strand_flip | tail -n +2 | sort -u) \\\n",
    "                 > ${base_dir}/${study}/strand_check/${ancestry}_snps.flip\n",
    "\n",
    "        # Apply filters\n",
    "        docker run -v ${base_dir}/$study/:/data/ rticode/plink:1.9 plink \\\n",
    "            --bfile  /data/genotype/${ancestry}/${study}_${ancestry} \\\n",
    "            --exclude /data/strand_check/${ancestry}_snps.remove \\\n",
    "            --make-bed \\\n",
    "            --out     /data/${ancestry}_filtered\n",
    "    done\n",
    "done\n",
    "\n",
    "wc -l $base_dir/*/*filtered.bim\n",
    "wc -l $base_dir/*/strand_check/*remove\n",
    "#wc -l $base_dir/*/strand_check/*snps.flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove monomorphic variants\n",
    "Monomorphic variants prevent MIS from accepting the genotype data. In this case, an arbitrarily small MAF is set that is smaller than the lower bound for these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply filters\n",
    "for study in ${study_list}; do\n",
    "    for ancestry in ${ancestry_list};do\n",
    "        docker run -v \"${base_dir}/$study/:/data/\" rticode/plink:1.9 plink \\\n",
    "            --bfile /data/${ancestry}_filtered \\\n",
    "            --maf 0.000001 \\\n",
    "            --make-bed \\\n",
    "            --out /data/${ancestry}_filtered_mono\n",
    "    done\n",
    "done\n",
    "\n",
    "wc -l $base_dir/*/*mono.bim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snp Intersection\n",
    "Only perform if merging datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies=($study_list)  #studies=(UHS1 UHS2 UHS3_v1-2 UHS3_v1-3) # array of study names\n",
    "\n",
    "# Make new PLINK binary file sets\n",
    "for ancestry in ${ancestry_list};do\n",
    "    for study in ${studies[@]}; do\n",
    "        docker run -v \"${base_dir}/:/data/\" rticode/plink:1.9 plink \\\n",
    "            --bfile /data/$study/${ancestry}_filtered_mono \\\n",
    "            --extract /data/intersect/${ancestry}_variant_intersection.txt \\\n",
    "            --make-bed \\\n",
    "            --out /data/intersect/${study}_${ancestry}_filtered_snp_intersection\n",
    "    done\n",
    "done\n",
    "    \n",
    "ww $base_dir/intersect/*section.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge test\n",
    "As a final check to confirm that our data sets are all compatible, a PLINK file set merge is conducted. If any issues persist then an error will be raised. \n",
    "\n",
    "Only run this section if merging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ancestry in $ancestry_list; do\n",
    "    echo \"Creating $ancestry merge-list\"\n",
    "    truncate -s 0 ${base_dir}/intersect/${ancestry}_merge_list.txt\n",
    "    for study in $study_list; do\n",
    "        echo /data/${study}_${ancestry}_filtered_snp_intersection >>\\\n",
    "        ${base_dir}/intersect/${ancestry}_merge_list.txt\n",
    "    done\n",
    "    \n",
    "# Merge file sets\n",
    "    echo -e \"\\n\\n======== ${ancestry} ========\\n\\n\"\n",
    "    docker run -v \"${base_dir}/intersect:/data/\" rticode/plink:1.9 plink \\\n",
    "        --merge-list /data/${ancestry}_merge_list.txt \\\n",
    "        --make-bed \\\n",
    "        --out /data/${ancestry}_studies_merged\n",
    "done\n",
    "\n",
    "wc -l $base_dir/intersect/*merged*bim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation preparation for Michigan Imputation Server\n",
    "Visit the [MIS Getting Started Webpage](https://imputationserver.sph.umich.edu/start.html#!pages/help) for more information about the preparing the data for upload to MIS.\n",
    "\n",
    "### Remove individuals missing whole chromsome\n",
    "Remove any individual missing, essentially, an entire chromosome. Then convert the data to VCF format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If NO merging was performed\n",
    "(i.e. only one study being processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split by chr and remove any individuals with missing data for whole chr\n",
    "for ancestry in $ancestry_list; do\n",
    "    for chr in {1..23}; do\n",
    "        docker run -v \"${base_dir}/:/data/\" rticode/plink:1.9 plink \\\n",
    "            --bfile /data/$study/${ancestry}_filtered_mono \\\n",
    "            --chr ${chr} \\\n",
    "            --mind 0.99 \\\n",
    "            --make-bed \\\n",
    "            --out /data/impute_prep/${ancestry}_chr${chr}_for_phasing \n",
    "    done\n",
    "done > ${base_dir}/impute_prep/chr_splitting.log \n",
    "\n",
    "\n",
    "## look through log files to determine if any subjects were removed\n",
    "for ancestry in $ancestry_list; do\n",
    "    grep removed $base_dir/impute_prep/$ancestry*log |\n",
    "        perl -lne '/(\\d+)(\\speople)/;\n",
    "             $mycount += $1; \n",
    "             print $mycount if eof'  > $base_dir/impute_prep/$ancestry.removed\n",
    "    any_removed=$(cat $base_dir/impute_prep/$ancestry.removed)\n",
    "    if [ \"$any_removed\" == 0 ]; then\n",
    "        echo \"No $ancestry subjects removed\"\n",
    "    else\n",
    "        echo \"Some $ancestry subjects removed\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If merging was performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split by chr and remove any individuals with missing data for whole chr\n",
    "for chr in {1..23}; do \n",
    "    for ancestry in $ancestry_list;do\n",
    "        docker run -v \"${base_dir}:/data/\" rticode/plink:1.9 plink \\\n",
    "            --bfile /data/intersect/${ancestry}_studies_merged \\\n",
    "            --chr ${chr} \\\n",
    "            --mind 0.99 \\\n",
    "            --make-bed \\\n",
    "            --out /data/impute_prep/${ancestry}_chr${chr}_for_phasing\n",
    "    done > ${base_dir}/impute_prep/chr_splitting.log \n",
    "done\n",
    "\n",
    "\n",
    "## look through log files to determine if any subjects were removed\n",
    "for ancestry in $ancestry_list; do\n",
    "    grep removed $base_dir/impute_prep/$ancestry*log |\n",
    "        perl -lne '/(\\d+)(\\speople)/;\n",
    "             $mycount += $1; \n",
    "             print $mycount if eof'  > $base_dir/impute_prep/$ancestry.removed\n",
    "    any_removed=$(cat $base_dir/impute_prep/$ancestry.removed)\n",
    "    if [ \"$any_removed\" == 0 ]; then\n",
    "        echo \"No $ancestry subjects removed\"\n",
    "    else\n",
    "        echo \"Some $ancestry subjects removed\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ancestry in ${ancestry_list}; do\n",
    "    mkdir -p ${base_dir}/impute_prep/${ancestry}\n",
    "    for chr in {1..23}; do\n",
    "        docker run -v \"${base_dir}/impute_prep/:/data/\" rticode/plink:1.9 plink \\\n",
    "            --bfile /data/${ancestry}_chr${chr}_for_phasing \\\n",
    "            --output-chr M \\\n",
    "            --set-hh-missing \\\n",
    "            --recode vcf bgz \\\n",
    "            --out /data/$ancestry/${ancestry}_chr${chr}_final\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer the *.vcf.gz files to local machine (per chromosome) and then upload to MIS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Michigan Imputation Server (MIS)\n",
    "Transfer the `*.vcf` files to local machine (per chromosome) and then upload to MIS.\n",
    "\n",
    "## Uploading parameters EA\n",
    "These are the parameters that were selected on MIS:\n",
    "\n",
    "__Name__: VIDUS_ea_chr23\n",
    "\n",
    "__Reference Panel__ 1000G Phase 3 v5\n",
    "\n",
    "__Input Files__ File Upload <br>\n",
    "\n",
    "* Select Files - select VCF files that were downloaded to local machine from cloud. <br>\n",
    "\n",
    "__Phasing__: ShapeIT v2.r790 (unphased) \n",
    "\n",
    "__Population__: EUR\n",
    "\n",
    "__Mode__: Quality Control & Imputation\n",
    "\n",
    "* I will not attempt to re-identify or contact research participants.\n",
    "* I will report any inadvertent data release, security breach or other data management incident of which I become aware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Validation**\n",
    "```\n",
    "1 valid VCF file(s) found.\n",
    "\n",
    "Samples: 940\n",
    "Chromosomes: X\n",
    "SNPs: 14705\n",
    "Chunks: 8\n",
    "Datatype: unphased\n",
    "Reference Panel: phase3\n",
    "Phasing: shapeit\n",
    "```\n",
    "\n",
    "**Quality Control**\n",
    "```\n",
    "ChrX Statistics: \n",
    "Submitting 2 jobs: \n",
    "chrX Non.Par male ( as Chr X II ) \n",
    "chrX Non.Par female ( as Chr X I ) \n",
    "NonPar Sex Check: \n",
    "Males: 712\n",
    "Females: 228\n",
    "No Sex dedected and therefore filtered: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Imputed Data from MIS\n",
    "First Download the data form the Michigan Imputation Server by clicking on the link provided in the email they send out to alert you that your data has finished. Here you will find commands for downloading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestry=aa\n",
    "study=wihs3\n",
    "passW=\"6pc6BrQVevuMW\"\n",
    "cd /shared/jmarks/hiv/wihs3/genotype/imputed/final/$ancestry\n",
    "\n",
    "\n",
    "# download.file\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "# QC-results\n",
    "curl -sL https://imputationserver.sph.umich.edu/get/1600201/69680c1f7e70788e97868263a39b117f | bash\n",
    "# Logs\n",
    "curl -sL https://imputationserver.sph.umich.edu/get/1600208/4d9447d59c8572d741c6a37b23fb9419 | bash\n",
    "# SNP Statistics\n",
    "curl -sL https://imputationserver.sph.umich.edu/get/1600207/af4d6be166bd84f15c33b656fe4c6916 | bash\n",
    "# Imputation Results\n",
    "curl -sL https://imputationserver.sph.umich.edu/get/1600204/6e97e687b015a8503a2562ec243e7f03 | bash\n",
    "\n",
    "####################################################################################################\n",
    "####################################################################################################\n",
    "\n",
    "# inflate chr results\n",
    "for file in *zip; do\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "        --job_name unzip.$study.$ancestry.$file \\\n",
    "        --script_prefix unzip.imputed.$study.$ancestry.data \\\n",
    "        --mem 3 \\\n",
    "        --nslots 2 \\\n",
    "        --priority 0 \\\n",
    "        --program unzip -P $passW $file \n",
    "done\n",
    "\n",
    "# we can remove the original imputed data from MIS after we inflate the zip files\n",
    "rm -rf *zip\n",
    "\n",
    "# upload to s3\n",
    "aws s3 sync . s3://rti-hiv/wihs3/data/genotype/imputed/$ancestry --quiet &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "746px",
    "left": "0px",
    "right": "1533.47px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

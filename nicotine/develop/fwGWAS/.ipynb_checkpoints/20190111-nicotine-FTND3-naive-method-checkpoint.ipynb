{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fwGWAS Naive Method (baseline model)\n",
    "## Functional weighted SCZ1 (wave1) GWAS results \n",
    "**Author:** Jesse Marks <br>\n",
    "**Programming Language:** Python3\n",
    "\n",
    "This is the first method we are testing for the functional weighting GWAS (fwGWAS) method comparison. We are referring to this method as the Naive Method or the baseline model. This approach&mdash;based off of the 2016 Nature Genetics paper by Sveinbjornsson et al.&mdash;uses disparate P-value thresholds for each sequence variant functional category. More specifically, sequence variants are grouped into four categories: <br>\n",
    "i) **loss-of-function variants** <br>\n",
    "ii) **moderate-impact variants** <br>\n",
    "iii) **low-impact variants** <br>\n",
    "iv) **other** <br>\n",
    "\n",
    "A disparate P-value threshold will be applied to each variant depending on which of the four categories it assigned to. A variant is assigned to a group based on its functional annotation and its putative functional effects. We use the software SnpEff to annotate the variants.\n",
    "\n",
    "This notebook details the methods (functions) developed to carry out the Naive Method on the wave 2 FTND (FTND2) data set. Our goal is to assess the benefits of applying functional weighted significance thresholds (fwGWAS) to GWAS results vs applying the field standard $5E-08$ threshold. In particular, we would like to see if when we take a fwGWAS approach if it results in identifying some novel variants that were not deemed significant when compared to the field standard threshold. Does the fwGWAS approach predict significant variants that the standard approach does not? When we add more samples, thus more power, do we indeed see those variants deemed significant that were predicted by fwGWAS approach? To test these inquiries we will apply fwGWAS to SCZ1 and then compare those results with the results from SZC2 (second wave of study cohort where more samples were added) where we apply the field standard $5E-08$. We will be able to determine if the novel variants picked up by fwGWAS on SCZ1 were indeed significant when more samples were added with SCZ2.\n",
    "\n",
    "The FTND3 GWAS results are located on Azure (FIPS MOD) at the path:\n",
    "\n",
    "`/share/storage/Johnson/fwGWAS/data/SCZ/SCZ1/pgc.scz.full.2012-04.hg19.phase3ID.cleaned.txt.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input file\n",
    "The input file is the summary statistics of a GWAS. The variant names (MarkerNames) should be in 1000 genome phase3 format (rsid:position:A1:A2). The pipeline will first convert these GWAS statistics to variant call format (VCF). This is the format accepted by the SnpEff software that generates the variants annotations.\n",
    "\n",
    "**Note, make sure your headers are appropriately named** <br>\n",
    "The headers should have the following 7 columns:\n",
    "\n",
    "* `chr` \n",
    "* `MarkerName`\n",
    "* `position`\n",
    "* `Allele1`\n",
    "* `Allele2`\n",
    "* `P-value`\n",
    "\n",
    "A sample of what the GWAS summary statistics should look like:\n",
    "```\n",
    "MarkerName chr position Allele1 Allele2 Effect StdErr P-value Direction HetISq HetChiSq HetDf HetPVal\n",
    "rs372150258:569896:A:G 1 569896 a g -0.0089 0.0625 0.8871 +++?-?-?+???????-??-???+?-??? 20.4 11.301 9 0.2556\n",
    "rs368347679:569933:G:A 1 569933 a g -0.0173 0.0187 0.3551 -+------+-?+-???--?+?-?+--+?? 10.5 21.232 19 0.3241\n",
    "1:569998:C:T 1 569998 t c 0.0944 0.0669 0.1581 +-+?+?+?+???????+??-???-?+??? 28.3 12.560 9 0.1835\n",
    "1:570002:A:G 1 570002 a g -0.1021 0.0653 0.1177 ---?-?-?+???????-??+???+?-??? 19.7 11.210 9 0.2616\n",
    "rs9326625:570076:T:C 1 570076 t c -0.0125 0.0386 0.7461 -++?-?-?-???????-??+???+?+??? 9.5 9.941 9 0.3553\n",
    "rs9283156:570079:C:T 1 570079 t c -0.0131 0.0390 0.7377 ++-?+?-?+???????-??-???-?+??? 0.0 7.320 9 0.6038\n",
    "rs7339962:570094:G:A 1 570094 a g -0.0410 0.0538 0.446 ---?+?-?+???????-??-???+????? 0.0 4.922 8 0.7659\n",
    "rs2298012:570097:A:G 1 570097 a g -0.0095 0.0346 0.784 --+?-?-?-???????-??+???+?-??? 38.1 14.533 9 0.1046\n",
    "rs9326626:570178:G:A 1 570178 a g 0.0117 0.0488 0.8114 ++-?+?+?+???????-??-???-?-??? 21.5 11.472 9 0.2447\n",
    "rs368120791:570638:T:C 1 570638 t c 0.0053 0.0181 0.771 +--++++--+?-+???++?-?+?-++-?? 28.1 26.433 19 0.1186\n",
    "```\n",
    "\n",
    "One should rename their header to match the 7 columns that are needed for the analysis, or alter the code in function one to reflect the respective headers names in their GWAS statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SnpEff Software\n",
    "[SnpEff](http://snpeff.sourceforge.net/index.html) is a variant annotation and effect prediction tool that we will be using to perform the sequence variant annotations. It is located at: <br>\n",
    "`/share/storage/Johnson//share/storage/Johnson/software/SnpEff/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Main\n",
    "Execute all functions in sequence. The user needs to only modify the 5 variables at the top of this main function; everything else is taken care of in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Python3 ###\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Carryout all the functions necessary to \n",
    "    perform the fwGWAS naive method. Please\n",
    "    there are simply for variables to \n",
    "    \"\"\"\n",
    "\n",
    "    ### Variables to alter\n",
    "################################################################################\n",
    "    study = \"SCZ1\"\n",
    "    date = 20190110\n",
    "    # path to directory containing the GWAS results (should end with a forward slash)\n",
    "    data_dir = '/share/storage/FTND/data/wave2_FTND/20180627/'\n",
    "    # name of the GWAS results file in the directory above\n",
    "    rtvf_in = data_dir + 'ftnd-wave2-gwas-results.txt.gz'\n",
    "    # path to directory data processing performed (should end with a forward slash)\n",
    "    processing_dir = '/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/scz1/006/'\n",
    "    # name of the initial VCF file to be created (note the extension)\n",
    "    rtvf_out = \"{a}{b}-{c}.vcf\".format(a=processing_dir, b=date, c=study) \n",
    "    print(rtvf_out)\n",
    "    \n",
    "    ### DO NOT alter below this line\n",
    "    ################################################################################\n",
    "    \n",
    "    # Convert GWAS results to VCF format\n",
    "    se_inF = results_to_vcf_format(in_file=rtvf_in,\n",
    "                                   out_file=rtvf_out)\n",
    "    se_outF = se_inF[:-4] + '-ann.vcf'\n",
    "\n",
    "    # Run SnpEff to obtain annotations\n",
    "    ex_inF = snp_eff(base_dir=processing_dir, \n",
    "                     in_file=se_inF, \n",
    "                     out_file=se_outF)\n",
    "    ex_outF = ex_inF[:-4] + '-extracted'\n",
    "\n",
    "    # Extract annotations, IDs, and P-values\n",
    "    ga_inF = extract_ann(in_file=ex_inF,\n",
    "                         out_file=ex_outF)\n",
    "    ga_outF = ga_inF + '-grouped'\n",
    "    \n",
    "    # Group variants into the four function annotation categories\n",
    "    ff_inF = group_annotations(in_file=ga_inF,\n",
    "                               out_file=ga_outF)\n",
    "    ff_outF = ff_inF + '-filtered-fw'\n",
    "    \n",
    "    # Filter using the four fw-thresholds\n",
    "    rs_inF1 = filter_fw(in_file=ff_inF,\n",
    "                        out_file=ff_outF)\n",
    "    \n",
    "    fs_outF = ff_inF + '-filtered-std'\n",
    "    \n",
    "    # Filter using the standard GWAS threshold (5e-8)\n",
    "    rs_inF2 = filter_standard(in_file=ga_outF, \n",
    "                             out_file=fs_outF)\n",
    "    rs_out = rtvf_out[:-4] + '-results-summary'\n",
    "    \n",
    "    # Get results summary\n",
    "    fw_file, std_file, repro_file = results_summary(in_file=rs_inF1,\n",
    "                                                    in_file2=rs_inF2, \n",
    "                                                    out_file=rs_out)\n",
    "\n",
    "    # generate table for Manhattan plot\n",
    "    in_data = rtvf_out\n",
    "    out_table = in_data[0:-3] + \"table\"\n",
    "    genome_table = gw_table(in_data,out_table)\n",
    "\n",
    "    # generate highlight tables for Manhattan plot\n",
    "    fw_table = highlight_table(fw_file)\n",
    "    std_table = highlight_table(std_file)\n",
    "    repro_table = highlight_table(repro_file)\n",
    "\n",
    "    # plotting\n",
    "    plot_tables(genome_table, repro_table, \"yellow\", \"reproduced\", study)\n",
    "    plot_tables(genome_table, std_table, \"red\", \"lossed\", study)\n",
    "    plot_tables(genome_table, fw_table, \"green\", \"novel\", study)\n",
    "    general_plot(genome_table, study)\n",
    "\n",
    "\n",
    "    return\n",
    "\n",
    "## Function1\n",
    "def results_to_vcf_format(in_file, out_file):\n",
    "    \"\"\"\n",
    "    The SnpEff software expects, as input, a file in VCF format. \n",
    "    This function performs the conversion of the GWAS results \n",
    "    to VCF format so that SnpEff can obtain the annotations.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file - GWAS results file. \n",
    "    out_file - Name (and path) of the VCF file to be created.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    import gzip, sys\n",
    "    try:\n",
    "        with gzip.open(in_file, 'rt') as inF:\n",
    "            with open(out_file, 'wt') as outF:\n",
    "                head = inF.readline()\n",
    "    \n",
    "                head_line = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "                outF.write('\\t'.join(head_line) + '\\n')\n",
    "                split_line = head.split()\n",
    "     \n",
    "                try:\n",
    "                    pval_index = split_line.index('P-value')\n",
    "                    chr_index = split_line.index('chr')\n",
    "                    rsid_index = split_line.index('MarkerName')\n",
    "                    position_index = split_line.index('position')\n",
    "                    ref_allele_index = split_line.index('Allele1')\n",
    "                    alt_allele_index = split_line.index('Allele2')\n",
    "                except (ValueError):\n",
    "                    sys.exit(\"Make sure the headers are appropriately named:\")\n",
    "\n",
    "                # skip the header now\n",
    "                line = inF.readline()\n",
    "                while(line):\n",
    "                    split_line = line.split()\n",
    "     \n",
    "                    f1 = split_line[chr_index]\n",
    "                    f2 = split_line[position_index]\n",
    "                    f3 = split_line[rsid_index]\n",
    "                    f4 = split_line[ref_allele_index]\n",
    "                    f5 = split_line[alt_allele_index]\n",
    "                    f6 = '.'\n",
    "                    f7 = '.'\n",
    "                    f8 = split_line[pval_index]\n",
    "     \n",
    "                    vcf_list = [f1, f2, f3, f4, f5, f6, f7, f8]\n",
    "                    outF.write('\\t'.join(vcf_list) + '\\n')\n",
    "                    line = inF.readline()\n",
    "    except (OSError):\n",
    "        sys.exit(\"Couldn't recognize input file. Make sure your have specified the file name\\\n",
    "                correctly. Also make sure to gzip the input file.\")\n",
    "    return out_file; \n",
    "\n",
    "\n",
    "## Function2\n",
    "def snp_eff(base_dir, in_file, out_file):\n",
    "    \"\"\"\n",
    "    This function executes the SnpEff software that annotates the\n",
    "    sequence variants using the Genome Build 37 as the reference.'\n",
    "    \n",
    "    INPUT:\n",
    "    base_dir - path were results should be saved.\n",
    "    in_file - name (and path) of VCF file for input to SnpEff\n",
    "    out_file - name of the output annotated VCF.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    \n",
    "    import subprocess\n",
    "\n",
    "    ### DO NOT modify these variables\n",
    "    ###########################################################################\n",
    "    config_path = '/share/storage/Johnson/software/SnpEff/snpEff/snpEff.config' \n",
    "    snpEff_path = '/share/storage/Johnson/software/SnpEff/snpEff/snpEff.jar'\n",
    "    snp_eff = base_dir + 'snp-eff.sh'\n",
    "    # -t for multithreading implies -noStats (speeds process way up)\n",
    "    command_list = ['java', '-Xmx8g', '-jar', snpEff_path, '-c', config_path, '-v',\n",
    "                    '-t', 'GRCh37.75', in_file, '>', out_file]\n",
    "    command_string = ' '.join(command_list)\n",
    "    ###########################################################################\n",
    "\n",
    "    # save command as a bash script\n",
    "    with open(snp_eff, 'w') as outF:\n",
    "        message = '#!/usr/bin/bash\\n'\n",
    "        message += command_string\n",
    "        outF.write(message)\n",
    "\n",
    "    # execute bash script\n",
    "    run_command = ['bash', snp_eff]\n",
    "    subprocess.run(run_command)\n",
    "    return out_file\n",
    "\n",
    "## Function3\n",
    "def extract_ann(in_file, out_file):\n",
    "    \"\"\"\n",
    "    Extract the annotation information from the SnpEff\n",
    "    results VCF file. The unique ID and GWAS P-value\n",
    "    for each variant is extracted as well.\n",
    "    \n",
    "    INPUT: \n",
    "    in_file - The name of the file that was output from SnpEff.\n",
    "              The file should be in vcf format and have in the \n",
    "              INFO field the pval+annotation for each variant.\n",
    "    out_file - Name of the file for which to save the results \n",
    "               of this function to. This file will have the \n",
    "               following three fields:\n",
    "          2. rsID\n",
    "          1. unique ID (CHR:POSTION:A1:A2)\n",
    "          2. sequence variant annotation (e.g. stop-gain,)\n",
    "          3. P-value\n",
    "    OUTPUT: \n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(in_file, 'r') as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    " \n",
    "            while line[0] == '#':\n",
    "                line = inF.readline()\n",
    "      \n",
    "            while(line):\n",
    "                split_line = line.split()\n",
    "                #unique_id = split_line[0] + ':' + split_line[1] + \\\n",
    "                #    ':' + split_line[3] + ':' + split_line[4]\n",
    "                unique_id = split_line[2]\n",
    "                #rsID = unique_id.split(':')[0] # only rsID if in 1000g_p3 format\n",
    "                chrom = split_line[0]               \n",
    "                info_field = split_line[7]\n",
    "                all_annotations = info_field.split(';')\n",
    "                pval = all_annotations[0]\n",
    "                functional_annotations = all_annotations[1].split(',')\n",
    "                for item in functional_annotations:\n",
    "                    output = chrom + '\\t' + unique_id + '\\t' + item.split('|')[1] + '\\t' + pval\n",
    "                    outF.write(output + '\\n')\n",
    "                line = inF.readline()  \n",
    "    return out_file;\n",
    "\n",
    "## Function4\n",
    "def group_annotations(in_file, out_file):\n",
    "    \"\"\"\n",
    "    Categorized the variants into groups based off\n",
    "    of their annotations.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file - the file name (and path) of the file\n",
    "              that contains the variant annotations.\n",
    "    out_file - the file name (and path) of the output file\n",
    "               that will essentially append the variant group\n",
    "               to the in_put file.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    with open(in_file, 'r') as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    "            group_dict = {}\n",
    "            # add loss-of-function variants\n",
    "            group_dict['loss-of-function variants'] = ['stop_gained', \n",
    "                                                      'stop_lost', \n",
    "                                                      'frameshift_variant', \n",
    "                                                      'splice_donor_variant', \n",
    "                                                      'splice_acceptor_variant', \n",
    "                                                      'initiator_codon_variant']\n",
    "            # add moderate-impact variants\n",
    "            group_dict['moderate-impact variants'] = ['missense_variant', \n",
    "                                                     'inframe_insertion', \n",
    "                                                     'splice_region_variant']\n",
    "            # add low-impact variants\n",
    "            group_dict['low-impact variants'] = ['synonymous_variant', \n",
    "                                                '3_prime_UTR_variant', \n",
    "                                                '5_prime_UTR_variant', \n",
    "                                                'upstream_gene_variant', \n",
    "                                                'downstream_gene_variant']\n",
    "            ## Group variants based on their categorization.\n",
    "            while(line):\n",
    "                split_line = line.split()\n",
    "                # Search for ann in dict.\n",
    "                for item in group_dict:\n",
    "                    if split_line[2] in group_dict[item]:\n",
    "                        split_line.append(item)\n",
    "                        break\n",
    "                # If the variant was not in any of the three groups;\n",
    "                # then it is categorized as an 'other' variant.\n",
    "                if len(split_line) == 4:\n",
    "                    split_line.append('other')\n",
    "                outF.write('\\t'.join(split_line) + '\\n')\n",
    "                line = inF.readline()\n",
    "    return out_file;\n",
    "\n",
    "\n",
    "## Function5\n",
    "def filter_fw(in_file, out_file):\n",
    "    \"\"\"\n",
    "    This function filters the variants by comparing the sequence\n",
    "    variant P-values obtained from the GWAS results with the \n",
    "    functional-weighted threshold.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file - name (and path) of the input file that contains the \n",
    "              variant groupings.\n",
    "    out_file - name (and path) of the output file that will be the\n",
    "               fw-threshold filtered file.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    with open(in_file) as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    "            loss_func = 5.5e-7\n",
    "            mod_impact = 1.1e-7\n",
    "            low_impact = 1.0e-8\n",
    "            other = 1.7e-9\n",
    "            thresh_dict = {'loss-of-function variants': loss_func,\n",
    "                           'moderate-impact variants': mod_impact,\n",
    "                           'low-impact variants': low_impact,\n",
    "                           'other': other}\n",
    "            while(line):\n",
    "                split_line = line.split('\\t')\n",
    "                group = split_line[4].strip()\n",
    "                pval = float(split_line[3])\n",
    "                if pval <= thresh_dict[group]:\n",
    "                    outF.write(line)\n",
    "                line = inF.readline()\n",
    "    return out_file;\n",
    "\n",
    "## Function6\n",
    "def filter_standard(in_file, out_file):\n",
    "    \"\"\"\n",
    "    This function filters the variants by comparing the sequence\n",
    "    variant pvalues obtained from the GWAS results with the \n",
    "    standard GWAS threshold of 5e-8.\n",
    "         \n",
    "    INPUT:\n",
    "    in_file - name (and path) of the input file that contains the \n",
    "              variant groupings.\n",
    "    out_file - name (and path) of the output file that will be the\n",
    "               standard-threshold filtered file.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    with open(in_file) as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    "            bf_threshold = 5e-8\n",
    "            #\n",
    "            while(line):\n",
    "                split_line = line.split('\\t')\n",
    "                group = split_line[4].strip()\n",
    "                pval = float(split_line[3])\n",
    "                if pval <= bf_threshold:\n",
    "                    outF.write(line)\n",
    "                line = inF.readline()\n",
    "    return out_file;\n",
    "\n",
    "\n",
    "\n",
    "## Function7\n",
    "def results_summary(in_file, in_file2, out_file):\n",
    "    \"\"\"\n",
    "    The function takes as input the two results files from the threshold filtering\n",
    "    performed above and outputs the summary statistics. Specifically, the output file \n",
    "    will contain two counts-dictionaries. One dict will count the number of variants \n",
    "    in each functional group that was exclusive to the fw-thresholded sequence\n",
    "    variants. The other will be for the variants exclusive to the standard WGS P-value\n",
    "    thresholded results.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file -  name of the fw-thresholded file\n",
    "    in_file2 - name of the standard thresholded file\n",
    "    out_file - Name of the file to which the summary statistics will be saved.\n",
    "    \n",
    "    OUTPUT:\n",
    "    Nothing is returned from this function, however three files are output. One is\n",
    "    the out_file provided as input, and then two additional files are created.\n",
    "    \n",
    "    additional01 - File assumes the name <out_file>-fw-variants and includes a list of \n",
    "                   the variants that were deemed significant only when the fw-thresholds\n",
    "                   were applied as thresholds of significance.\n",
    "    additional02 - File assumes the name <out_file>-std-variants and includes a list of\n",
    "                   the variants that were deemed significant only when the standard\n",
    "                   threshold (5e-8) was applied.\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "     \n",
    "    uniq_fw = out_file+'-uniq-fw-variants'\n",
    "    uniq_std = out_file+'-uniq-std-variants'\n",
    "    overlap = out_file + '-replicated-variants'\n",
    "    ## compare the two filtered files and print the variants \n",
    "    #  Exclusive to the fw-thresholded variants\n",
    "    bash_command = 'bash -c \"comm -23 <(sort {0}) <(sort {1})\"'.format(in_file, in_file2)\n",
    "    fw_exclusive = subprocess.run(bash_command, shell=True, stdout=subprocess.PIPE, encoding='utf-8').stdout\n",
    "    # Exlusive to the standard thresholded variants (5e-8)\n",
    "    bash_command2 = 'bash -c \"comm -13 <(sort {0}) <(sort {1})\"'.format(in_file, in_file2)\n",
    "    standard_exclusive = subprocess.run(bash_command2, shell=True, stdout=subprocess.PIPE, encoding='utf-8').stdout\n",
    "    # Variants deemed siginificant using both thresholding methods\n",
    "    bash_command3 = 'bash -c \"comm -12 <(sort {0}) <(sort {1}) \"'.format(in_file, in_file2)\n",
    "    both_methods = subprocess.run(bash_command3, shell=True, stdout=subprocess.PIPE, encoding='utf-8').stdout\n",
    "    \n",
    "    # keep only unique SNPs\n",
    "    def remove_dups(old_string):\n",
    "        snp_dict = {}\n",
    "        new_string = \"\"\n",
    "        for line in old_string.splitlines():\n",
    "            my_snp = line.split()[1]\n",
    "            if my_snp not in snp_dict:\n",
    "                new_string += line + \"\\n\"\n",
    "            snp_dict[my_snp] = \"present\"\n",
    "        return new_string\n",
    "    fw_exclusive2 = remove_dups(fw_exclusive)\n",
    "    standard_exclusive2 = remove_dups(standard_exclusive)\n",
    "    both_methods2 = remove_dups(both_methods)\n",
    "    \n",
    "    with open(out_file, 'w') as outF:\n",
    "        for count,string in enumerate([fw_exclusive2, standard_exclusive2, both_methods2]):\n",
    "            counts_dict = {'loss-of-function variants':0,\n",
    "                           'moderate-impact variants':0,\n",
    "                           'low-impact variants':0,\n",
    "                           'other':0}\n",
    "            if count == 0:\n",
    "                message = '####\\n####Novel variants.\\n\\n'\n",
    "            elif count == 1:\n",
    "                message = '\\n\\n####\\n####Variants not replicated.\\n\\n'\n",
    "            else:\n",
    "                message = '\\n\\n####\\n####Variants that were replicated.\\n\\n'\n",
    " \n",
    "            split_lines = string.splitlines()\n",
    "            if split_lines: # if there are any SNPs \n",
    "                uniq_snps = {}\n",
    "                for line in split_lines:\n",
    "                    snp = line.split('\\t')[0]\n",
    "                    if snp not in uniq_snps:\n",
    "                        uniq_snps[snp] = None\n",
    "                        ann = line.split('\\t')[4]\n",
    "                        counts_dict[ann] += 1\n",
    "            dict_sum = str(sum(counts_dict.values()))\n",
    "            dict_sum = '\\nTotal number of variants: {}'.format(dict_sum)\n",
    "            outF.write(message)\n",
    "            outF.write(str(counts_dict) + dict_sum + '\\n')\n",
    "    with open(uniq_fw, 'w') as fwF:\n",
    "        fwF.write(fw_exclusive2)\n",
    "    with open(uniq_std, 'w') as stdF:\n",
    "        stdF.write(standard_exclusive2)\n",
    "    with open(overlap, 'w') as bothF:\n",
    "        bothF.write(both_methods2)\n",
    "    return (uniq_fw, uniq_std, overlap)\n",
    "\n",
    "## Function 8\n",
    "def gw_table(in_data, out_data):\n",
    "    \"\"\"\n",
    "    Generate the table needed for the plotting script that creates the\n",
    "    Manhattan and QQ-plot. \n",
    "    \n",
    "    INPUT:\n",
    "    in_data - File name (with path) to the GWAS results.\n",
    "    out_data - File name (with path) of table to be generated\n",
    "    \n",
    "    OUTPUT:\n",
    "    The file \"out_data\" is created. This is a table used as input for\n",
    "    the plotting script to create the Manhattan and QQ-plot. \n",
    "    Nothing is returned from this function, however. \n",
    "    \"\"\"\n",
    "    import gzip, os\n",
    "    #with gzip.open(in_data, 'rt') as inF:\n",
    "    with open(out_data, 'wt') as outF, open(in_data) as inF:\n",
    "        next(inF) # skip header\n",
    "        line = inF.readline()\n",
    "        header = ('VARIANT_ID', 'CHR', 'POSITION', 'P', 'TYPE')\n",
    "        header = '\\t'.join(header)\n",
    "        outF.write(header + '\\n')\n",
    " \n",
    "        while(line):\n",
    "            split_line = line.split()\n",
    "            variant_id = split_line[2]\n",
    "            chrom = split_line[0]\n",
    "            pos = split_line[1]\n",
    "            pval = split_line[7]\n",
    "            A1 = split_line[3]\n",
    "            A2 = split_line[4]\n",
    "            acgt = ('A', 'C', 'G', 'T', 'a', 'c', 'g', 't')\n",
    " \n",
    "            if (A1 and A2) in acgt:\n",
    "                var_type = 'snp'\n",
    "            else:\n",
    "                var_type = 'indel'\n",
    " \n",
    "            line_values = (variant_id, chrom, pos, pval, var_type)\n",
    "            table_line = '\\t'.join(line_values) \n",
    "            outF.write(table_line + '\\n')\n",
    "            line = inF.readline()\n",
    "    return out_data\n",
    "\n",
    "\n",
    "## Function9\n",
    "def highlight_table(in_data):\n",
    "    \"\"\"\n",
    "    Generate the highlight table for the GWAS plotting script.\n",
    "    \n",
    "    INPUT:\n",
    "    in_data - File name (with path) to the significant (and unique) variants.\n",
    "    \n",
    "    OUTPUT:\n",
    "    The file \"out_data\" is created. This is a table used as input for\n",
    "    the plotting script to create the Manhattan and QQ-plot. \n",
    "    Nothing is returned from this function, however. \n",
    "    \"\"\"\n",
    "    out_data = in_data + '.table'\n",
    "    with open(in_data, 'rt') as inF:\n",
    "        with open(out_data, 'wt') as outF:\n",
    "            line = inF.readline()\n",
    "            header = ('VARIANT_ID', 'CHR', 'POSITION', 'P', 'TYPE')\n",
    "            header = '\\t'.join(header)\n",
    "            outF.write(header + '\\n')\n",
    " \n",
    "            while(line):\n",
    "                split_line = line.split('\\t')\n",
    "                uniq_id = split_line[1]\n",
    "                chrom = split_line[0]\n",
    "                pos = uniq_id.split(\":\")[1]\n",
    "                pval = split_line[3]\n",
    "\n",
    "                A1 = uniq_id.split(\":\")[2]\n",
    "                A2 = uniq_id.split(\":\")[3]\n",
    "                acgt = ('A', 'C', 'G', 'T', 'a', 'c', 'g', 't')\n",
    "                if (A1 and A2) in acgt:\n",
    "                    var_type = 'snp'\n",
    "                else:\n",
    "                    var_type = 'indel'\n",
    " \n",
    "                line_values = (uniq_id, chrom, pos, pval, var_type)\n",
    "                table_line = '\\t'.join(line_values) \n",
    "                outF.write(table_line + '\\n')\n",
    "                line = inF.readline()\n",
    "    return out_data\n",
    "\n",
    "\n",
    "# Function10\n",
    "def gwas_plots(gw_table, highlight_table, highlight_col, out_plots, thresh='5.0e-08',title = \"Manhattan\"):\n",
    "    \"\"\"Generate the Manhattan and QQ plots.\"\"\"\n",
    "    \n",
    "    import subprocess\n",
    "    command_list = ['/share/apps/R/bin/Rscript /home/jmarks/bin/generate_gwas_plots_v04.R',  \n",
    "                    '--in ', gw_table, \n",
    "                    '--in_chromosomes autosomal_nonPAR', \n",
    "                    '--in_header ',\n",
    "                    '--out ', out_plots, \n",
    "                    '--col_id VARIANT_ID ', \n",
    "                    '--col_chromosome CHR ',\n",
    "                    '--col_position POSITION ',\n",
    "                    '--col_p P ',\n",
    "                    '--col_variant_type TYPE ',\n",
    "                    '--highlight_list ', highlight_table,\n",
    "                    '--manhattan_highlight_color ', highlight_col,\n",
    "                    '--generate_snp_indel_manhattan_plot ',\n",
    "                    '--manhattan_odd_chr_color gray74 ',\n",
    "                    '--manhattan_even_chr_color gray87 ',\n",
    "                    '--manhattan_points_cex 1.5 ',\n",
    "                    '--generate_snp_indel_qq_plot ',\n",
    "                    '--qq_lines ',\n",
    "                    '--title {} '.format(title), \n",
    "                    '--qq_points_bg black ',\n",
    "                    '--qq_lambda ',\n",
    "                    '--sig_threshold', thresh ]\n",
    "    command_string = ' '.join(command_list)\n",
    "    subprocess.run(command_string, shell=True)\n",
    "    return \n",
    "\n",
    "\n",
    "## Function11\n",
    "def plot_tables(genome_table, highlight_table, color, description, title = \"Manhattan\"):\n",
    "    \"\"\"\n",
    "    title (string) title of the Manhattan plot\n",
    "    genome_table is the table for the whole genome\n",
    "    highlight_table is the table for the variants to be highlighted in the Manhattan plot\n",
    "    color (string) is the color of the variants to be highlighted\n",
    "    description (string) should be one of the following strings: novel, reproduced, or lossed\"\"\"\n",
    "    \n",
    "    out_plots = genome_table[:-6] + \"-plots-{}-variants\".format(description)\n",
    "    gwas_plots(genome_table, highlight_table, color, out_plots, title=title)\n",
    "    return\n",
    "\n",
    "\n",
    "## Function12\n",
    "def general_plot(gw_table, title = \"Manhattan\"):\n",
    "    \"\"\"Generate the Manhattan and QQ plots.\"\"\"\n",
    "\n",
    "    import subprocess\n",
    "    out_plots = gw_table[:-6] + \"-plots\"\n",
    "    command_list = ['/share/apps/R/bin/Rscript /home/jmarks/bin/generate_gwas_plots_v04.R',  \n",
    "                    '--in ', gw_table, \n",
    "                    '--in_chromosomes autosomal_nonPAR', \n",
    "                    '--in_header ',\n",
    "                    '--out ', out_plots, \n",
    "                    '--col_id VARIANT_ID ', \n",
    "                    '--col_chromosome CHR ',\n",
    "                    '--col_position POSITION ',\n",
    "                    '--col_p P ',\n",
    "                    '--col_variant_type TYPE ',\n",
    "                    '--generate_snp_indel_manhattan_plot ',\n",
    "                    '--manhattan_points_cex 1.5 ',\n",
    "                    '--generate_snp_indel_qq_plot ',\n",
    "                    '--qq_lines ',\n",
    "                    '--title {} '.format(title), \n",
    "                    '--qq_points_bg black ',\n",
    "                    '--qq_lambda ']\n",
    "    command_string = ' '.join(command_list)\n",
    "    subprocess.run(command_string, shell=True)\n",
    "    return \n",
    "\n",
    "\n",
    "################################################################################\n",
    "if __name__ == \"__main__\": main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individaul Functions\n",
    "Below are the individual function present in the main() function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function1&mdash;Convert results to vcf format\n",
    "<!--Note, this function expects the headers to be specifically named. Simply alter the names in the code to match your header names.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"/share/storage/FTND/data/wave2_FTND/20180627/ftnd-wave2-gwas-results.txt.gz\"\n",
    "base_dir = \"/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/ftnd2/004/\"\n",
    "out_file = base_dir + \"ftnd2-gw.vcf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function1\n",
    "def results_to_vcf_format(in_file, out_file):\n",
    "    \"\"\"\n",
    "    The SnpEff software expects, as input, a file in VCF format. \n",
    "    This function performs the conversion of the GWAS results \n",
    "    to VCF format so that SnpEff can obtain the annotations.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file - GWAS results file. \n",
    "    out_file - Name (and path) of the VCF file to be created.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    import gzip, sys\n",
    "    try:\n",
    "        with gzip.open(in_file, 'rt') as inF:\n",
    "            with open(out_file, 'wt') as outF:\n",
    "                head = inF.readline()\n",
    "    \n",
    "                head_line = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "                outF.write('\\t'.join(head_line) + '\\n')\n",
    "                split_line = head.split()\n",
    "     \n",
    "                try:\n",
    "                    pval_index = split_line.index('P-value')\n",
    "                    chr_index = split_line.index('chr')\n",
    "                    rsid_index = split_line.index('MarkerName')\n",
    "                    position_index = split_line.index('position')\n",
    "                    ref_allele_index = split_line.index('Allele1')\n",
    "                    alt_allele_index = split_line.index('Allele2')\n",
    "                except (ValueError):\n",
    "                    sys.exit(\"Make sure the headers are appropriately named:\")\n",
    "\n",
    "                # skip the header now\n",
    "                line = inF.readline()\n",
    "                while(line):\n",
    "                    split_line = line.split()\n",
    "     \n",
    "                    f1 = split_line[chr_index]\n",
    "                    f2 = split_line[position_index]\n",
    "                    f3 = split_line[rsid_index]\n",
    "                    f4 = split_line[ref_allele_index]\n",
    "                    f5 = split_line[alt_allele_index]\n",
    "                    f6 = '.'\n",
    "                    f7 = '.'\n",
    "                    f8 = split_line[pval_index]\n",
    "     \n",
    "                    vcf_list = [f1, f2, f3, f4, f5, f6, f7, f8]\n",
    "                    outF.write('\\t'.join(vcf_list) + '\\n')\n",
    "                    line = inF.readline()\n",
    "    except (OSError):\n",
    "        sys.exit(\"Couldn't recognize input file. Make sure your have specified the file name\\\n",
    "                correctly. Also make sure to gzip the input file.\")\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function2&mdash;Obtain variant annotations with SnpEff \n",
    "\n",
    "**Note**: Adjust the java memory specification as needed. Default allocation is 2GB; here I specified 8GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \"/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/ftnd2/004/test.vcf\"\n",
    "base_dir = \"/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/ftnd2/004/\"\n",
    "out_file = base_dir + 'test-ann.vcf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snp_eff(base_dir, in_file, out_file):\n",
    "    \"\"\"\n",
    "    This function executes the SnpEff software that annotates the\n",
    "    sequence variants using the Genome Build 37 as the reference.'\n",
    "    \n",
    "    INPUT:\n",
    "    base_dir - path were results should be saved.\n",
    "    in_file - name (and path) of VCF file for input to SnpEff\n",
    "    out_file - name of the output annotated VCF.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    \n",
    "    import subprocess\n",
    "\n",
    "    ### DO NOT modify these variables\n",
    "    ###########################################################################\n",
    "    config_path = '/share/storage/Johnson/software/SnpEff/snpEff/snpEff.config' \n",
    "    snpEff_path = '/share/storage/Johnson/software/SnpEff/snpEff/snpEff.jar'\n",
    "    snp_eff = base_dir + 'snp-eff.sh'\n",
    "    # -t for multithreading implies -noStats (speeds process way up)\n",
    "    command_list = ['java', '-Xmx8g', '-jar', snpEff_path, '-c', config_path, '-v',\n",
    "                    '-t', 'GRCh37.75', in_file, '>', out_file]\n",
    "    command_string = ' '.join(command_list)\n",
    "    ###########################################################################\n",
    "\n",
    "    # save command as a bash script\n",
    "    with open(snp_eff, 'w') as outF:\n",
    "        message = '#!/usr/bin/bash\\n'\n",
    "        message += command_string\n",
    "        outF.write(message)\n",
    "\n",
    "    # execute bash script\n",
    "    run_command = ['bash', snp_eff]\n",
    "    subprocess.run(run_command)\n",
    "    return out_file\n",
    "\n",
    "%time snp_eff(base_dir, in_file, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function3&mdash;extract annotation information\n",
    "<!--\n",
    "We might want to add the rsID field, in the future. This would change down stream behavior that we would need to address.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_file = out_file\n",
    "in_file = \"/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/ftnd3/001/20190111-FTND3-ann.vcf\"\n",
    "out_file = in_file[0:-4] + \"-extracted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-55e99a3ba0bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mextract_ann\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-55e99a3ba0bd>\u001b[0m in \u001b[0;36mextract_ann\u001b[0;34m(in_file, out_file)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m#rsID = unique_id.split(':')[0] # only rsID if in 1000g_p3 format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mchrom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0minfo_field\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0mall_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_field\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mpval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_annotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## Function3\n",
    "def extract_ann(in_file, out_file):\n",
    "    \"\"\"\n",
    "    Extract the annotation information from the SnpEff\n",
    "    results VCF file. The unique ID and GWAS P-value\n",
    "    for each variant is extracted as well.\n",
    "    \n",
    "    INPUT: \n",
    "    in_file - The name of the file that was output from SnpEff.\n",
    "              The file should be in vcf format and have in the \n",
    "              INFO field the pval+annotation for each variant.\n",
    "    out_file - Name of the file for which to save the results \n",
    "               of this function to. This file will have the \n",
    "               following three fields:\n",
    "          2. rsID\n",
    "          1. unique ID (CHR:POSTION:A1:A2)\n",
    "          2. sequence variant annotation (e.g. stop-gain,)\n",
    "          3. P-value\n",
    "    OUTPUT: \n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(in_file, 'r') as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    " \n",
    "            while line[0] == '#':\n",
    "                line = inF.readline()\n",
    "      \n",
    "            while(line):\n",
    "                split_line = line.split()\n",
    "                #unique_id = split_line[0] + ':' + split_line[1] + \\\n",
    "                #    ':' + split_line[3] + ':' + split_line[4]\n",
    "                unique_id = split_line[2]\n",
    "                #rsID = unique_id.split(':')[0] # only rsID if in 1000g_p3 format\n",
    "                chrom = split_line[0]               \n",
    "                info_field = split_line[7]\n",
    "                all_annotations = info_field.split(';')\n",
    "                pval = all_annotations[0]\n",
    "                functional_annotations = all_annotations[1].split(',')\n",
    "                for item in functional_annotations:\n",
    "                    output = chrom + '\\t' + unique_id + '\\t' + item.split('|')[1] + '\\t' + pval\n",
    "                    outF.write(output + '\\n')\n",
    "                line = inF.readline()  \n",
    "    return out_file\n",
    "extract_ann(in_file, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function4&mdash;Group Variants into Four Annotational Categories\n",
    "\n",
    "Sequence variant annotation of each function group as described by the 2016 Nature paper by Sveinbjornsson et al.\n",
    "1. loss-of-function (stop-gain & stop-loss, frameshift indel, donor and acceptor splice-site, and initiator codon variants)\n",
    "2. moderate-impact (missense, in-frame indel and splice region variants)\n",
    "3. low-impact (synonymous, 3' and 5' UTR, and upstream and downstream variants)\n",
    "4. other (all other variants)\n",
    "\n",
    "**Note**: there are some variant annotations whose classification is in discordance when considering the Nature paper vs the SnpEff report on (putative) variant impact. For example, initiator codon variants are considered to be in the loss of function group according to the Nature paper where as the SnpEff software annotations the impact as low. There could be issues with this when considering *other* variants. One of these *other* variants might actually be a loss of impact variant or even a moderate impact. The threshold for *other* variants is set more stringent so that we might filter one of these variants out when in actuality we should have lower the threshold. This is just a side-note; I have not tried to determine if there are any instances of this yet. We should take a closer look at it though.\n",
    "\n",
    "### SnpEff annotation (Sequence Ontology terms)\n",
    "\n",
    "<br>\n",
    "\n",
    "**loss-of-function**\n",
    "* stop_gained \n",
    "* stop_lost\n",
    "* frameshift_variant\n",
    "* splice_donor_variant\n",
    "* splice_acceptor_variant\n",
    "* initiator_codon_variant (note that SnpEff indicates that the impact of these variants are LOW)\n",
    "\n",
    "<br>\n",
    "\n",
    "**moderate-impact-variants**\n",
    "* missense_variant\n",
    "* inframe_insertion\n",
    "* splice_region_variant (impact LOW)\n",
    "\n",
    "<br>\n",
    "\n",
    "**low-impact variants**\n",
    "* synonymous_variant\n",
    "* 3_prime_UTR_variant\n",
    "* 5_prime_UTR_variant\n",
    "* upstream_gene_variant\n",
    "* downstream_gene_variant\n",
    "\n",
    "**other**\n",
    "* All other variant annotations detailed in SnpEff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = \n",
    "out_file += \"-grouped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/ftnd3/001/20190111-FTND3-ann-extracted-grouped'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Function4\n",
    "def group_annotations(in_file, out_file):\n",
    "    \"\"\"\n",
    "    Categorized the variants into groups based off\n",
    "    of their annotations.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file - the file name (and path) of the file\n",
    "              that contains the variant annotations.\n",
    "    out_file - the file name (and path) of the output file\n",
    "               that will essentially append the variant group\n",
    "               to the in_put file.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    with open(in_file, 'r') as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    "            group_dict = {}\n",
    "            # add loss-of-function variants\n",
    "            group_dict['loss-of-function variants'] = ['stop_gained', \n",
    "                                                      'stop_lost', \n",
    "                                                      'frameshift_variant', \n",
    "                                                      'splice_donor_variant', \n",
    "                                                      'splice_acceptor_variant', \n",
    "                                                      'initiator_codon_variant']\n",
    "            # add moderate-impact variants\n",
    "            group_dict['moderate-impact variants'] = ['missense_variant', \n",
    "                                                     'inframe_insertion', \n",
    "                                                     'splice_region_variant']\n",
    "            # add low-impact variants\n",
    "            group_dict['low-impact variants'] = ['synonymous_variant', \n",
    "                                                '3_prime_UTR_variant', \n",
    "                                                '5_prime_UTR_variant', \n",
    "                                                'upstream_gene_variant', \n",
    "                                                'downstream_gene_variant']\n",
    "            ## Group variants based on their categorization.\n",
    "            while(line):\n",
    "                split_line = line.split()\n",
    "                # Search for ann in dict.\n",
    "                for item in group_dict:\n",
    "                    if split_line[2] in group_dict[item]:\n",
    "                        split_line.append(item)\n",
    "                        break\n",
    "                # If the variant was not in any of the three groups;\n",
    "                # then it is categorized as an 'other' variant.\n",
    "                if len(split_line) == 4:\n",
    "                    split_line.append('other')\n",
    "                outF.write('\\t'.join(split_line) + '\\n')\n",
    "                line = inF.readline()\n",
    "    return out_file\n",
    "\n",
    "group_annotations(in_file, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function5&mdash;Filter variants based off of the fwThresholds\n",
    "1. Loss of function; $5.5 \\times 10^{-7}$ \n",
    "2. Moderate impact; $1.1 \\times 10^{-7}$ \n",
    "3. Low impact; $1.0 \\times 10^{-8}$ \n",
    "4. Other; $1.7 \\times 10^{-9}$ \n",
    "\n",
    "These thresholds are based off of the estimated enrichment of categories among association signals of 1000G and the resulting significance thresholds - detailed in `Weighting Sequence Variants` 2016 Nature paper by Sveinbjornsson et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = out_file\n",
    "out_fw = out_file + \"-filtered-fw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function5\n",
    "def filter_fw(in_file, out_file):\n",
    "    \"\"\"\n",
    "    This function filters the variants by comparing the sequence\n",
    "    variant P-values obtained from the GWAS results with the \n",
    "    functional-weighted threshold.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file - name (and path) of the input file that contains the \n",
    "              variant groupings.\n",
    "    out_file - name (and path) of the output file that will be the\n",
    "               fw-threshold filtered file.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    with open(in_file) as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    "            loss_func = 5.5e-7\n",
    "            mod_impact = 1.1e-7\n",
    "            low_impact = 1.0e-8\n",
    "            other = 1.7e-9\n",
    "            thresh_dict = {'loss-of-function variants': loss_func,\n",
    "                           'moderate-impact variants': mod_impact,\n",
    "                           'low-impact variants': low_impact,\n",
    "                           'other': other}\n",
    "            while(line):\n",
    "                split_line = line.split('\\t')\n",
    "                group = split_line[4].strip()\n",
    "                pval = float(split_line[3])\n",
    "                if pval <= thresh_dict[group]:\n",
    "                    outF.write(line)\n",
    "                line = inF.readline()\n",
    "    return out_file\n",
    "\n",
    "filter_fw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Function6&mdash;Filter variants based off of the standard P-value\n",
    "Filter the sequence variants by the standard genome-wide significance (WGS) P-Value threshold of $5\\times 10^{-8}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = out_file\n",
    "out_std = out_file + \"-filtered-std\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function6\n",
    "def filter_standard(in_file, out_file):\n",
    "    \"\"\"\n",
    "    This function filters the variants by comparing the sequence\n",
    "    variant pvalues obtained from the GWAS results with the \n",
    "    standard GWAS threshold of 5e-8.\n",
    "         \n",
    "    INPUT:\n",
    "    in_file - name (and path) of the input file that contains the \n",
    "              variant groupings.\n",
    "    out_file - name (and path) of the output file that will be the\n",
    "               standard-threshold filtered file.\n",
    "    \n",
    "    OUTPUT:\n",
    "    This function returns a character string of the name and path of out_file.\n",
    "    \"\"\"\n",
    "    with open(in_file) as inF:\n",
    "        with open(out_file, 'w') as outF:\n",
    "            line = inF.readline()\n",
    "            bf_threshold = 5e-8\n",
    "            #\n",
    "            while(line):\n",
    "                split_line = line.split('\\t')\n",
    "                group = split_line[4].strip()\n",
    "                pval = float(split_line[3])\n",
    "                if pval <= bf_threshold:\n",
    "                    outF.write(line)\n",
    "                line = inF.readline()\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function7&mdash;Report Results\n",
    "Results comparison: compare the sequence variants that were deemed significant when using the fw-thresholds vs the standard standard P-value threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fw_file = out_fw\n",
    "# std_file = out_std\n",
    "fw_file = \"/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/ftnd2/008/20190109-FTND2-ann-extracted-grouped-filtered-fw\"\n",
    "std_file = \"/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/ftnd2/008/20190109-FTND2-ann-extracted-grouped-filtered-std\"\n",
    "\n",
    "out_file = \"/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/ftnd2/008/results-summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/ftnd2/008/results-summary-uniq-fw-variants',\n",
       " '/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/ftnd2/008/results-summary-uniq-std-variants',\n",
       " '/home/jmarks/Documents/fwGWAS/method_comp/naive_meth/ftnd2/008/results-summary-replicated-variants')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def results_summary(in_file, in_file2, out_file):\n",
    "    \"\"\"\n",
    "    The function takes as input the two results files from the threshold filtering\n",
    "    performed above and outputs the summary statistics. Specifically, the output file \n",
    "    will contain two counts-dictionaries. One dict will count the number of variants \n",
    "    in each functional group that was exclusive to the fw-thresholded sequence\n",
    "    variants. The other will be for the variants exclusive to the standard WGS P-value\n",
    "    thresholded results.\n",
    "    \n",
    "    INPUT:\n",
    "    in_file -  name of the fw-thresholded file\n",
    "    in_file2 - name of the standard thresholded file\n",
    "    out_file - Name of the file to which the summary statistics will be saved.\n",
    "    \n",
    "    OUTPUT:\n",
    "    Nothing is returned from this function, however three files are output. One is\n",
    "    the out_file provided as input, and then two additional files are created.\n",
    "    \n",
    "    additional01 - File assumes the name <out_file>-fw-variants and includes a list of \n",
    "                   the variants that were deemed significant only when the fw-thresholds\n",
    "                   were applied as thresholds of significance.\n",
    "    additional02 - File assumes the name <out_file>-std-variants and includes a list of\n",
    "                   the variants that were deemed significant only when the standard\n",
    "                   threshold (5e-8) was applied.\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "     \n",
    "    uniq_fw = out_file+'-uniq-fw-variants'\n",
    "    uniq_std = out_file+'-uniq-std-variants'\n",
    "    overlap = out_file + '-replicated-variants'\n",
    "    ## compare the two filtered files and print the variants \n",
    "    #  Exclusive to the fw-thresholded variants\n",
    "    bash_command = 'bash -c \"comm -23 <(sort {0}) <(sort {1})\"'.format(in_file, in_file2)\n",
    "    fw_exclusive = subprocess.run(bash_command, shell=True, stdout=subprocess.PIPE, encoding='utf-8').stdout\n",
    "    # Exlusive to the standard thresholded variants (5e-8)\n",
    "    bash_command2 = 'bash -c \"comm -13 <(sort {0}) <(sort {1})\"'.format(in_file, in_file2)\n",
    "    standard_exclusive = subprocess.run(bash_command2, shell=True, stdout=subprocess.PIPE, encoding='utf-8').stdout\n",
    "    # Variants deemed siginificant using both thresholding methods\n",
    "    bash_command3 = 'bash -c \"comm -12 <(sort {0}) <(sort {1}) \"'.format(in_file, in_file2)\n",
    "    both_methods = subprocess.run(bash_command3, shell=True, stdout=subprocess.PIPE, encoding='utf-8').stdout\n",
    "    \n",
    "    # keep only unique SNPs\n",
    "    def remove_dups(old_string):\n",
    "        snp_dict = {}\n",
    "        new_string = \"\"\n",
    "        for line in old_string.splitlines():\n",
    "            my_snp = line.split()[1]\n",
    "            if my_snp not in snp_dict:\n",
    "                new_string += line + \"\\n\"\n",
    "            snp_dict[my_snp] = \"present\"\n",
    "        return new_string\n",
    "    fw_exclusive2 = remove_dups(fw_exclusive)\n",
    "    standard_exclusive2 = remove_dups(standard_exclusive)\n",
    "    both_methods2 = remove_dups(both_methods)\n",
    "    \n",
    "    with open(out_file, 'w') as outF:\n",
    "        for count,string in enumerate([fw_exclusive2, standard_exclusive2, both_methods2]):\n",
    "            counts_dict = {'loss-of-function variants':0,\n",
    "                           'moderate-impact variants':0,\n",
    "                           'low-impact variants':0,\n",
    "                           'other':0}\n",
    "            if count == 0:\n",
    "                message = '####\\n####Novel variants.\\n\\n'\n",
    "            elif count == 1:\n",
    "                message = '\\n\\n####\\n####Variants not replicated.\\n\\n'\n",
    "            else:\n",
    "                message = '\\n\\n####\\n####Variants that were replicated.\\n\\n'\n",
    " \n",
    "            split_lines = string.splitlines()\n",
    "            if split_lines: # if there are any SNPs \n",
    "                uniq_snps = {}\n",
    "                for line in split_lines:\n",
    "                    snp = line.split('\\t')[1]\n",
    "                    if snp not in uniq_snps:\n",
    "                        uniq_snps[snp] = None\n",
    "                        ann = line.split('\\t')[4]\n",
    "                        counts_dict[ann] += 1\n",
    "            dict_sum = str(sum(counts_dict.values()))\n",
    "            dict_sum = '\\nTotal number of variants: {}'.format(dict_sum)\n",
    "            outF.write(message)\n",
    "            outF.write(str(counts_dict) + dict_sum + '\\n')\n",
    "    with open(uniq_fw, 'w') as fwF:\n",
    "        fwF.write(fw_exclusive2)\n",
    "    with open(uniq_std, 'w') as stdF:\n",
    "        stdF.write(standard_exclusive2)\n",
    "    with open(overlap, 'w') as bothF:\n",
    "        bothF.write(both_methods2)\n",
    "    return (uniq_fw, uniq_std, overlap)\n",
    "\n",
    "results_summary(fw_file, std_file, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot fwGWAS Results\n",
    "Create the tables for plotting. This will be a table for all of the variants, genome-wide, as well as a table for each of the categories:\n",
    "* novel variants\n",
    "* reproduced variants\n",
    "* lossed variants\n",
    "\n",
    "We make a table for each of these three categories so that we can highlight the specific variants in the Manhattan plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = vcf_file\n",
    "out_data = in_data[0:-3] + \"table\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gw_table(in_data, out_data):\n",
    "    \"\"\"\n",
    "    Generate the table needed for the plotting script that creates the\n",
    "    Manhattan and QQ-plot. \n",
    "    \n",
    "    INPUT:\n",
    "    in_data - File name (with path) to the GWAS results.\n",
    "    out_data - File name (with path) of table to be generated\n",
    "    \n",
    "    OUTPUT:\n",
    "    The file \"out_data\" is created. This is a table used as input for\n",
    "    the plotting script to create the Manhattan and QQ-plot. \n",
    "    Nothing is returned from this function, however. \n",
    "    \"\"\"\n",
    "    import gzip, os\n",
    "    #with gzip.open(in_data, 'rt') as inF:\n",
    "    with open(out_data, 'wt') as outF, open(in_data) as inF:\n",
    "        next(inF) # skip header\n",
    "        line = inF.readline()\n",
    "        header = ('VARIANT_ID', 'CHR', 'POSITION', 'P', 'TYPE')\n",
    "        header = '\\t'.join(header)\n",
    "        outF.write(header + '\\n')\n",
    " \n",
    "        while(line):\n",
    "            split_line = line.split()\n",
    "            variant_id = split_line[2]\n",
    "            chrom = split_line[0]\n",
    "            pos = split_line[1]\n",
    "            pval = split_line[7]\n",
    "            A1 = split_line[3]\n",
    "            A2 = split_line[4]\n",
    "            acgt = ('A', 'C', 'G', 'T', 'a', 'c', 'g', 't')\n",
    " \n",
    "            if (A1 and A2) in acgt:\n",
    "                var_type = 'snp'\n",
    "            else:\n",
    "                var_type = 'indel'\n",
    " \n",
    "            line_values = (variant_id, chrom, pos, pval, var_type)\n",
    "            table_line = '\\t'.join(line_values) \n",
    "            outF.write(table_line + '\\n')\n",
    "            line = inF.readline()\n",
    "    return out_data\n",
    "\n",
    "%time genome_table = gw_table(in_data, out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_table(in_data):\n",
    "    \"\"\"\n",
    "    Generate the highlight table for the GWAS plotting script.\n",
    "    \n",
    "    INPUT:\n",
    "    in_data - File name (with path) to the significant (and unique) variants.\n",
    "    \n",
    "    OUTPUT:\n",
    "    The file \"out_data\" is created. This is a table used as input for\n",
    "    the plotting script to create the Manhattan and QQ-plot. \n",
    "    Nothing is returned from this function, however. \n",
    "    \"\"\"\n",
    "    out_data = in_data + '.table'\n",
    "    with open(in_data, 'rt') as inF:\n",
    "        with open(out_data, 'wt') as outF:\n",
    "            line = inF.readline()\n",
    "            header = ('VARIANT_ID', 'CHR', 'POSITION', 'P', 'TYPE')\n",
    "            header = '\\t'.join(header)\n",
    "            outF.write(header + '\\n')\n",
    " \n",
    "            while(line):\n",
    "                split_line = line.split('\\t')\n",
    "                uniq_id = split_line[1]\n",
    "                chrom = split_line[0]\n",
    "                pos = uniq_id.split(\":\")[1]\n",
    "                pval = split_line[3]\n",
    "\n",
    "                A1 = uniq_id.split(\":\")[2]\n",
    "                A2 = uniq_id.split(\":\")[3]\n",
    "                acgt = ('A', 'C', 'G', 'T', 'a', 'c', 'g', 't')\n",
    "                if (A1 and A2) in acgt:\n",
    "                    var_type = 'snp'\n",
    "                else:\n",
    "                    var_type = 'indel'\n",
    " \n",
    "                line_values = (uniq_id, chrom, pos, pval, var_type)\n",
    "                table_line = '\\t'.join(line_values) \n",
    "                outF.write(table_line + '\\n')\n",
    "                line = inF.readline()\n",
    "    return out_data\n",
    "\n",
    "\n",
    "fw_table = highlight_table(fw_file)\n",
    "std_table = highlight_table(std_file)\n",
    "repro_table = highlight_table(repro_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Typical Manhattan + QQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_plot(gw_table, title = \"Manhattan\"):\n",
    "    \"\"\"Generate the Manhattan and QQ plots.\"\"\"\n",
    "\n",
    "    import subprocess\n",
    "    out_plots = gw_table[:-6] + \"-plots\"\n",
    "    command_list = ['/share/apps/R/bin/Rscript /home/jmarks/bin/generate_gwas_plots_v04.R',  \n",
    "                    '--in ', gw_table, \n",
    "                    '--in_chromosomes autosomal_nonPAR', \n",
    "                    '--in_header ',\n",
    "                    '--out ', out_plots, \n",
    "                    '--col_id VARIANT_ID ', \n",
    "                    '--col_chromosome CHR ',\n",
    "                    '--col_position POSITION ',\n",
    "                    '--col_p P ',\n",
    "                    '--col_variant_type TYPE ',\n",
    "                    '--generate_snp_indel_manhattan_plot ',\n",
    "                    '--manhattan_points_cex 1.5 ',\n",
    "                    '--generate_snp_indel_qq_plot ',\n",
    "                    '--qq_lines ',\n",
    "                    '--title {} '.format(title), \n",
    "                    '--qq_points_bg black ',\n",
    "                    '--qq_lambda ']\n",
    "    command_string = ' '.join(command_list)\n",
    "    subprocess.run(command_string, shell=True)\n",
    "    return \n",
    "\n",
    "general_plot(genome_table, \"FTND2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot Manhattan (with highlighted variants)\n",
    "\n",
    "* 5e-08\n",
    "* Loss of function; $5.5 \\times 10^{-7}$\n",
    "* Moderate impact; $1.1 \\times 10^{-7}$\n",
    "* Low impact; $1.0 \\times 10^{-8}$\n",
    "* Other; $1.7 \\times 10^{-9}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gwas_plots(gw_table, highlight_table, highlight_col, out_plots, thresh='5.0e-08',title = \"Manhattan\"):\n",
    "    \"\"\"Generate the Manhattan and QQ plots.\"\"\"\n",
    "    \n",
    "    import subprocess\n",
    "    command_list = ['/share/apps/R/bin/Rscript /home/jmarks/bin/generate_gwas_plots_v04.R',  \n",
    "                    '--in ', gw_table, \n",
    "                    '--in_chromosomes autosomal_nonPAR', \n",
    "                    '--in_header ',\n",
    "                    '--out ', out_plots, \n",
    "                    '--col_id VARIANT_ID ', \n",
    "                    '--col_chromosome CHR ',\n",
    "                    '--col_position POSITION ',\n",
    "                    '--col_p P ',\n",
    "                    '--col_variant_type TYPE ',\n",
    "                    '--highlight_list ', highlight_table,\n",
    "                    '--manhattan_highlight_color ', highlight_col,\n",
    "                    '--generate_snp_indel_manhattan_plot ',\n",
    "                    '--manhattan_odd_chr_color gray74 ',\n",
    "                    '--manhattan_even_chr_color gray87 ',\n",
    "                    '--manhattan_points_cex 1.5 ',\n",
    "                    '--generate_snp_indel_qq_plot ',\n",
    "                    '--qq_lines ',\n",
    "                    '--title {} '.format(title), \n",
    "                    '--qq_points_bg black ',\n",
    "                    '--qq_lambda ',\n",
    "                    '--sig_threshold', thresh ]\n",
    "    command_string = ' '.join(command_list)\n",
    "    subprocess.run(command_string, shell=True)\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "def plot_tables(genome_table, highlight_table, color, description, title = \"Manhattan\"):\n",
    "    \"\"\"\n",
    "    title (string) title of the Manhattan plot\n",
    "    genome_table is the table for the whole genome\n",
    "    highlight_table is the table for the variants to be highlighted in the Manhattan plot\n",
    "    color (string) is the color of the variants to be highlighted\n",
    "    description (string) should be one of the following strings: novel, reproduced, or lossed\"\"\"\n",
    "    \n",
    "    out_plots = genome_table[:-6] + \"-plots-{}-variants\".format(description)\n",
    "    gwas_plots(genome_table, highlight_table, color, out_plots, title=title)\n",
    "    return\n",
    "\n",
    "plot_title = \"FTND2\"\n",
    "plot_tables(genome_table, repro_table, \"yellow\", \"reproduced\", plot_title)\n",
    "plot_tables(genome_table, std_table, \"red\", \"lossed\", plot_title)\n",
    "plot_tables(genome_table, fw_table, \"green\", \"novel\", plot_title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

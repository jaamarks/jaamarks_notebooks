{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FTND LD Score Regression Update\n",
    "**Author:** Jesse Marks  <br>\n",
    "**GitHub Issue:** [#103](https://github.com/RTIInternational/bioinformatics/issues/103#issuecomment-602203354)\n",
    "\n",
    "In this notebook we document the [LD Score Regression](https://github.com/bulik/ldsc) (LDSC) analysis performed for our paper [Expanding the Genetic Architecture of Nicotine Dependence and its Shared Genetics with Multiple Traits: Findings from the Nicotine Dependence GenOmics (iNDiGO) Consortium](https://www.biorxiv.org/content/10.1101/2020.01.15.898858v1.full). The reviewers of this paper commented about outdated results that we used for the LDSR. The data we used were on [LDHub](http://ldsc.broadinstitute.org/). We therefore had to download the most recent sets of results from the [Psychiatric Genomics Consortium](https://www.med.unc.edu/pgc/) and use these results to update our LDSR analysis plot. We are also going to add a vertical line at rg==1 in our plot to address a request from the reviewer.\n",
    "\n",
    "Note that Michael Bray of WUSTL updated the Lung Cancer results which we will put in here.\n",
    "\n",
    "\n",
    "## Data Locations\n",
    "Dana Hancock downloaded the updated results too:\n",
    "```\n",
    "\\rtpnfil02\\dhancock\\Nicotine\\Analysis\\META\\1df\\wave3GWASmeta\\LDSR\\ADHD_Demontis2019\n",
    "\\rtpnfil02\\dhancock\\Nicotine\\Analysis\\META\\1df\\wave3GWASmeta\\LDSR\\Anorexia_Watson2019\n",
    "\\rtpnfil02\\dhancock\\Nicotine\\Analysis\\META\\1df\\wave3GWASmeta\\LDSR\\Autism_Groves2019\n",
    "\\rtpnfil02\\dhancock\\Nicotine\\Analysis\\META\\1df\\wave3GWASmeta\\LDSR\\Bipolar_Stahl2019\n",
    "\\rtpnfil02\\dhancock\\Nicotine\\Analysis\\META\\1df\\wave3GWASmeta\\LDSR\\MDD_Howard2019\n",
    "\\rtpnfil02\\dhancock\\Nicotine\\Analysis\\META\\1df\\wave3GWASmeta\\LDSR\\PTSD_Nievergelt2019\n",
    "\\rtpnfil02\\dhancock\\Nicotine\\Analysis\\META\\1df\\wave3GWASmeta\\LDSR\\YrsSchool_Lee2018\\\n",
    "```\n",
    "\n",
    "<br><br>\n",
    "\n",
    "The wave3 FTND meta-analysis results can be found at:\n",
    "```\n",
    "s3://rti-nd/META/1df/results/wave3/final_results/ea/final/20190322_ftnd_meta_analysis_wave3.eur.chr[1..22].exclude_singletons.1df.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Guideline\n",
    "1. Create Excel phenotype file locally then upload to EC2 instance\n",
    "2. Clone https://github.com/RTIInternational/ld-regression-pipeline\n",
    "3. Then edit full_ld_regression_wf_template.json to include the reference data of choice\n",
    "4. Use dockerized tool to finish filling out the json file that will be input for workflow\n",
    "5. Run the WDL workflow for LDSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Input Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADHD\n",
    "cd /shared/jmarks/nicotine/ldsc/ftnd_all/20200326/processing/ADHD_Demontis2019\n",
    "\n",
    "## split up results file so we can order it sequencially by chromosome\n",
    "for chr in {1..22}; do\n",
    "    metaF=daner_meta_filtered_NA_iPSYCH23_PGC11_sigPCs_woSEX_2ell6sd_EUR_Neff_70.meta\n",
    "    outF=adhd_pgc_eur_chr${chr}.txt\n",
    "\n",
    "    awk -v chrom=$chr 'NR==1 {print $0; next} NR>1 {\n",
    "        if ($1==chrom)\n",
    "            {print $0}} ' $metaF > $outF &\n",
    "done        \n",
    "\n",
    "outf=adhd_demontis2019_ldsc_ready.txt\n",
    "echo -e \"SNP\\tCHR\\tPOS\\tA1\\tA2\\tOR\\tP\\tN\" > $outf\n",
    "for chr in {1..22};do\n",
    "    inf=adhd_pgc_eur_chr$chr.txt\n",
    "    # MarkerName, CHR, POS, Allele1, Allele2, Effect, P-value\n",
    "    tail -n +2 $inf  | \\\n",
    "    awk 'BEGIN{OFS=\"\\t\"} {print $2,$1,$3,$4,$5,$9,$11,$17+$18}' \\\n",
    "        >> $outf\n",
    "done &\n",
    "\n",
    "gzip $outf\n",
    "## upload to S3\n",
    "aws s3 cp $outf.gz s3://rti-nd/ldsc_genetic_correlation/data/ADHD_Demontis2019/$outf.gz\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "## Anorexia\n",
    "\n",
    "# remove extra headers\n",
    "zcat pgcAN2.2019-07.vcf.tsv.gz  |  perl -lane ' \n",
    "    if ((!/##/) ) \n",
    "        { print $_}' > anorexia.txt\n",
    "\n",
    "# split up results file so we can order it sequencially by chromosome\n",
    "for chr in {1..22}; do\n",
    "    metaF=anorexia.txt\n",
    "    outF=anorexia_pgc_eur_chr${chr}.txt\n",
    "\n",
    "    awk -v chrom=$chr 'NR==1 {print $0; next} NR>1 {\n",
    "        if ($1==chrom)\n",
    "            {print $0}} ' $metaF > $outF &\n",
    "done        \n",
    "\n",
    "\n",
    "outf=anorexia_watson2019_ldsc_ready.txt\n",
    "echo -e \"SNP\\tCHR\\tPOS\\tA1\\tA2\\tBETA\\tP\\tN\" > $outf\n",
    "for chr in {1..22};do\n",
    "    inf=anorexia_pgc_eur_chr$chr.txt\n",
    "    # MarkerName, CHR, POS, Allele1, Allele2, Effect, P-value\n",
    "    tail -n +2 $inf  | \\\n",
    "    awk 'BEGIN{OFS=\"\\t\"}  {print $3,$1,$2,$5,$4,$6,$8,$12+$13}'  >> $outf\n",
    "done &\n",
    "\n",
    "gzip $outf\n",
    "\n",
    "## clean up directory\n",
    "rm anorexia*t\n",
    "\n",
    "## upload to S3\n",
    "aws s3 sync . s3://rti-nd/ldsc_genetic_correlation/data/Anorexia_Watson2019/\n",
    "\n",
    "####################################################################################################\n",
    "## Autism\n",
    "\n",
    "\n",
    "## split up results file so we can order it sequencially by chromosome\n",
    "for chr in {1..22}; do\n",
    "    metaF=iPSYCH-PGC_ASD_Nov2017.gz\n",
    "    outF=autism_pgc_eur_chr${chr}.txt\n",
    "\n",
    "    awk -v chrom=$chr 'NR==1 {print $0; next} NR>1 {\n",
    "        if ($1==chrom)\n",
    "            {print $0}} ' <(zcat $metaF) > $outF &\n",
    "done        \n",
    "\n",
    "outf=autism_groves2019_n46351_ldsc_ready.txt\n",
    "echo -e \"SNP\\tCHR\\tPOS\\tA1\\tA2\\tOR\\tP\" > $outf\n",
    "for chr in {1..22};do\n",
    "    inf=autism_pgc_eur_chr$chr.txt\n",
    "    # MarkerName, CHR, POS, Allele1, Allele2, Effect, P-value\n",
    "    tail -n +2 $inf  | \\\n",
    "    awk 'BEGIN{OFS=\"\\t\"} {print $2,$1,$3,$4,$5,$7,$9}' \\\n",
    "        >> $outf\n",
    "done &\n",
    "\n",
    "gzip $outf\n",
    "\n",
    "## clean up directory\n",
    "rm autism_pgc*t\n",
    "\n",
    "## upload to S3\n",
    "aws s3 sync. s3://rti-nd/ldsc_genetic_correlation/data/autism_groves2019/\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "## Bipolar\n",
    "\n",
    "\n",
    "## split up results file so we can order it sequencially by chromosome\n",
    "for chr in {1..22}; do\n",
    "    metaF=daner_PGC_BIP32b_mds7a_0416a.gz\n",
    "    outF=bipolar_pgc_eur_chr${chr}.txt\n",
    "\n",
    "    awk -v chrom=$chr 'NR==1 {print $0; next} NR>1 {\n",
    "        if ($1==chrom)\n",
    "            {print $0}} ' <(zcat $metaF) > $outF &\n",
    "done        \n",
    "\n",
    "outf=bipolar_stahl2019_ldsc_ready.txt\n",
    "echo -e \"SNP\\tCHR\\tPOS\\tA1\\tA2\\tOR\\tP\\tN\" > $outf\n",
    "for chr in {1..22};do\n",
    "    inf=bipolar_pgc_eur_chr$chr.txt\n",
    "    # MarkerName, CHR, POS, Allele1, Allele2, Effect, P-value, N\n",
    "    tail -n +2 $inf  | \\\n",
    "    awk 'BEGIN{OFS=\"\\t\"} {print $2,$1,$3,$4,$5,$9,$11,$18+$17}' \\\n",
    "        >> $outf\n",
    "done &\n",
    "\n",
    "gzip $outf\n",
    "\n",
    "## clean up directory\n",
    "rm bipolar_pgc*t\n",
    "\n",
    "## upload to S3\n",
    "aws s3 sync . s3://rti-nd/ldsc_genetic_correlation/data/bipolar_stahl2019/\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "## MDD\n",
    "\n",
    "\n",
    "## split up results file so we can order it sequencially by chromosome\n",
    "\n",
    "\n",
    "outf=mdd_howard2019_n807553_ldsc_ready.txt\n",
    "echo -e \"SNP\\tCHR\\tPOS\\tA1\\tA2\\tLOG_ODD\\tP\" > $outf\n",
    "for chr in {1..22};do\n",
    "    inf=mdd_pgc_eur_chr$chr.txt\n",
    "    # MarkerName, CHR, POS, Allele1, Allele2, Effect, P-value\n",
    "    tail -n +2 $inf  | \\\n",
    "    awk 'BEGIN{OFS=\"\\t\"} {print $3,$1,$2,$4,$5,$7,$9}' \\\n",
    "        >> $outf\n",
    "done &\n",
    "\n",
    "gzip $outf\n",
    "\n",
    "## clean up directory\n",
    "rm mdd_pgc*t\n",
    "\n",
    "## upload to S3\n",
    "aws s3 sync . s3://rti-nd/ldsc_genetic_correlation/data/mdd_howard2019/\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "## PTSD\n",
    "\n",
    "\n",
    "## split up results file so we can order it sequencially by chromosome\n",
    "for chr in {1..22}; do\n",
    "    metaF=pts_eur_freeze2_overall.results.gz\n",
    "    outF=ptsd_pgc_eur_chr${chr}.txt\n",
    "\n",
    "    awk -v chrom=$chr 'NR==1 {print $0; next} NR>1 {\n",
    "        if ($1==chrom)\n",
    "            {print $0}} ' <(zcat $metaF) > $outF &\n",
    "done        \n",
    "\n",
    "outf=ptsd_nieverge2019_ldsc_ready.txt\n",
    "echo -e \"SNP\\tCHR\\tPOS\\tA1\\tA2\\tOR\\tP\\tN\" > $outf\n",
    "for chr in {1..22};do\n",
    "    inf=ptsd_pgc_eur_chr$chr.txt\n",
    "    # MarkerName, CHR, POS, Allele1, Allele2, Effect, P-value, N\n",
    "    tail -n +2 $inf  | \\\n",
    "    awk 'BEGIN{OFS=\"\\t\"} {print $2,$1,$3,$4,$5,$9,$11,$17+$18}'  >> $outf\n",
    "done &\n",
    "\n",
    "gzip $outf\n",
    "\n",
    "## clean up directory\n",
    "rm ptsd_pgc*t\n",
    "\n",
    "## upload to S3\n",
    "aws s3 sync . s3://rti-nd/ldsc_genetic_correlation/data/ptsd_nieverge2019/\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "## YrsSchool_Lee2018\n",
    "\n",
    "\n",
    "## split up results file so we can order it sequencially by chromosome\n",
    "for chr in {1..22}; do\n",
    "    metaF=GWAS_EA_excl23andMe.txt\n",
    "    outF=yrschool_pgc_eur_chr${chr}.txt\n",
    "\n",
    "    awk -v chrom=$chr 'NR==1 {print $0; next} NR>1 {\n",
    "        if ($2==chrom)\n",
    "            {print $0}} ' <(cat $metaF) > $outF &\n",
    "done        \n",
    "\n",
    "outf=yrschool_lee2019_n766345_ldsc_ready.txt\n",
    "echo -e \"SNP\\tCHR\\tPOS\\tA1\\tA2\\tBETA\\tP\" > $outf\n",
    "for chr in {1..22};do\n",
    "    inf=yrschool_pgc_eur_chr$chr.txt\n",
    "    # MarkerName, CHR, POS, Allele1, Allele2, Effect, P-value\n",
    "    tail -n +2 $inf  | \\\n",
    "    awk 'BEGIN{OFS=\"\\t\"} {print $1,$2,$3,$4,$5,$7,$9}'  >> $outf\n",
    "done &\n",
    "\n",
    "gzip $outf\n",
    "\n",
    "## clean up directory\n",
    "rm yrs_pgc*t\n",
    "\n",
    "## upload to S3\n",
    "aws s3 sync . s3://rti-nd/ldsc_genetic_correlation/data/yrschool_lee2018/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis Workflow\n",
    "`1b17491d-9e97-439c-b973-c162d196943a`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procD=/shared/jmarks/nicotine/ldsc/ftnd_all/20200326/\n",
    "\n",
    "# enter compute node and use screen tool\n",
    "\n",
    "# clone github repo\n",
    "cd $procD\n",
    "git clone https://github.com/RTIInternational/ld-regression-pipeline\n",
    "    \n",
    "# edit file-input json\n",
    "cd ld-regression-pipeline\n",
    "mkdir workflow_inputs\n",
    "cp json_input/full_ld_regression_wf_template.json workflow_inputs\n",
    "cd workflow_inputs\n",
    "\n",
    "## vim edit file (see README.md at https://github.com/RTIInternational/ld-regression-pipeline)\n",
    "\n",
    "\n",
    "# create final workflow input (a json file)\n",
    "docker run -v $procD/ld-regression-pipeline/workflow_inputs:/data/ \\\n",
    "    rticode/generate_ld_regression_input_json:1ddbd682cb1e44dab6d11ee571add34bd1d06e21 \\\n",
    "    --json-input /data/full_ld_regression_wf_template.json \\\n",
    "    --pheno-file /data/ftnd_ldsc_phenotypes_local.xlsx >\\\n",
    "        $procD/ld-regression-pipeline/workflow_inputs/final_wf_inputs.json\n",
    "\n",
    "## zip appropriate files \n",
    "# Change to directory immediately above ld-regression-pipeline\n",
    "cd $procD/ld-regression-pipeline\n",
    "cd ..\n",
    "# Make zipped copy of repo somewhere\n",
    "zip --exclude=*var/* --exclude=*.git/* -r \\\n",
    "    $procD/ld-regression-pipeline/workflow_inputs/ld-regression-pipeline.zip \\\n",
    "    ld-regression-pipeline\n",
    "\n",
    "## download cromwell and the config file, if necessary\n",
    "cd /shared/jmarks/bin/cromwell\n",
    "#aws s3 cp s3://rti-cromwell-output/cromwell-config/cromwell_default_genomics_queue.conf .\n",
    "#wget https://github.com/broadinstitute/cromwell/releases/download/44/cromwell-44.jar\n",
    "\n",
    "## run ldsc workflow on AWS EC2 instance\n",
    "java -Dconfig.file=/shared/jmarks/bin/cromwell/cromwell_default_genomics_queue.conf \\\n",
    "    -jar cromwell-49.jar \\\n",
    "    run $procD/ld-regression-pipeline/workflow/full_ld_regression_wf.wdl \\\n",
    "    -i $procD/ld-regression-pipeline/workflow_inputs/final_wf_inputs.json \\\n",
    "    -p $procD/ld-regression-pipeline/workflow_inputs/ld-regression-pipeline.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sandbox\n",
    "\n",
    "java -Dconfig.file=/shared/jmarks/bin/cromwell/cromwell_default_genomics_queue.conf \\\n",
    "    -jar cromwell-49.jar \\\n",
    "    run $procD/ld-regression-pipeline/workflow/full_ld_regression_wf.wdl \\\n",
    "    -i $procD/ld-regression-pipeline/workflow_inputs/final_wf_inputs.json \\\n",
    "    -p $procD/ld-regression-pipeline/workflow_inputs/ld-regression-pipeline.zip\n",
    "\n",
    "\n",
    "curl -X POST \"http://localhost:8000/api/workflows/v1\" -H \"accept: application/json\" \\\n",
    "    -F \"workflowSource=@$procD/ld-regression-pipeline/workflow/full_ld_regression_wf.wdl\" \\\n",
    "    -F \"workflowInputs=@$procD/ld-regression-pipeline/workflow_inputs/final_wf_inputs.json\" \\\n",
    "    -F \"workflowDependencies=@$procD/ld-regression-pipeline/workflow_inputs/ld-regression-pipeline.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Plot\n",
    "We combine these updated results with the previous set of genetic correlation results.\n",
    "\n",
    "Upload the plot table to EC2 instance to run docker and create the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## enter interactive mode ##\n",
    "# note that the image tag corresponds to the latest tag for this image\n",
    "\n",
    "docker run -it -v\"/shared/jmarks/projects/nicotine/ldsc/ftnd-all/006/:/data/\" \\\n",
    "    rticode/plot_ld_regression_results:172bbfcc46b857dc95b4d0a080ccd092fd3a4bac  /bin/bash\n",
    "\n",
    "\n",
    "Rscript /opt/plot_ld_regression/plot_ld_regression_results.R  \\\n",
    "    --input_file 20200513_ftnd_ld_regression_results.csv \\\n",
    "    --output_file 20200513_ftnd_ld_regression_results.pdf  \\\n",
    "    --group_order_file ftnd_rg_plot_order.csv \\\n",
    "    --comma_delimited \\\n",
    "    --vertical_rg 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

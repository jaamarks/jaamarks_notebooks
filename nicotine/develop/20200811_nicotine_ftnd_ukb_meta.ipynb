{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave 3 FTND (Nicotine Dependence) meta-analysis: 1000G phase 3\n",
    "**Author:** Jesse Marks <br>\n",
    "**Results**: The results of this meta-analysis are on AWS S3 at: `s3://rti-nd/gwas_meta/categorical_ftnd/results/1df/`<br>\n",
    "**GitHub Issue:** [#55](https://github.com/RTIInternational/bioinformatics/issues/55)<br>\n",
    "**Paper**: [B. Quach et.al.](https://www.biorxiv.org/content/10.1101/2020.01.15.898858v1)\n",
    "\n",
    "Here we perform two meta-analysis (1) cross-ancestry and (2) EUR-specific. We are combining UK Biobank (UKB) with our FTND results.\n",
    "1. Cross-ancestry: UKB 33,791 current smokers and wave3 FTND N=58,000 subjects for a total of **N=91,791**.\n",
    "2. EUR-specific: UKB N=31,854 current smokers and wave3 FTND N=46,213 subjects for a total of **N=78,067**.\n",
    "\n",
    "\n",
    "**All FTND wave3 cohorts**\n",
    "```\n",
    "AAND_AFR\n",
    "ADAA_AFR\n",
    "COGEND2_AFR\n",
    "COGEND2_EUR\n",
    "COGEND_AFR\n",
    "COGEND_EUR\n",
    "COHRA1_EUR\n",
    "COPDGENE1_AFR\n",
    "COPDGENE1_EUR\n",
    "COPDGENE2_AFR\n",
    "COPDGENE2_EUR\n",
    "DECODE_EUR\n",
    "EAGLE_EUR\n",
    "EMERGE_EUR\n",
    "FINRISK_EUR\n",
    "FTC_EUR\n",
    "GAIN_AFR\n",
    "GAIN_EUR\n",
    "GERMAN_EUR\n",
    "JHS_ARIC_AFR\n",
    "MCTFR_EUR\n",
    "NELSON_EUR\n",
    "NONGAIN_EUR\n",
    "NTR_EUR\n",
    "S4S_EUR\n",
    "SAGE_AFR\n",
    "SAGE_EUR\n",
    "UW_TTURC_AFR\n",
    "UW_TTURC_EUR\n",
    "YALE_PENN_AFR\n",
    "YALE_PENN_EUR\n",
    "```\n",
    "\n",
    "**Data Locations**:<br>\n",
    "FTND—`s3://rti-nd/gwas/`<br>\n",
    "UKB cross-ancestry—`s3://rti-nd/gwas/uk_biobank/HSI`<br>\n",
    "UKB EUR-specific—`s3://rti-nd/gwas/uk_biobank/GWA_003`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dir structure\n",
    "study_dir=/shared/jmarks/projects/nicotine/meta/data\n",
    "\n",
    "mkdir -p ${study_dir}/aand/afr\n",
    "mkdir -p ${study_dir}/adaa/afr\n",
    "mkdir -p ${study_dir}/cogend2/afr\n",
    "mkdir -p ${study_dir}/cogend2/eur\n",
    "mkdir -p ${study_dir}/cogend/afr\n",
    "mkdir -p ${study_dir}/cogend/eur\n",
    "mkdir -p ${study_dir}/cohra1/eur\n",
    "mkdir -p ${study_dir}/copdgene1/afr\n",
    "mkdir -p ${study_dir}/copdgene1/eur\n",
    "mkdir -p ${study_dir}/copdgene2/afr\n",
    "mkdir -p ${study_dir}/copdgene2/eur\n",
    "mkdir -p ${study_dir}/decode/eur\n",
    "mkdir -p ${study_dir}/eagle/eur\n",
    "mkdir -p ${study_dir}/emerge/eur\n",
    "mkdir -p ${study_dir}/finrisk/eur\n",
    "mkdir -p ${study_dir}/ftc/eur\n",
    "mkdir -p ${study_dir}/gain/afr\n",
    "mkdir -p ${study_dir}/gain/eur\n",
    "mkdir -p ${study_dir}/german/eur\n",
    "mkdir -p ${study_dir}/jhs_aric/afr\n",
    "mkdir -p ${study_dir}/mctfr/eur\n",
    "mkdir -p ${study_dir}/nelson/eur\n",
    "mkdir -p ${study_dir}/nongain/eur\n",
    "mkdir -p ${study_dir}/ntr/eur\n",
    "mkdir -p ${study_dir}/s4s/eur\n",
    "mkdir -p ${study_dir}/sage/afr\n",
    "mkdir -p ${study_dir}/sage/eur\n",
    "mkdir -p ${study_dir}/uw_tturc/afr\n",
    "mkdir -p ${study_dir}/uw_tturc/eur\n",
    "mkdir -p ${study_dir}/yale_penn/afr\n",
    "mkdir -p ${study_dir}/yale_penn/eur\n",
    "\n",
    "mkdir -p ${study_dir}/ukb/{eur,cross}\n",
    "\n",
    "\n",
    "# Download data\n",
    "for cohort in {aand,adaa,cogend,cogend2,cohra1,copdgene1,copdgene2,decode,eagle,emerge,finrisk,ftc,gain,german,jhs_aric,mctfr,nelson,nongain,ntr,s4s,sage,uw_tturc,yale_penn}; do\n",
    "    for ancestry in {afr,eur}; do\n",
    "        aws s3 sync s3://rti-nd/gwas/$cohort/results/categorical_ftnd/0001/$ancestry/final_stats/ \\\n",
    "        ${study_dir}/$cohort/$ancestry/\n",
    "    done\n",
    "done\n",
    "\n",
    "aws s3 sync s3://rti-nd/gwas/uk_biobank/HSI/ ${study_dir}/ukb/cross/\n",
    "aws s3 sync s3://rti-nd/gwas/uk_biobank/GWA_003/ ${study_dir}/ukb/eur/\n",
    "\n",
    "## unzip (make sure you have enough storage!)\n",
    "gunzip -r * &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert UKB to 1000G_phase3 IDs\n",
    "cd /shared/jmarks/projects/nicotine/meta/data/ukb/cross\n",
    "\n",
    "for chr in {1..22}; do\n",
    "    inF=ukb.hsi.sex.age.age2.agesex.age2sex.20evs.chr$chr.maf_gt_0.01_ukb\n",
    "    outF=ukb.hsi.sex.age.age2.agesex.age2sex.20evs.chr$chr.maf_gt_0.01_ukb.1000g_p3\n",
    "\n",
    "    /shared/bioinformatics/software/perl/id_conversion/convert_to_1000g_p3_ids.pl \\\n",
    "        --file_in $inF \\\n",
    "        --file_out $outF \\\n",
    "        --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr${chr}.legend.gz \\\n",
    "        --file_in_header 1 \\\n",
    "        --file_in_id_col 1 \\\n",
    "        --file_in_chr_col 0 \\\n",
    "        --file_in_pos_col 2 \\\n",
    "        --file_in_a1_col 3 \\\n",
    "        --file_in_a2_col 4 \\\n",
    "        --chr $chr\n",
    "done\n",
    "\n",
    "\n",
    "\n",
    "# EUR\n",
    "cd /shared/jmarks/projects/nicotine/meta/data/ukb/eur/\n",
    "\n",
    "# add chr column and header (they are missing)\n",
    "head -1 ../cross/ukb.hsi.sex.age.age2.agesex.age2sex.20evs.chr22.maf_gt_0.01_ukb > head.txt\n",
    "for chr in {1..22}; do \n",
    "    inF=ukb.hsi.sex.age.4evs.white.chr$chr.1df.1df\n",
    "    awk -v chr=$chr '\n",
    "        {print chr, $0}' $inF > ${inF}.add_chr\n",
    "\n",
    "    cat head.txt ${inF}.add_chr > tmp && mv tmp ${inF}.add_chr\n",
    "\n",
    "done\n",
    "\n",
    "\n",
    "for chr in {1..22}; do\n",
    "    inF=ukb.hsi.sex.age.4evs.white.chr$chr.1df.1df.add_chr\n",
    "    outF=ukb.hsi.sex.age.4evs.white.chr$chr.1df.1df.1000g_p3\n",
    "\n",
    "    /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name chr$chr.convert \\\n",
    "    --script_prefix convert.chr$chr.1000g_p3 \\\n",
    "    --mem 5 \\\n",
    "    --nslots 2 \\\n",
    "    --priority 0 \\\n",
    "    --program  /shared/bioinformatics/software/perl/id_conversion/convert_to_1000g_p3_ids.pl \\\n",
    "        --file_in $inF \\\n",
    "        --file_out $outF \\\n",
    "        --legend /shared/data/ref_panels/1000G/2014.10/1000GP_Phase3_chr${chr}.legend.gz \\\n",
    "        --file_in_header 1 \\\n",
    "        --file_in_id_col 1 \\\n",
    "        --file_in_chr_col 0 \\\n",
    "        --file_in_pos_col 2 \\\n",
    "        --file_in_a1_col 3 \\\n",
    "        --file_in_a2_col 4 \\\n",
    "        --chr $chr\n",
    "done\n",
    "\n",
    "# remove intermediary files\n",
    "for chr in {1..22}; do; rm ukb.hsi.sex.age.4evs.white.chr$chr.1df.1df.add_chr; done\n",
    "\n",
    "# apply maf and r2 filters\n",
    "for chr in {1..22}; do \n",
    "    zcat ukb.hsi.sex.age.4evs.white.chr$chr.1df.1df.1000g_p3.gz  |\\\n",
    "    awk '$7 > 0.01 && $9 > 0.3 {print $0}' > \\\n",
    "    ukb.hsi.sex.age.4evs.white.chr$chr.1df.1df.1000g_p3.maf_gt_0.01.rsq_gt_0.3.txt\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EUR-specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"IRdisplay\")\n",
    "#display_png(file=\"C:/Users/jmarks/OneDrive - Research Triangle Institute/Projects/nicotine/ftnd/meta/0004/nicotine_ftnd_wave3_gwas_meta_analysis_eur.snps+indels.manhattan.png\", width=800, height=800)\n",
    "#display_png(file=\"C:/Users/jmarks/OneDrive - Research Triangle Institute/Projects/nicotine/ftnd/meta/0004/nicotine_ftnd_wave3_gwas_meta_analysis_eur.snps+indels.qq.png\", width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "Below are the methods to perform the meta-analysis in the AWS environment. The main parts that need modified are the paths to the cohorts' data which has been modified. For example, the R section at the end on lines 315 and 316.\n",
    "\n",
    "Also note that we are converting everything to the 1000 Genome Phase 3 format and therefore we will include the script for performing this below.\n",
    "\n",
    "## methods\n",
    "Perform meta-analysis with METAL and produce the Manhattan and QQ plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### Author: Jesse Marks\n",
    "### Date: April 30, 2020\n",
    "### Description: Rerunning the FTND EUR-specific GWAS meta-analysis with the \n",
    "###              cohorts removed: Minnesota (MCTFR).\n",
    "###\n",
    "###\n",
    "\n",
    "version=\"001\"\n",
    "df=\"1df\"\n",
    "filePrefix=\"nicotine_ftnd_wave3_gwas_meta_analysis_eur\"\n",
    "outDir=\"/shared/jmarks/projects/nicotine/meta/results/eur/$version\"\n",
    "dataDir=\"/shared/jmarks/projects/nicotine/meta/data\"\n",
    "gcList=\"\" # function name of the study(s) for which to apply GC to. if none leave \"\"\n",
    "minchr=1  # first chr in sequence\n",
    "maxchr=22  # last chr in sequence\n",
    "\n",
    "mkdir -p $outDir/{processing,final}\n",
    "\n",
    "\n",
    "### functions to create cohort paths. arg1=\"base/directory/path\" arg2=\"chromosome#\"\n",
    "#aand_afr() { echo $1/aand/afr/aand_cogend2.aa.1000G_p3.chr$2.CAT_FTND~SNP+SEX+AGE+EVs.maf_gt_0.01_afr+aand_cogend2+RSQ.phase3ID; }\n",
    "#adaa_afr() { echo $1/adaa/afr/adaa.aa.1000G.chr$2.CAT_FTND~SNP+covar+EVs.maf_gt_0.01_afr+adaa+RSQ.phase3ID.flipped.quality_added; }\n",
    "#cogend_afr() { echo $1/cogend/afr/cogend.aa.1000G_p3.chr$2.CAT_FTND~SNP+AGE_INT+SEX+EVs.maf_gt_0.01_afr+cogend+RSQ.phase3ID; }\n",
    "cogend_eur() { echo $1/cogend/eur/cogend.ea.1000G_p3.chr$2.CAT_FTND~SNP+AGE_INT+SEX+EVs.maf_gt_0.01_eur+cogend+RSQ.phase3ID; }\n",
    "#cogend2_afr() { echo $1/cogend2/afr/cogend2.aa.1000G_p3.chr$2.CAT_FTND~SNP+SEX+AGE+EVs.maf_gt_0.01_afr+cogend2+RSQ.phase3ID; }\n",
    "cogend2_eur() { echo $1/cogend2/eur/cogend2.ea.1000G_p3.chr$2.CAT_FTND~SNP+SEX+AGE+EVs.maf_gt_0.01_eur+cogend2+RSQ.phase3ID; }\n",
    "#copdgene1_afr() { echo $1/copdgene1/afr/copdgene1.aa.1000G_p3.chr$2.CAT_FTND~SNP+AGE+SEX+GOLD+EVs.maf_gt_0.01_afr+copdgene1+RSQ.phase3ID; }\n",
    "copdgene1_eur() { echo $1/copdgene1/eur/copdgene1.ea.1000G_p3.chr$2.CAT_FTND~SNP+AGE+SEX+GOLD+EVs.maf_gt_0.01_eur+copdgene1+RSQ.phase3ID; }\n",
    "#copdgene2_afr() { echo $1/copdgene2/afr/copdgene2.aa.1000G_p3.chr$2.CAT_FTND~SNP+AGE+SEX+GOLD+EVs.maf_gt_0.01_afr+copdgene2+RSQ.phase3ID; }\n",
    "copdgene2_eur() { echo $1/copdgene2/eur/copdgene2.ea.1000G_p3.chr$2.CAT_FTND~SNP+AGE+SEX+GOLD+EVs.maf_gt_0.01_eur+copdgene2+RSQ.phase3ID; }\n",
    "decode_eur() { echo $1/decode/eur/decode.ea.1000G.chr$2.1df.maf_gt_0.01_eur_decode.quality_added; }\n",
    "dental_caries_eur() { echo $1/dental_caries/eur/dental_caries.ea.1000G_p3.chr$2.CAT_FTND~SNP+SEX+AGE_INT+EVs.maf_gt_0.01_eur+dental_caries+RSQ.phase3ID; }\n",
    "eagle_eur() { echo $1/eagle/eur/eagle.ea.1000G_p3.chr$2.CAT_FTND~SNP+AGE_INT+SEX+EVs.maf_gt_0.01_eur+eagle+RSQ.phase3ID; }\n",
    "emerge_eur() { echo $1/emerge/eur/emerge.ea.1000G_p3.chr$2.CAT_FTND~SNP+AGE+SEX+PC3+PC7+PC6+PC9.maf_gt_0.01_subject+eur.rsq_gt_0.30.stats.alleles_switched; }\n",
    "finrisk_eur() { echo $1/finrisk/eur/FINRISK.ea.1000G.chr$2.CAT_FTND~1df.maf_gt_0.01_eur_FINRISK_HWEfilter_RSQ.quality_added; }\n",
    "ftc_eur() { echo $1/ftc/eur/finn_twin.ea.1000G.chr$2.CAT_FTND~1df.maf_gt_0.01_eur_finn_twin_exNA_RSQ.quality_added; }\n",
    "#gain_afr() { echo $1/gain/afr/schizo_gain.aa.1000G_p3.chr$2.CAT_FTND~SNP+SEX+AGE+EVs.maf_gt_0.01_afr+schizo_gain+RSQ.phase3ID; }\n",
    "gain_eur() { echo $1/gain/eur/schizo_gain.ea.1000G_p3.chr$2.CAT_FTND~SNP+SEX+AGE+EVs.maf_gt_0.01_eur+schizo_gain+RSQ.phase3ID; }\n",
    "german_eur() { echo $1/german/eur/$2_GermanCohort_nofilter_ftn_SNP_age_sex_5pca.maf_gt_0.01_eur+GermanCohort+exMAF0+RSQ.phase3ID; }\n",
    "#jhs_aric_afr() { echo $1/jhs_aric/afr/jhs_aric_aa.aa.1000G_p3.chr$2.CAT_FTND~SNP+AGE+SEX+EVs.maf_gt_0.01_afr+jhs_aric_aa+RSQ.phase3ID; }\n",
    "#minnesota_twins_eur() { echo $1/minnesota_twins/eur/minnesota_twins.ea.1000G_p3.chr$2.CAT_FTND~1df.add.out.maf_gt_0.01_eur+minnesota_twins.RSQ.probabel.quality_added; }\n",
    "nelson_eur() { echo $1/nelson/eur/nelson.ea.1000G_p3.chr$2.CAT_FTND~SNP+AGE+SEX+EVs.maf_gt_0.01_subject+eur.RSQ.filtered.probabel.quality_added; }\n",
    "nongain_eur() { echo $1/nongain/eur/schizo_nongain.ea.1000G_p3.chr$2.CAT_FTND~SNP+SEX+AGE+EVs.maf_gt_0.01_eur+schizo_nongain+RSQ.phase3ID; }\n",
    "ntr_eur() { echo $1/ntr/eur/ntr.ea.1000G.chr$2.CAT_FTND~1df.maf_gt_0.01_eur_ntr_info.quality_added; }\n",
    "#sage_afr() { echo $1/sage/afr/sage.aa.1000G_p3.chr$2.CAT_FTND~SEX+AGE_INT+ALC_DEP+COC_DEP+EVs.maf_gt_0.01_afr+sage+RSQ.phase3ID; }\n",
    "sage_eur() { echo $1/sage/eur/sage.ea.1000G_p3.chr$2.CAT_FTND~SEX+AGE_INT+ALC_DEP+COC_DEP+EVs.maf_gt_0.01_eur+sage+RSQ.phase3ID; }\n",
    "s4s_eur() { echo $1/s4s/eur/s4s.eur.1000G_p3.chr$2.CAT_FTND~1df.maf_gt_0.01.eur+s4s.RSQ.probabel.quality_added; }\n",
    "#uw_tturc_afr() { echo $1/uw_tturc/afr/uw-tturc.aa.1000G_p3.chr$2.CAT_FTND~SNP+SEX+AGE_INT+EVs.maf_gt_0.01_afr+uw-tturc+RSQ.phase3ID; }\n",
    "uw_tturc_eur() { echo $1/uw_tturc/eur/uw-tturc.ea.1000G_p3.chr$2.CAT_FTND~SNP+SEX+AGE_INT+EVs.maf_gt_0.01_eur+uw-tturc+RSQ.phase3ID; }\n",
    "#yale_penn_afr() { echo $1/yale_penn/afr/yale_penn.aa.1000G_p3.chr$2.FTND~SEX+AGE+EVs+CHIP_num.maf_gt_0.01_afr_yale_penn_exNA_RSQ.quality_added; }\n",
    "yale_penn_eur() { echo $1/yale_penn/eur/yale_penn.ea.1000G_p3.chr$2.FTND~SEX+AGE+EVs+CHIP_num.maf_gt_0.01_eur_yale_penn_exNA_RSQ.quality_added; }\n",
    "\n",
    "\n",
    "#NOTE, the following loop only works running in a new vim shell without any\n",
    "# predefined function. You could do this manually if you otherwise wanted to.\n",
    "# create capitalized cohort labels based off of the above functions\n",
    "cohortLabels=\"\"\n",
    "for function in $(compgen -A function);do\n",
    "    cohortLabels+=$(echo ${function^^})\n",
    "    cohortLabels+=\" \"\n",
    "done\n",
    "\n",
    "# the cohort labels below were retrieved from running the loop above\n",
    "# Note, make sure there are no other functions printed out from the compgen -a function command\n",
    "cohortLabels=${cohortLabels//\"MODULE\"}\n",
    "echo $cohortLabels\n",
    "#cohortLabels=\"COGEND2_EUR COGEND_EUR COPDGENE1_EUR COPDGENE2_EUR DECODE_EUR DENTAL_CARIES_EUR EAGLE_EUR EMERGE_EUR FINRISK_EUR FTC_EUR GAIN_EUR GERMAN_EUR NELSON_EUR NONGAIN_EUR NTR_EUR S4S_EUR SAGE_EUR UW_TTURC_EUR YALE_PENN_EUR\"\n",
    "#################################################################################################################\n",
    "#################################################################################################################\n",
    "\n",
    "##name    chrom   position        A1      A2      Freq1   MAF     Quality Rsq     n       Mean_predictor_allele   beta_SNP_addA1  sebeta_SNP_addA1      chi2_SNP_add     chi     p       or_95_percent_ci ##\n",
    "\n",
    "if [ $df == \"1df\" ];then\n",
    "    pv=\"p\"\n",
    "    std=\"STDERR\"\n",
    "elif [ $df == \"2df\" ]; then\n",
    "    pv=\"p_2df\"\n",
    "    std=\"INTERACTION\"\n",
    "fi\n",
    "\n",
    "\n",
    "\n",
    "### START METAL analysis ###\n",
    "#for (( chr=${minchr}; chr<=${maxchr}; chr++)); do\n",
    "#    my_string=\"\"\n",
    "#    for cohort in ${cohortLabels}; do\n",
    "#        if [[ $gcList !=  *\"${cohort,,}\"* ]]; then # if cohort not in GC list\n",
    "#            string_fun() { echo \"--PROCESS\" $(${cohort,,} $1 $2); }\n",
    "#            my_string+=$(string_fun $dataDir $chr)\n",
    "#            my_string+=\" \"\n",
    "#        fi\n",
    "#    done\n",
    "#\n",
    "#    \n",
    "#    if [ ${#gcList} != 0 ]; then # if there are cohorts to apply GC to\n",
    "#        my_string+=\"--GENOMICCONTROL ON  \"\n",
    "#        for cohort in ${gcList}; do\n",
    "#            string_fun() { echo \"--PROCESS\" $(${cohort,,} $1 $2); }\n",
    "#            my_string+=$(string_fun $dataDir $chr)\n",
    "#            my_string+=\" \"\n",
    "#        done \n",
    "#    fi\n",
    "#\n",
    "#    bash ~/bin/qsub_metal.sh \\\n",
    "#\t\t--chr $chr \\\n",
    "#\t\t--script_prefix metal_chr${chr} \\\n",
    "#        --SCHEME $std \\\n",
    "#        --PVALUE $pv \\\n",
    "#        --MARKER name \\\n",
    "#        --ALLELE A1 A2 \\\n",
    "#        --EFFECT beta_SNP_add \\\n",
    "#        --STDERR sebeta_SNP_add \\\n",
    "#        --GENOMICCONTROL OFF \\\n",
    "#        ${my_string} \\\n",
    "#        --OUTFILE $outDir/processing/${filePrefix}.chr$chr.$df .metal \\\n",
    "#        --ANALYZE HETEROGENEITY \\\n",
    "#        --script_prefix $outDir/processing/${filePrefix}.chr$chr.$df \\\n",
    "#        --mem 3.8 \\\n",
    "#        --priority 0\n",
    "#done \n",
    "\n",
    "###############################################################################\n",
    "# remove singleton SNP/indels (snps founnd in only one cohort) ###\n",
    "### python script ###\n",
    "\n",
    "#minchr = 1 # starting chr\n",
    "#maxchr = 23 # ending chr plus 1\n",
    "#filePrefix= \"nicotine_ftnd_wave3_gwas_meta_analysis_eur\"\n",
    "#outDir = \"/shared/jmarks/projects/nicotine/meta/results/eur/001/processing\" # no slash at end\n",
    "#\n",
    "#\n",
    "#for chrom in range(minchr,maxchr):\n",
    "#    file_name = \"{}/nicotine_ftnd_wave3_gwas_meta_analysis_eur.chr{}.1df1.metal\".format(outDir,chrom)\n",
    "#    out_name = \"{}/nicotine_ftnd_wave3_gwas_meta_analysis_eur_chr{}_exclude_singletons_stats.txt\".format(outDir,chrom)\n",
    "#\n",
    "#    print(\"Processing chromosome \" + str(chrom) + \"...\")\n",
    "#    inF = open(file_name, \"r\")\n",
    "#    outF = open(out_name, \"w\")\n",
    "#    firstLine = inF.readline()\n",
    "#    outF.write(firstLine)\n",
    "#    line = inF.readline()\n",
    "#    while(line):\n",
    "#        tmp = line.split()\n",
    "#        if(sum([d != \"?\" for d in tmp[6]]) > 1):\n",
    "#            outF.write(line)\n",
    "#        line = inF.readline()\n",
    "#    inF.close()\n",
    "#    outF.close()\n",
    "## end python script\n",
    "#################################################################################\n",
    "\n",
    "## START Merge ProbABEL and METAL results ###\n",
    "for (( chr=${minchr}; chr<=${maxchr}; chr++ )); do\n",
    "    my_string=\"\"\n",
    "    for cohort in ${cohortLabels}; do\n",
    "        string_fun() { echo $(${cohort,,} $1 $2); }\n",
    "        my_string+=$(string_fun $dataDir $chr)\n",
    "        my_string+=\" \"\n",
    "    done\n",
    "\n",
    "  /shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name merge_meta_${chr} \\\n",
    "    --script_prefix $outDir/processing/${filePrefix}.chr$chr \\\n",
    "    --mem 10 \\\n",
    "    --nslots 1 \\\n",
    "    --priority 0 \\\n",
    "    --program python ~/bin/merge_probabel_metal_v02.py \\\n",
    "        --metal $outDir/processing/${filePrefix}_chr${chr}_exclude_singletons_stats.txt \\\n",
    "        --probabel \\\n",
    "        ${my_string} \\\n",
    "        --probabel_labels ${cohortLabels} \\\n",
    "        --out $outDir/final/${filePrefix}_chr${chr}_exclude_singletons_stats_merged.txt\n",
    "done\n",
    "### END Merge ProbABEL and METAL results ###\n",
    "\n",
    "# Check for completion (should return/print out nothing)\n",
    "for (( chr=${minchr}; chr<=${maxchr}; chr++ )); do\n",
    "  file=$outDir/processing/${filePrefix}.chr$chr.qsub.log\n",
    "  if [ -f $file ]\n",
    "  then\n",
    "    logLineCount=$(wc -l $file | perl -lane 'print $F[0];')\n",
    "    if [ $logLineCount -eq 0 ]; then\n",
    "      echo $file empty\n",
    "    else\n",
    "      tail -n 1 $file |\n",
    "        perl -ne 'chomp; if (!/Done$/) { print \"'$file'\\n\".$_.\"\\n\"; }'\n",
    "    fi\n",
    "  else\n",
    "    echo $file missing\n",
    "  fi\n",
    "done\n",
    "\n",
    "\n",
    "### START Generate plots ###\n",
    "# create SNP table for input to plotting script\n",
    "outFile=$outDir/processing/${filePrefix}.table\n",
    "echo -e \"VARIANT_ID\\tCHR\\tPOSITION\\tP\\tTYPE\" > $outFile\n",
    "for (( chr=${minchr}; chr<=${maxchr}; chr++ )); do\n",
    "    inFile=$outDir/final/${filePrefix}_chr${chr}_exclude_singletons_stats_merged.txt\n",
    "    echo Processing $inFile\n",
    "    tail -n +2 $inFile |\n",
    "    perl -lne '/^(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+\\S+\\s+\\S+\\s+(\\S+)/;\n",
    "                if (($4 eq \"a\" || $4 eq \"c\" || $4 eq \"g\" || $4 eq \"t\") && ($5 eq \"a\" || $5 eq \"c\" || $5 eq \"g\" || $5 eq \"t\")) {\n",
    "                  print join(\"\\t\",$1,$2,$3,$6,\"snp\");\n",
    "                } else {\n",
    "                  print join(\"\\t\",$1,$2,$3,$6,\"indel\");\n",
    "                }' >> $outFile\n",
    "done\n",
    "\n",
    "\n",
    "# generate plots\n",
    "/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "    --job_name gwas_plots \\\n",
    "    --script_prefix $outDir/processing/${filePrefix}.plots \\\n",
    "    --mem 10 \\\n",
    "    --nslots 3 \\\n",
    "    --priority 0 \\\n",
    "    --program Rscript /shared/bioinformatics/software/R/generate_gwas_plots.R \\\n",
    "    --in $outDir/processing/${filePrefix}.table \\\n",
    "    --in_chromosomes autosomal_nonPAR \\\n",
    "    --in_header \\\n",
    "    --out $outDir/final/${filePrefix}\\\n",
    "    --col_id VARIANT_ID \\\n",
    "    --col_chromosome CHR \\\n",
    "    --col_position POSITION \\\n",
    "    --col_p P \\\n",
    "    --col_variant_type TYPE \\\n",
    "    --generate_snp_indel_manhattan_plot \\\n",
    "    --manhattan_odd_chr_color red \\\n",
    "    --manhattan_even_chr_color blue \\\n",
    "    --manhattan_points_cex 1.5 \\\n",
    "    --manhattan_cex_lab 1.5 \\\n",
    "    --manhattan_cex_axis 1.5 \\\n",
    "    --generate_snp_indel_qq_plot \\\n",
    "    --qq_lines \\\n",
    "    --qq_points_bg black \\\n",
    "    --qq_lambda\n",
    "\n",
    "## plot with ylim\n",
    "#/shared/bioinformatics/software/scripts/qsub_job.sh \\\n",
    "#  --job_name gwas_plots_no_singletons_ylim \\\n",
    "#  --script_prefix $outDir/processing/${filePrefix}.exclude_singletons.ylim_9.plots \\\n",
    "#  --mem 10 \\\n",
    "#  --nslots 3 \\\n",
    "#  --priority 0 \\\n",
    "#  --program Rscript /shared/bioinformatics/software/R/generate_gwas_plots.R \\\n",
    "#  --in $outDir/processing/${filePrefix}.exclude_singletons.table \\\n",
    "#  --in_chromosomes autosomal_nonPAR \\\n",
    "#  --in_header \\\n",
    "#  --out $outDir/processing/${filePrefix}.exclude_singletons.ylim_9 \\\n",
    "#  --col_id VARIANT_ID \\\n",
    "#  --col_chromosome CHR \\\n",
    "#  --col_position POSITION \\\n",
    "#  --col_p P \\\n",
    "#  --col_variant_type TYPE \\\n",
    "#  --generate_snp_indel_manhattan_plot \\\n",
    "#  --manhattan_odd_chr_color red \\\n",
    "#  --manhattan_even_chr_color blue \\\n",
    "#  --manhattan_points_cex 1.5 \\\n",
    "#  --manhattan_cex_lab 1.5 \\\n",
    "#  --manhattan_cex_axis 1.5 \\\n",
    "#  --generate_snp_indel_qq_plot \\\n",
    "#  --qq_lines \\\n",
    "#  --qq_points_bg black \\\n",
    "#  --qq_lambda \\\n",
    "#  --manhattan_ylim 9\n",
    "### END Generate plots ###\n",
    "\n",
    "\n",
    "#nicotine_ftnd_wave3_gwas_meta_analysis_eur_chr1_exclude_singletons_stats_merged.txt\n",
    "\n",
    "### START Filter by p-value  < 0.001 ###\n",
    "outFile=$outDir/processing/${filePrefix}_exclude_singletons.p_lte_0.001.csv\n",
    "head -n 1 $outDir/final/${filePrefix}_chr1_exclude_singletons_stats_merged.txt > $outFile\n",
    "for (( chr=${minchr}; chr<=${maxchr}; chr++ )); do\n",
    "  inFile=$outDir/final/${filePrefix}_chr${chr}_exclude_singletons_stats_merged.txt\n",
    "  echo Processing $inFile\n",
    "  tail -n +2 $inFile |\n",
    "    perl -lane 'if ($F[7] <= 0.001) { print; }' >> $outFile\n",
    "done\n",
    "### end p-value filtering ###\n",
    "\n",
    "\n",
    "#### Sort p-value filtered file (Rscript) ###\n",
    "#R\n",
    "#\n",
    "#outDir <- \"/shared/jmarks/hiv/meta/results/024/v02\"\n",
    "#pfile <- \"hiv_acq_cross_1df_meta_024_exclude_singletons.p_lte_0.001\"\n",
    "#inData <- read.table(paste(sep=\"\", outDir, \"/processing/\", pfile), header = TRUE)\n",
    "#outData <- inData[order(inData$P.value),]\n",
    "#write.csv(outData, file=paste(sep=\"\", outDir, \"/final/\", pfile, \".csv\"), row.names = FALSE, quote=FALSE)\n",
    "#### END Filter by p-value ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "### Create FUMA file ###\n",
    "# Chr \n",
    "# Position\n",
    "# MarkerName\n",
    "# P-value\n",
    "# Allele1\n",
    "# Allele2\n",
    "# Effect\n",
    "# StdErr\n",
    "\n",
    "#MarkerName chr position Allele1 Allele2 Effect StdErr P-value Direction HetISq HetChiSq HetDf HetPVal\n",
    "base_dir=$outDir/final\n",
    "\n",
    "in_file() {\n",
    "echo $1/hiv_acquisition_1df_meta_analysis_uhs1-4_aa+uhs1-4_ea+vidus_ea+wihs1_aa+wihs1_ea+wihs1_ha+wihs2_aa.chr$2.exclude_singletons.1df;\n",
    " }\n",
    "outfile=$base_dir/hiv_acquisition_1df_meta_analysis_uhs1-4_aa+uhs1-4_ea+vidus_ea+wihs1_aa+wihs1_ea+wihs1_ha+wihs2_aa.exclude_singletons.ALL_CHR.FUMA\n",
    "echo $(in_file $base_dir 1)\n",
    "\n",
    "# print header to file\n",
    "awk '{print $1,$2,$3,$4,$5,$6,$7,$8;exit}'\\\n",
    "    $(in_file $base_dir 1) > $outfile\n",
    "for (( chr=${minchr}; chr<=${maxchr}; chr++ )); do\n",
    "    echo processing chr$chr\n",
    "    awk 'NR>=2{print $1,$2,$3,$4,$5,$6,$7,$8}'\\\n",
    "     $(in_file $base_dir $chr) >> $outfile\n",
    "done\n",
    "\n",
    "### End FUMA creation ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary scripts\n",
    "These were scripts called in the methods file above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge_metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##\n",
    "import gzip, sys, os, operator\n",
    "\n",
    "# function parses input arguments\n",
    "# required arguments: --metal\n",
    "#                                        --probabel\n",
    "#                                        --probabel_labels\n",
    "#                                        --out\n",
    "def parseArguments(args):\n",
    "        while(len(args) > 0):\n",
    "                # input metal file name (full path)\n",
    "                if(args[0] == '--metal'):\n",
    "                        metalFName = args[1]\n",
    "                        args = args[2:]\n",
    "\n",
    "                # a list of input probabel file names (full path)\n",
    "                elif(args[0] == '--probabel'):\n",
    "                        args = args[1:]\n",
    "                        probabelFList = []\n",
    "                        while(len(args)>0 and args[0][:2] != '--'):\n",
    "                                probabelFList.append(args[0])\n",
    "                                args = args[1:]\n",
    "\n",
    "                # a list of probabel labels\n",
    "                elif(args[0] == '--probabel_labels'):\n",
    "                        args = args[1:]\n",
    "                        labelsList = []\n",
    "                        while(len(args)>0 and args[0][:2] != '--'):\n",
    "                                labelsList.append(args[0])\n",
    "                                args = args[1:]\n",
    "\n",
    "                # output merged file name (full path)\n",
    "                elif(args[0] == '--out'):\n",
    "                        outFName = args[1]\n",
    "                        args = args[2:]\n",
    "\n",
    "                # other arguments unused\n",
    "                else:\n",
    "                        sys.exit('Unused arguments: ' + ' '.join(args))\n",
    "\n",
    "        # check if missing required arguments\n",
    "        if('metalFName' not in locals() or 'probabelFList' not in locals() or 'labelsList' not in locals() or 'outFName' not in locals()):\n",
    "                sys.exit('Missing at least one required argument. Please specify --metal, --probabel, --probabel_labels, --out')\n",
    "\n",
    "        # check if length of probabel files equals length of probabel labels\n",
    "        if(len(probabelFList) != len(labelsList)):\n",
    "                sys.exit('Length of probabel files does not match length of probabel labels.')\n",
    "\n",
    "        return (metalFName, outFName, probabelFList, labelsList)\n",
    "\n",
    "# function sort the input probabel file by position\n",
    "def maybeSort(fname):\n",
    "        if(fname[-7:] == '.sorted'):\n",
    "                return fname\n",
    "        else:\n",
    "                # check if a sorted file is available\n",
    "                if(os.path.exists(fname + '.sorted')):\n",
    "                        print 'Using already sorted file: ' + fname + '.sorted'\n",
    "                        return fname + '.sorted'\n",
    "                #if(os.path.exists(fname + '.sorted.gz')):\n",
    "                #       os.system('rm ' + fname + '.sorted.gz')\n",
    "                # sort by position\n",
    "                inF = open(fname, 'r')\n",
    "                header = inF.readline().split()\n",
    "                if('position' in header):\n",
    "                        posIndex = str(header.index('position') + 1)\n",
    "                elif('pos' in header):\n",
    "                        posIndex = str(header.index('pos') + 1)\n",
    "                print 'Sorting file: ' + fname\n",
    "                cmd = 'sort -k' + posIndex + 'n,' + posIndex + ' ' + fname + ' > ' + fname + '.sorted'\n",
    "                os.system(cmd)\n",
    "                return fname + '.sorted'\n",
    "\n",
    "# one marker represents a row,\n",
    "# use .output() function to write to file\n",
    "class Marker:\n",
    "        def __init__(self, line):\n",
    "                tmp = line.split()\n",
    "                self.name = tmp[0]\n",
    "                self.chr = '.'\n",
    "                self.pos = '.'\n",
    "                self.content = tmp[1:]\n",
    "                self.length = self.content)\n",
    "\n",
    "        def addChrPos(self, line, chrIndex, posIndex):\n",
    "                tmp = line.split()\n",
    "                newChr = tmp[chrIndex]\n",
    "                newPos = tmp[posIndex]\n",
    "\n",
    "                if(self.chr == '.'):\n",
    "                        self.chr = newChr\n",
    "                elif(self.chr != newChr):\n",
    "                        print('Chromosome for marker ' + self.name + ' does not match.')\n",
    "\n",
    "                if(self.pos == '.'):\n",
    "                        self.pos = newPos\n",
    "                elif(self.pos != newPos):\n",
    "                        print('Position for marker ' + self.name + ' does not match.')\n",
    "\n",
    "        def output(self):\n",
    "                return(' '.join([self.name, self.chr, self.pos]) + ' ' + ' '.join(self.content))\n",
    "# extract chr and pos information from probabel file, save to metalDict\n",
    "def extractNameChrPos(metalDict, probabelFName):\n",
    "        probabelF = open(probabelFName, 'r')\n",
    "        header = probabelF.readline().split()\n",
    "\n",
    "        nameIndex = -1\n",
    "        chrIndex = -1\n",
    "        posIndex = -1\n",
    "\n",
    "        if('name' in header):\n",
    "                nameIndex = header.index('name')\n",
    "        elif('marker_name' in header):\n",
    "                nameIndex = header.index('marker_name')\n",
    "        elif('markername' in header):\n",
    "                nameIndex = header.index('markername')\n",
    "\n",
    "        if('chrom' in header):\n",
    "                chrIndex = header.index('chrom')\n",
    "        elif('chr' in header):\n",
    "                chrIndex = header.index('chr')\n",
    "\n",
    "        if('position' in header):\n",
    "                posIndex = header.index('position')\n",
    "        elif('pos' in header):\n",
    "                posIndex = header.index('pos')\n",
    "\n",
    "        if(nameIndex == -1 or chrIndex == -1 or posIndex == -1):\n",
    "                print probabelFName\n",
    "                print header\n",
    "\n",
    "        tmpSet = set()\n",
    "        for line in probabelF.readlines():\n",
    "                tmp = line.split()\n",
    "                tmpSet.add(tmp[nameIndex])\n",
    "                if(metalDict.get(tmp[nameIndex], 'NA') == 'NA'):\n",
    "                        continue\n",
    "                metalDict[tmp[nameIndex]].addChrPos(line, chrIndex, posIndex)\n",
    "        probabelF.close()\n",
    "        return tmpSet\n",
    "\n",
    "# add metal content to dictionary\n",
    "def addMetalToDict(d, fname):\n",
    "        if(fname[-2:] == 'gz'):\n",
    "                inF = gzip.open(fname, 'r')\n",
    "        else:\n",
    "                inF = open(fname, 'r')\n",
    "        markerP = {}\n",
    "        header = inF.readline()\n",
    "        pIndex = header.split().index('P-value')\n",
    "\n",
    "        for line in inF.readlines():\n",
    "                tmp = line.split()\n",
    "                marker = tmp[0]\n",
    "                d[marker] = Marker(line)\n",
    "                markerP[marker] = float(tmp[pIndex])\n",
    "\n",
    "        inF.close()\n",
    "\n",
    "        return markerP\n",
    "\n",
    "# function extract header from probabel files\n",
    "def extractHeaders(probabelStream):\n",
    "        headers = []\n",
    "        for i in range(len(probabelStream)):\n",
    "                headers.append(probabelStream[i].readline())\n",
    "        return headers\n",
    "\n",
    "# function construct header from metal files and probabel files\n",
    "def constructHeader(metalFName, probabelHeaders, labelsList):\n",
    "        if(metalFName[-2:] == 'gz'):\n",
    "                metalF = gzip.open(metalFName, 'r')\n",
    "        else:\n",
    "                metalF = open(metalFName, 'r')\n",
    "        header = metalF.readline().split()\n",
    "        header.insert(1, 'position')\n",
    "        header.insert(1, 'chr')\n",
    "        metalF.close()\n",
    "\n",
    "        for i in range(len(labelsList)):\n",
    "                tmp = probabelHeaders[i].split()\n",
    "                for t in tmp:\n",
    "                        if(t not in ['name', 'marker_name', 'markername', 'chrom', 'chr', 'position', 'pos']):\n",
    "                                header.append(t + '.' + labelsList[i])\n",
    "        return ' '.join(header)\n",
    "\n",
    "# extract marker name index and position index from header\n",
    "def extractNameIndexPosIndex(probabelHeaders):\n",
    "        nameIndex = []\n",
    "        posIndex = []\n",
    "        lengths = []\n",
    "        for header in probabelHeaders:\n",
    "                tmp = header.split()\n",
    "                if('name' in tmp):\n",
    "                        nameIndex.append(tmp.index('name'))\n",
    "                elif('marker_name' in tmp):\n",
    "                        nameIndex.append(tmp.index('marker_name'))\n",
    "                elif('markername' in tmp):\n",
    "                        nameIndex.append(tmp.index('markername'))\n",
    "                else:\n",
    "                        nameIndex.append(-1)\n",
    "                if('position' in tmp):\n",
    "                        posIndex.append(tmp.index('position'))\n",
    "                elif('pos' in tmp):\n",
    "                        posIndex.append(tmp.index('pos'))\n",
    "                else:\n",
    "                        posIndex.append(-1)\n",
    "                lengths.append(len(tmp) - posIndex[-1] - 1)\n",
    "        return (nameIndex, posIndex, lengths)\n",
    "\n",
    "def processThisMarker(markerName, metalDict, probabelStream, markerNames, buffer, probabelHeaders):\n",
    "        nameIndex, posIndex, lengths = extractNameIndexPosIndex(probabelHeaders)\n",
    "        # content from metal\n",
    "        thisMarker = metalDict[markerName]\n",
    "        line = thisMarker.output() # metal content added\n",
    "        for i in range(len(probabelStream)):\n",
    "                if(thisMarker.name in markerNames[i]):\n",
    "                        # first check buffer\n",
    "                        if(buffer[i].get(thisMarker.name, 'NA') != 'NA'):\n",
    "                                line = line + ' ' + ' '.join(buffer[i][thisMarker.name])\n",
    "                                del buffer[i][thisMarker.name]\n",
    "                        # not in buffer, then read in from stream\n",
    "                        else:\n",
    "                                newLine = probabelStream[i].readline()\n",
    "                                tmp = newLine.split()\n",
    "                                # if the next element is not the one looking for, deposite in buffer\n",
    "                                while(newLine and tmp[nameIndex[i]] != thisMarker.name):\n",
    "                                        buffer[i][tmp[nameIndex[i]]] = tmp[posIndex[i]+1:]\n",
    "                                        newLine = probabelStream[i].readline()\n",
    "                                        tmp = newLine.split()\n",
    "\n",
    "                                # now this is the marker\n",
    "                                line = line + ' ' + ' '.join(tmp[posIndex[i]+1:])\n",
    "                else:\n",
    "                        for j in range(lengths[i]):\n",
    "                                line = line + ' NA'\n",
    "        return line\n",
    "\n",
    "def checkOutput(outFName):\n",
    "        with open(outFName) as outF:\n",
    "                header = outF.readline()\n",
    "                headerLength = len(header.split())\n",
    "                line = outF.readline()\n",
    "                while(line):\n",
    "                        if(len(line.split()) != headerLength):\n",
    "                                return \"Fail\"\n",
    "                        line = outF.readline()\n",
    "                return \"Succeed\"\n",
    "\n",
    "# the main function\n",
    "if __name__ == \"__main__\":\n",
    "        metalFName, outFName, probabelFList, labelsList = parseArguments(sys.argv[1:])\n",
    "\n",
    "        for i in range(len(probabelFList)):\n",
    "                probabelFList[i] = maybeSort(probabelFList[i])\n",
    "\n",
    "        # read in metal file\n",
    "        # construct a dictionary to hold all metal results\n",
    "        # key is the marker name, value is a Marker class object\n",
    "        metalDict = {}\n",
    "        markerP = addMetalToDict(metalDict, metalFName) # markerP - meta analyses p-value\n",
    "\n",
    "        # first loop through all probabel files to add chr and position information\n",
    "        # at the same time, keep a record of all marker names\n",
    "        markerNames = []\n",
    "        for probabelFName in probabelFList:\n",
    "                tmpSet = extractNameChrPos(metalDict, probabelFName)\n",
    "                markerNames.append(tmpSet)\n",
    "\n",
    "        # sort marker by position\n",
    "        markerPos = {}\n",
    "        for m in metalDict.keys():\n",
    "                try:\n",
    "                        markerPos[m] = int(metalDict[m].pos)\n",
    "                except Exception:\n",
    "                        pass\n",
    "        sortedMarker = sorted(markerPos.items(), key=operator.itemgetter(1))\n",
    "\n",
    "        # loop through all probabel files second times\n",
    "        # this time, keep the input stream\n",
    "        probabelStream = []\n",
    "        for probabelFName in probabelFList:\n",
    "                probabelStream.append(open(probabelFName))\n",
    "\n",
    "        # first pass - create the output file\n",
    "        # header - first line from stream read\n",
    "        outF = open(outFName, 'w')\n",
    "        probabelHeaders = extractHeaders(probabelStream)\n",
    "        outF.write(constructHeader(metalFName, probabelHeaders, labelsList) + '\\n')\n",
    "\n",
    "        # content - read subsequent lines\n",
    " # a buffer stores markers that are out of order\n",
    "        buffer = []\n",
    "        for i in probabelHeaders:\n",
    "                buffer.append({})\n",
    "        for m in sortedMarker:\n",
    "                line = processThisMarker(m[0], metalDict, probabelStream, markerNames, buffer, probabelHeaders)\n",
    "                outF.write(line + '\\n')\n",
    "\n",
    "        outF.close()\n",
    "\n",
    "        # check output number of columns\n",
    "\n",
    "        while(checkOutput(outFName) == 'Fail'):\n",
    "                # header - first line from stream read\n",
    "                outF = open(outFName, 'w')\n",
    "                probabelHeaders = extractHeaders(probabelStream)\n",
    "                outF.write(constructHeader(metalFName, probabelHeaders, labelsList) + '\\n')\n",
    "\n",
    "                # content - read subsequent lines\n",
    "                # a buffer stores markers that are out of order\n",
    "                buffer = []\n",
    "                for i in probabelHeaders:\n",
    "                        buffer.append({})\n",
    "                for m in sortedMarker:\n",
    "                        line = processThisMarker(m[0], metalDict, probabelStream, markerNames, buffer, probabelHeaders)\n",
    "                        outF.write(line + '\\n')\n",
    "\n",
    "                outF.close()\n",
    "\n",
    "        print 'Done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qsub_metal_v2.sh\n",
    "I had to modify lines 70 and 71 to reflect the parallel processing (multi-threading) environment in the AWS environment - symmetric multiprocessing (smp)\n",
    "\n",
    "In smp all of the cores act as one through the operating system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#!/bin/sh\n",
    "\n",
    "metalScript=\"#!/shared/bioinformatics/software/third_party/metal_v3.25.2011/bin/metal\\n\\n\"\n",
    "outFile=\"\"\n",
    "finalOutFile=\"\"\n",
    "scriptPrefix=\"\"\n",
    "mem=3.8\n",
    "priority=0\n",
    "\n",
    "while [ \"$1\" != \"\" ];\n",
    "do\n",
    "        if [ \"$1\" == \"--MARKER\" ] || [ \"$1\" == \"--EFFECT\" ] || [ \"$1\" == \"--PVALUE\" ] || [ \"$1\" == \"--WEIGHT\" ] || [ \"$1\" == \"--GENOMICCONTROL\" ] || [ \"$1\" == \"--PROCESS\" ] || [ \"$1\" == \"--SCHEME\" ] || [ \"$1\" == \"--STDERR\" ]; then\n",
    "                metalScript=$metalScript$(echo $1 | sed 's/--//')\" \"$2\"\\n\"\n",
    "                shift\n",
    "        elif [ \"$1\" == \"--ALLELE\" ] || [ \"$1\" == \"--OUTFILE\" ]; then\n",
    "                metalScript=$metalScript$(echo $1 | sed 's/--//')\" \"$2\" \"$3\"\\n\"\n",
    "                if [ \"$1\" == \"--OUTFILE\" ]; then\n",
    "                        outFile=$2\"1\"$3\n",
    "                        finalOutFile=$2$3\n",
    "                fi\n",
    "                shift\n",
    "                shift\n",
    "        elif [ \"$1\" == \"--ANALYZE\" ]; then\n",
    "                if [ \"$2\" == \"HETEROGENEITY\" ]; then\n",
    "                        metalScript=$metalScript\"ANALYZE HETEROGENEITY\\n\"\n",
    "                        shift\n",
    "                else\n",
    "                        metalScript=$metalScript\"ANALYZE\\n\"\n",
    "                fi\n",
    "        else\n",
    "                case $1 in\n",
    "                        --script_prefix )                       shift\n",
    "                                                                                scriptPrefix=$1\n",
    "                                                                                ;;\n",
    "                        --mem )                                         shift\n",
    "                                                                                mem=$1\n",
    "                                                                                ;;\n",
    "                        --priority )                            shift\n",
    "                                                                                priority=$1\n",
    "                                                                                ;;\n",
    "                esac\n",
    "        fi\n",
    "        shift\n",
    "done\n",
    "metalScript=$metalScript\"QUIT\\n\"\n",
    "fileMetalScript=$scriptPrefix\".metal.sh\"\n",
    "echo -e $metalScript > $fileMetalScript\n",
    "chmod 775 $fileMetalScript\n",
    "\n",
    "fileQsubScript=$scriptPrefix\".metal.qsub.sh\"\n",
    "fileQsubScriptLog=$scriptPrefix\".metal.qsub.log\"\n",
    "fileQsubScriptError=$scriptPrefix\".metal.qsub.error\"\n",
    "echo \\#$ -S /bin/bash > $fileQsubScript\n",
    "echo \\#$ -v LD_LIBRARY_PATH >> $fileQsubScript\n",
    "echo \\#  >> $fileQsubScript\n",
    "echo \\# >> $fileQsubScript\n",
    "echo \\#$ -l h_rt=600:00:00  >> $fileQsubScript\n",
    "echo \\# >> $fileQsubScript\n",
    "echo \\# >> $fileQsubScript\n",
    "echo \\# Job name  >> $fileQsubScript\n",
    "echo \\#$ -N METAL >> $fileQsubScript\n",
    "echo \\# >> $fileQsubScript\n",
    "echo \\# Use current working directory >> $fileQsubScript\n",
    "echo \\#$ -cwd >> $fileQsubScript\n",
    "echo \\# >> $fileQsubScript\n",
    "echo \\# Join stdout and stderr >> $fileQsubScript\n",
    "echo \\#$ -j y >> $fileQsubScript\n",
    "echo \\# >> $fileQsubScript\n",
    "echo \\# pe request for MPICH2. Set your number of processors here.  >> $fileQsubScript\n",
    "echo \\# SMP stands for \"Shared Memory Jobs\" >> $fileQsubScript\n",
    "echo \\#$ -pe smp 1 >> $fileQsubScript\n",
    "echo \\# >> $fileQsubScript\n",
    "echo \\# Run job through bash shell >> $fileQsubScript\n",
    "echo \\#$ -S /bin/bash >> $fileQsubScript\n",
    "echo \\# >> $fileQsubScript\n",
    "echo \\# The following is for reporting only. It is not really needed >> $fileQsubScript\n",
    "echo \\# to run the job. It will show up in your output file. >> $fileQsubScript\n",
    "echo echo \\\"Got \\$NSLOTS processors.\\\" >> $fileQsubScript\n",
    "echo $fileMetalScript >> $fileQsubScript\n",
    "echo mv $outFile $finalOutFile >> $fileQsubScript\n",
    "echo mv $outFile.info $finalOutFile.info >> $fileQsubScript\n",
    "\n",
    "chmod 775 $fileQsubScript\n",
    "\n",
    "vmem=`echo \"$mem + 2\" | bc`\n",
    "\n",
    "qsub -q all.q -l mem_free=${mem}G,h_vmem=${vmem}G,h_rt=24:00:00 -p $priority -o $fileQsubScriptLog -e $fileQsubScriptError $fileQsubScript\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inFile=ftnd3_ukbiobank_gwas_meta_afr_eur_chr9_exclude_singletons_stats.txt\n",
    " tail -n +2 $inFile |  \\\n",
    "    perl -lne '/^(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+\\S+\\s+\\S+\\s+\\S+\\s+\\S+\\s+(\\S+)/;\n",
    "                if (($2 eq \"a\" || $2 eq \"c\" || $2 eq \"g\" || $2 eq \"t\")\n",
    "                && ($3 eq \"a\" || $3 eq \"c\" || $3 eq \"g\" || $3 eq \"t\")) {\n",
    "                    print join(\"\\t\",$1,$2,$3,$4,\"snp\");\n",
    "                } else {\n",
    "                    print join(\"\\t\",$1,$2,$3,$4,\"indel\");\n",
    "                        }'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "586px",
    "left": "0px",
    "right": "1351.46px",
    "top": "110px",
    "width": "167px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

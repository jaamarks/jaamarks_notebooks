{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data and visualize\n",
    "I need to grab the beta value and the standard error (beta) for each SNP accross each cohort.\n",
    "\n",
    "**Don't forget** I need to grab the minor allele and major allele of each SNP across each cohort. I will determine the orientation. Then, I will use a \"majority rules\" approach to determine if I need to flip the sign of the beta. Specifically, if the major and minor alleles are listed differently for a few cohorts, then I will need to flip the sign of the beta (i.e. change from negative to positive or vice versa.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data\n",
    "This sample data is for one variant - `rs1008078` - accross all the cohorts in meta-analysis 044. I will store the results in a dictionary. The key will be the rsID and the key will be to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from decimal import Decimal\n",
    "from scipy.stats import chisqprob\n",
    "\n",
    "# I will create a new data frame for each variant. This data frame will have the column names:\n",
    "# (1) cohort, (2) Ancestry group, (3) Beta, (4) Std. Error, (5) Seweighted, and (6) Pr(>|t|) which is the p-val\n",
    "# addictionally  I will add the rows for calculating the meta in the Seweighted column and below all of the cohorts\n",
    "# getting the first cohort, note that this will eventually be in a loop of the cohorts\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\jmarks\\\\Desktop\\\\Projects\\\\Nicotine\\\\GSCAN_extended_results_nicotine\\\\results\\\\results_from_missing_snp_lookup\\\\\")\n",
    "mydata = pd.ExcelFile(\"sample_missing_SNP_results.xlsx\")\n",
    "mydata = mydata.parse(\"Sheet1\")\n",
    "\n",
    "cohorts_list44 = [\"AAND_COGEND2_AA\",\n",
    "\"COGEND_AA\",\n",
    "\"COGEND_EA\",\n",
    "\"COGEND2_AA\",\n",
    "\"COGEND2_EA\",\n",
    "\"COPDGene_AA\",\n",
    "\"COPDGene_EA\",\n",
    "\"deCODE_EA\",\n",
    "\"Dental_Caries_EA\",\n",
    "\"EAGLE_EA\",\n",
    "\"FINN_TWIN_EA\",\n",
    "\"GAIN_AA\",\n",
    "\"GAIN_EA\",\n",
    "\"JHS_AA\",\n",
    "\"nonGAIN_EA\",\n",
    "\"NTR_EA\",\n",
    "\"SAGE_AA\",\n",
    "\"SAGE_EA\",\n",
    "\"UW_TTURC_AA\",\n",
    "\"UW_TTURC_EA\",\n",
    "\"YALE_PENN_AA\",\n",
    "\"YALE_PENN_EA\"]\n",
    "\n",
    "totalRows = len(cohorts_list44)\n",
    "\n",
    "# This dictionary will have an rsID for the key and the key will be to a dataframe\n",
    "dataDict = {}\n",
    "\n",
    "# initialize a dataframe\n",
    "emptyArray = np.empty((totalRows,13,))\n",
    "emptyArray[:] = np.nan\n",
    "columns = [\"SNP\", \"Cohort\", \"Ancestry group\", \"Beta\", \"Std. Error\", \"Seweighted\", \"Pr(>|t|)\", \n",
    "           \"AllMeta.SumSEweight\", \"AllMeta.weightedSE\", \"AllMeta.SEweighted_beta\", \n",
    "           \"AllMeta.SEweighted_Z\", \"AllMeta.SEweighted_Chi\", \"AllMeta.SEweighted_P\"]\n",
    "num_of_rsIDs = len(mydata)\n",
    "\n",
    "# initialize a meta-calculation\n",
    "metaSEweighted_beta = 0\n",
    "\n",
    "# loop to fill in information for the meta-anlaysis calculation\n",
    "for rsID in range(num_of_rsIDs):\n",
    "    \n",
    "    markerName = mydata.iloc[rsID,0]\n",
    "    dataDict[markerName] = pd.DataFrame(columns=columns, data=emptyArray)\n",
    "    dataDict[markerName].iloc[rsID,0] = markerName # add SNP\n",
    "    \n",
    "    for cohort in range(len(cohorts_list44)):\n",
    "        \n",
    "        #print(cohorts_list44[cohort])\n",
    "        # get all of the cohort specific data\n",
    "        cohortData = mydata.filter(like=cohorts_list44[cohort]).iloc[0,:]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #cohortData\n",
    "        \n",
    "        # add cohort to dataframe\n",
    "        cohortName = cohorts_list44[cohort]\n",
    "        dataDict[markerName].iloc[cohort,1] = cohorts_list44[cohort]\n",
    "        \n",
    "        # add Ancestry group\n",
    "        ancestry = cohorts_list44[cohort][-2:]\n",
    "        dataDict[markerName].iloc[cohort, 2] = ancestry\n",
    "        \n",
    "        # add Beta\n",
    "        betaVal = cohortData.filter(like=\".beta\")[0]\n",
    "        #print(betaVal)\n",
    "        dataDict[markerName].iloc[cohort, 3] = betaVal\n",
    "        \n",
    "        # add Std. Error\n",
    "        standardErr = cohortData.filter(like=\"sebeta\")[0]\n",
    "        dataDict[markerName].iloc[cohort, 4] = standardErr\n",
    "        # add Seweighted\n",
    "        seWeighted = 1 / (standardErr ** 2)\n",
    "        dataDict[markerName].iloc[cohort,5]  = seWeighted\n",
    "        \n",
    "        # add p-val\n",
    "        pVal = cohortData.filter(regex=\".p$\")[0]\n",
    "        dataDict[markerName].iloc[cohort, 6] = pVal\n",
    "        \n",
    "        # add to metaSEweighted_beta\n",
    "        metaSEweighted_beta += betaVal*standardErr\n",
    "        \n",
    "\n",
    "# Meta calculations\n",
    "SumSEweight = dataDict[markerName]['Seweighted'].sum()\n",
    "dataDict[markerName].iloc[0, 7] = SumSEweight\n",
    "    \n",
    "metaWeightedSE = math.sqrt(1/SumSEweight)\n",
    "dataDict[markerName].iloc[0, 8] = metaWeightedSE\n",
    "\n",
    "dataDict[markerName].iloc[0, 9] = metaSEweighted_beta\n",
    "\n",
    "metaSEweighted_Z = (metaSEweighted_beta / metaWeightedSE)\n",
    "dataDict[markerName].iloc[0, 10] = metaSEweighted_Z\n",
    "\n",
    "metaSEweighted_chi = metaSEweighted_Z ** 2\n",
    "dataDict[markerName].iloc[0, 11] = metaSEweighted_chi\n",
    "\n",
    "metaSEweighted_P = '%.2E' % Decimal(chi2.sf(metaSEweighted_chi, 1))\n",
    "dataDict[markerName].iloc[0, 12] = metaSEweighted_P\n",
    "\n",
    "\n",
    "dataDict[markerName]\n",
    "dataDict[markerName].to_csv(\"C:\\\\Users\\\\jmarks\\\\Desktop\\\\out.file\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COPDGene_AA'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohorts_list44[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.empty((29,7,))\n",
    "a[:] = np.nan\n",
    "print(a)\n",
    "tempDF = pd.DataFrame(np.nan, index=[0,1,2,3],columns=[\"a\",\"b\",\"c\"])\n",
    "#tempDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNP</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Ancestry group</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Std. Error</th>\n",
       "      <th>Seweighted</th>\n",
       "      <th>Pr(&gt;|t|)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SNP, Cohort, Ancestry group, Beta, Std. Error, Seweighted, Pr(>|t|)]\n",
       "Index: []"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDict['rs1008078']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 044 meta-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-31457ffe1a7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mzero44\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mzero44\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero44\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mzero45\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mzero45\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero45\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mzero46\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"C:\\\\Users\\\\jmarks\\\\Desktop\\\\Projects\\\\Nicotine\\\\GSCAN_extended_results_nicotine\\\\results\\\\results_from_missing_snp_lookup\\\\\")\n",
    "\n",
    "\n",
    "#os.listdir()\n",
    "#xl = pd.ExcelFile(\"missing_SNPs_results_prefiltered_meta_analyses_044_045_046_V02.xlsx\")\n",
    "xl.sheet_names\n",
    "zero44 = xl.sheet_names[0]\n",
    "zero44 = xl.parse(zero44)\n",
    "zero45 = xl.sheet_names[1]\n",
    "zero45 = xl.parse(zero45)\n",
    "zero46 = xl.sheet_names[2]\n",
    "zero46 = xl.parse(zero46)\n",
    "zero44.iloc[0:1,:]\n",
    "\n",
    "# beta is in each, but also sebeta is too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 045 meta-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 046 meta-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
